{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start with select columns of the biggest csv, merge them with descriptions csv, and remove users with fewer than 3 checkins and beers with fewer than 2 checkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1894852, 9)\n",
      "(114347, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "checkins = pd.read_csv('comboframe.csv', usecols=['beer_id', 'rating_user',\n",
    "                                                  'rating_global', 'user_id',\n",
    "                                                  'abv', 'brewery_name',\n",
    "                                                  'beer_style', 'beer_name',\n",
    "                                                  'checkin_id'])\n",
    "# only allow each user one rating for each beer\n",
    "checkins.drop_duplicates(subset=['beer_id', 'user_id'], inplace=True)\n",
    "print(checkins.shape)\n",
    "descrips = pd.read_csv('descriptions.csv')\n",
    "print(descrips.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1394388, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge in the descriptions and see how many checkins remain\n",
    "checkins = checkins.merge(descrips, how='inner')\n",
    "checkins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1155870, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins = checkins[checkins.user_id.map(checkins.groupby('user_id').size() > 2)]\n",
    "checkins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1129526, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins = checkins[checkins.beer_id.map(checkins.groupby('beer_id').size() > 1)]\n",
    "checkins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1129526 entries, 0 to 1394387\n",
      "Data columns (total 10 columns):\n",
      "checkin_id          1129526 non-null int64\n",
      "beer_id             1129526 non-null int64\n",
      "user_id             1129526 non-null int64\n",
      "rating_user         1129526 non-null float64\n",
      "brewery_name        1129526 non-null object\n",
      "beer_name           1129526 non-null object\n",
      "beer_style          1129526 non-null object\n",
      "rating_global       1104319 non-null float64\n",
      "abv                 1129526 non-null float64\n",
      "beer_description    1129526 non-null object\n",
      "dtypes: float64(3), int64(3), object(4)\n",
      "memory usage: 94.8+ MB\n"
     ]
    }
   ],
   "source": [
    "checkins.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1103369, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the ones with no global ratings\n",
    "checkins.dropna(subset=['rating_global'], axis=0, inplace=True)\n",
    "# and the zeros\n",
    "checkins = checkins[checkins.rating_global > 0]\n",
    "checkins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkin_id</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>821797539</td>\n",
       "      <td>2095023</td>\n",
       "      <td>3340203</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>793777280</td>\n",
       "      <td>2095023</td>\n",
       "      <td>2166716</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   checkin_id  beer_id  user_id  rating_user   brewery_name  \\\n",
       "0   821797539  2095023  3340203         3.75  Stone Brewing   \n",
       "1   793777280  2095023  2166716         3.50  Stone Brewing   \n",
       "\n",
       "                 beer_name      beer_style  rating_global  abv  \\\n",
       "0  Stone Scorpion Bowl IPA  IPA - American        3.73789  7.5   \n",
       "1  Stone Scorpion Bowl IPA  IPA - American        3.73789  7.5   \n",
       "\n",
       "                                    beer_description  \n",
       "0  To create a recipe so tropical and fruity with...  \n",
       "1  To create a recipe so tropical and fruity with...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkin_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.103369e+06</td>\n",
       "      <td>1.103369e+06</td>\n",
       "      <td>1.103369e+06</td>\n",
       "      <td>1.103369e+06</td>\n",
       "      <td>1.103369e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.546046e+08</td>\n",
       "      <td>2.094023e+06</td>\n",
       "      <td>3.826596e+00</td>\n",
       "      <td>3.828369e+00</td>\n",
       "      <td>6.927206e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.028723e+08</td>\n",
       "      <td>1.729344e+06</td>\n",
       "      <td>5.743143e-01</td>\n",
       "      <td>2.891699e-01</td>\n",
       "      <td>1.984595e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.773630e+05</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>1.536520e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.420015e+08</td>\n",
       "      <td>6.537330e+05</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>3.657270e+00</td>\n",
       "      <td>5.700000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.892611e+08</td>\n",
       "      <td>1.651536e+06</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>3.811980e+00</td>\n",
       "      <td>6.700000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.113865e+08</td>\n",
       "      <td>3.161810e+06</td>\n",
       "      <td>4.250000e+00</td>\n",
       "      <td>4.010630e+00</td>\n",
       "      <td>7.900000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.491104e+08</td>\n",
       "      <td>7.450082e+06</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>4.903410e+00</td>\n",
       "      <td>6.500000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         checkin_id       user_id   rating_user  rating_global           abv\n",
       "count  1.103369e+06  1.103369e+06  1.103369e+06   1.103369e+06  1.103369e+06\n",
       "mean   7.546046e+08  2.094023e+06  3.826596e+00   3.828369e+00  6.927206e+00\n",
       "std    1.028723e+08  1.729344e+06  5.743143e-01   2.891699e-01  1.984595e+00\n",
       "min    9.773630e+05  1.900000e+01  1.000000e-01   1.536520e+00  0.000000e+00\n",
       "25%    7.420015e+08  6.537330e+05  3.500000e+00   3.657270e+00  5.700000e+00\n",
       "50%    7.892611e+08  1.651536e+06  4.000000e+00   3.811980e+00  6.700000e+00\n",
       "75%    8.113865e+08  3.161810e+06  4.250000e+00   4.010630e+00  7.900000e+00\n",
       "max    8.491104e+08  7.450082e+06  5.000000e+00   4.903410e+00  6.500000e+01"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins[['checkin_id','user_id','rating_user','rating_global','abv']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3284"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(checkins.abv == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.100044e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.946279e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.932038e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.700000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.700000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.900000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.900000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                abv\n",
       "count  1.100044e+06\n",
       "mean   6.946279e+00\n",
       "std    1.932038e+00\n",
       "min    3.000000e-01\n",
       "25%    5.700000e+00\n",
       "50%    6.700000e+00\n",
       "75%    7.900000e+00\n",
       "max    2.900000e+01"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Those will mess up the predictions, since abv is a strong correlator with ratings.  Also get rid of that 65% abv!!\n",
    "checkins = checkins[(checkins.abv > 0) & (checkins.abv < 30)]\n",
    "checkins[['abv']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start with a scenario where we have no ratings for a user.  We'll say the user is looking at a menu of 10 beers.  With only this info, our only recourse is to recommend things in order of their global mean ratings.  Let's simulate that by taking the users who have exactly 10 ratings and seeing how the user ranked the top 3 recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4130"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a mapping from user to number of ratings can be helpful in many situations\n",
    "usercounts = checkins.groupby('user_id').size()\n",
    "tens = checkins[checkins.user_id.map(usercounts) == 10].set_index('user_id').sort_index()\n",
    "len(tens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have 413 users.  Here's the \"digital menu\" staring our first user in the face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Half Acre Beer Company</td>\n",
       "      <td>Logue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yamorido</td>\n",
       "      <td>Coup De Grace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Westside Ale Works</td>\n",
       "      <td>Weekend Juice NEIPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chilly Water Brewing Company</td>\n",
       "      <td>Wagon Wheel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6 beers brewing co.</td>\n",
       "      <td>Limelight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hemingway's Brewery</td>\n",
       "      <td>Doug's Courage XPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Upslope Brewing Company</td>\n",
       "      <td>Hazy IPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Half Acre Beer Company</td>\n",
       "      <td>Alive In Its Jaws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Uchu Brewing</td>\n",
       "      <td>Aldebaran (#65)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Y.Market Brewing</td>\n",
       "      <td>Hysteric IPA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   brewery_name            beer_name\n",
       "0        Half Acre Beer Company                Logue\n",
       "1                      Yamorido        Coup De Grace\n",
       "2            Westside Ale Works  Weekend Juice NEIPA\n",
       "3  Chilly Water Brewing Company          Wagon Wheel\n",
       "4           6 beers brewing co.            Limelight\n",
       "5           Hemingway's Brewery   Doug's Courage XPA\n",
       "6       Upslope Brewing Company             Hazy IPA\n",
       "7        Half Acre Beer Company    Alive In Its Jaws\n",
       "8                  Uchu Brewing      Aldebaran (#65)\n",
       "9              Y.Market Brewing         Hysteric IPA"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.reset_index()[['brewery_name', 'beer_name']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how those 10 are rated globally, from best to worst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_name</th>\n",
       "      <th>rating_global</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alive In Its Jaws</td>\n",
       "      <td>4.28491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logue</td>\n",
       "      <td>4.10604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aldebaran (#65)</td>\n",
       "      <td>4.00521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hazy IPA</td>\n",
       "      <td>3.87626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weekend Juice NEIPA</td>\n",
       "      <td>3.74539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hysteric IPA</td>\n",
       "      <td>3.74126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Limelight</td>\n",
       "      <td>3.67035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coup De Grace</td>\n",
       "      <td>3.64394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wagon Wheel</td>\n",
       "      <td>3.60677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Doug's Courage XPA</td>\n",
       "      <td>3.60528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             beer_name  rating_global\n",
       "7    Alive In Its Jaws        4.28491\n",
       "0                Logue        4.10604\n",
       "8      Aldebaran (#65)        4.00521\n",
       "6             Hazy IPA        3.87626\n",
       "2  Weekend Juice NEIPA        3.74539\n",
       "9         Hysteric IPA        3.74126\n",
       "4            Limelight        3.67035\n",
       "1        Coup De Grace        3.64394\n",
       "3          Wagon Wheel        3.60677\n",
       "5   Doug's Courage XPA        3.60528"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tens.head(10)\n",
    "t.reset_index()[['beer_name', 'rating_global']].sort_values('rating_global', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and how the user rated them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_name</th>\n",
       "      <th>rating_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logue</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alive In Its Jaws</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aldebaran (#65)</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coup De Grace</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Limelight</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Doug's Courage XPA</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hazy IPA</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hysteric IPA</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weekend Juice NEIPA</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wagon Wheel</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             beer_name  rating_user\n",
       "0                Logue         3.75\n",
       "7    Alive In Its Jaws         3.75\n",
       "8      Aldebaran (#65)         3.75\n",
       "1        Coup De Grace         3.50\n",
       "4            Limelight         3.50\n",
       "5   Doug's Courage XPA         3.50\n",
       "6             Hazy IPA         3.50\n",
       "9         Hysteric IPA         3.50\n",
       "2  Weekend Juice NEIPA         3.25\n",
       "3          Wagon Wheel         3.25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reset_index()[['beer_name', 'rating_user']].sort_values('rating_user', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first user, the global mean works great:  The top 3 recommendations were the 3 the user ended up rating the highest.  This user would be happy to use this recommender again.  Before this user ever gets down to the 5th recommendation, the one that was tied for last in his actual ratings, he will hopefully have given the recommender some feedback (ratings) to make more informed decisions.  Also, a user in this situation very likely may repeat orders once he's happy with one or two, so the demands of such a recommender are different from, say, a book recommender.   Now let's see how this method works for all 413 users here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a func to deal with ties in rankings\n",
    "def untied_rank(arr, vals):\n",
    "    '''\n",
    "    Measure how well the input vals (list or np.array) has chosen\n",
    "    the top values of input arr (np.array). \n",
    "    vals must be subset of arr.\n",
    "    1.0 is perfect, 0.0 is worst.\n",
    "    '''\n",
    "    fails = 0\n",
    "    poss_fails = 0\n",
    "    ordered = np.sort(arr)\n",
    "    if max(ordered) == min(ordered): return 0.5  # like guessing, if all equal\n",
    "    for i in range(len(vals)):\n",
    "        fails += sum(arr > vals[i])\n",
    "        arr = np.delete(arr, np.where(arr == vals[i])[0][0])\n",
    "        poss_fails += sum(ordered > ordered[i])\n",
    "    \n",
    "    return 1 - fails / poss_fails\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The perfect rankings for the first user, above\n",
    "untied_rank(t.rating_user.values, t.rating_user.values[np.argsort(t.rating_global.values)[:-4:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score picking the top 3 globally rated for 413 \"menus\":  0.7535366940665592\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for u in tens.index.unique():\n",
    "    uten = tens.loc[u, ['rating_user','rating_global']]\n",
    "    scores.append(untied_rank(uten.rating_user.values, \n",
    "                              uten.rating_user.values[np.argsort(uten.rating_global.values)[:-4:-1]]))\n",
    "print(f'The average score picking the top 3 globally rated for 413 \"menus\":  {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what a .75 score looks like for one user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The global rankings/recommendations for that user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_name</th>\n",
       "      <th>rating_global</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cone Wars: Idaho 7 Fresh Hop IPA</td>\n",
       "      <td>4.03846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wicked Haze</td>\n",
       "      <td>3.91730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Emergent IPA</td>\n",
       "      <td>3.91379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Melon Rye IIIPA</td>\n",
       "      <td>3.90668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Citra IPA</td>\n",
       "      <td>3.81579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Humulus Unum Amarillo</td>\n",
       "      <td>3.77632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Capo Blood Orange IPA</td>\n",
       "      <td>3.71512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fraud Alert</td>\n",
       "      <td>3.62619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hophoria IPA</td>\n",
       "      <td>3.58289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bullseye Pale Ale</td>\n",
       "      <td>3.57362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          beer_name  rating_global\n",
       "5  Cone Wars: Idaho 7 Fresh Hop IPA        4.03846\n",
       "0                       Wicked Haze        3.91730\n",
       "9                  The Emergent IPA        3.91379\n",
       "1                   Melon Rye IIIPA        3.90668\n",
       "6                         Citra IPA        3.81579\n",
       "3             Humulus Unum Amarillo        3.77632\n",
       "4             Capo Blood Orange IPA        3.71512\n",
       "2                       Fraud Alert        3.62619\n",
       "7                      Hophoria IPA        3.58289\n",
       "8                 Bullseye Pale Ale        3.57362"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tens.iloc[360:370, :]\n",
    "t.reset_index()[['beer_name', 'rating_global']].sort_values('rating_global', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and actual ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_name</th>\n",
       "      <th>rating_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wicked Haze</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cone Wars: Idaho 7 Fresh Hop IPA</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Melon Rye IIIPA</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Citra IPA</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fraud Alert</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Humulus Unum Amarillo</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Capo Blood Orange IPA</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hophoria IPA</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bullseye Pale Ale</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Emergent IPA</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          beer_name  rating_user\n",
       "0                       Wicked Haze         4.25\n",
       "5  Cone Wars: Idaho 7 Fresh Hop IPA         4.00\n",
       "1                   Melon Rye IIIPA         3.75\n",
       "6                         Citra IPA         3.75\n",
       "2                       Fraud Alert         3.50\n",
       "3             Humulus Unum Amarillo         3.50\n",
       "4             Capo Blood Orange IPA         3.50\n",
       "7                      Hophoria IPA         3.50\n",
       "8                 Bullseye Pale Ale         3.50\n",
       "9                  The Emergent IPA         3.50"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reset_index()[['beer_name', 'rating_user']].sort_values('rating_user', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's good recommendations:  The top 2 came in second and first, and the 3rd rec was actually tied for 5th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The worst-case scenario for this recommender method is when a user rates everything pretty equally, and the high global rating beers are unlikely to be picked out from the others by this user.  An example is this user whose ratings score 0.0 by this system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_name</th>\n",
       "      <th>rating_global</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Peconic Project</td>\n",
       "      <td>4.07962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wicked Smaht</td>\n",
       "      <td>3.97449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DJ Night</td>\n",
       "      <td>3.80664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sigint</td>\n",
       "      <td>3.70455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Citralization</td>\n",
       "      <td>3.70051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Go Bigg Or Go Home IPA</td>\n",
       "      <td>3.66873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Smilin' Mike</td>\n",
       "      <td>3.62981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Useful Idiot</td>\n",
       "      <td>3.59771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daayani</td>\n",
       "      <td>3.59000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West Coast IPA</td>\n",
       "      <td>3.56235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                beer_name  rating_global\n",
       "6         Peconic Project        4.07962\n",
       "7            Wicked Smaht        3.97449\n",
       "1                DJ Night        3.80664\n",
       "3                  Sigint        3.70455\n",
       "9           Citralization        3.70051\n",
       "5  Go Bigg Or Go Home IPA        3.66873\n",
       "8            Smilin' Mike        3.62981\n",
       "4           Useful Idiot         3.59771\n",
       "2                 Daayani        3.59000\n",
       "0          West Coast IPA        3.56235"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tens.iloc[90:100, :]\n",
    "t.reset_index()[['beer_name', 'rating_global']].sort_values('rating_global', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and how this user made the recommender look horrible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_name</th>\n",
       "      <th>rating_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Useful Idiot</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Go Bigg Or Go Home IPA</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West Coast IPA</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DJ Night</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daayani</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sigint</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Peconic Project</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wicked Smaht</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Smilin' Mike</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Citralization</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                beer_name  rating_user\n",
       "4           Useful Idiot          4.50\n",
       "5  Go Bigg Or Go Home IPA         4.25\n",
       "0          West Coast IPA         4.00\n",
       "1                DJ Night         4.00\n",
       "2                 Daayani         4.00\n",
       "3                  Sigint         4.00\n",
       "6         Peconic Project         4.00\n",
       "7            Wicked Smaht         4.00\n",
       "8            Smilin' Mike         4.00\n",
       "9           Citralization         4.00"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reset_index()[['beer_name', 'rating_user']].sort_values('rating_user', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommender's top 3 picks actually all tied for 3rd in the user's ratings...and for last."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, here's how the same system does for picking top 1 to top 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allscores = []\n",
    "for x in range(2,12):\n",
    "    scores = []\n",
    "    for u in tens.index.unique():\n",
    "        uten = tens.loc[u, ['rating_user','rating_global']]\n",
    "        scores.append(untied_rank(uten.rating_user.values, \n",
    "                    uten.rating_user.values[np.argsort(uten.rating_global.values)[:-x:-1]]))\n",
    "    allscores.append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd8FVX6x/HPNwkJvYN0Il2kg0pbe0FdxC6Iba2o2HZ1\n122/dVdd69pRdF1FBUVFXdFVsQJKUQi9995Beg05vz/mRMaYDjdzkzzv1yuv3DtzZua5596ZZ86Z\nJuccxhhjTEElRB2AMcaY4skSiDHGmEKxBGKMMaZQLIEYY4wpFEsgxhhjCsUSiDHGmEKxBFLCSBot\n6fqo4yiJJKVKcpKS4iCWnZKa5FEmx3glNfLzSIxdlD9b3jJJpxfFsoobSUMkPZDDuGskfVfUMeVX\nsUsg/oe4x//41/nKrxh1XMYUJedcRefcksOYfoWfx8EjGRfkvkE8QvN3kprFav4FFW/xFKVil0C8\n3s65ikAHoCPwx4jjKfbiYa86q3iMyZQupeU3WNjPWVwTCADOuXXAKIJEAoCkFEmPS1ohab2kwZLK\nhcb3kTRN0nZJiyX18sPrSRopaYukRZJuCE1zn6R3JQ2VtEPSTEktJP1R0gZJKyWdGSo/WtIDksb7\nltJHkmpIGuaXO0lSaqh8K0lf+GXPl3RpaNwQSYMk/c8v+3tJTUPjz5A0T9I2Sc8BCteRpGslzZX0\no6RRkhqHxjlJt0paCCzMro79517n5z9W0rGhceUk/UvScj/+u8y6ltTTf/6tvn6uCdXN9aF5/KyJ\nnl1Mkp7289guKU3Sr0LlEyX9yX+XO/z4hr7O/pXls4yUdFc2n/Hvkp71r8tI2iXpsdBn3CupemiS\n/v73tUnSn0PzSZB0r49ls6R3MqfToe6kq7ObNpuYhvjf7hf+c43J5rtrltf3kGWeFylowbdRlu4t\n/73cL2mcX97nkmqGpr3Kz3+zpL8qhy4pSTcC/YHfy//2Q6M7SJrhY3xbUtnQdL9WsF5u9b+bdjnU\ny1j/crqf/2V++A0K1tst/nuul6Wubpe0xNf7Y5Ky3fYpWNdHKFjXtwPXSDpe0gQf21pJz0lKziOe\nHD+PpI6Spvh6fhso+4tAfhGWnvP1Nk/SaaERVST9x8e1WsF2JzE0Pt/rvwJPKtimbVewnWuTa2TO\nuWL1BywDTvevGwAzgadD458ERgLVgUrAR8BDftzxwDbgDILkWR9o5ceNBZ73X2YHYCNwqh93H7AX\nOAtIAl4HlgJ/BsoANwBLQzGMBhYBTYEqwBxgAXB6aPpXfdkKwErgN35cR2AT0NqPHwJs9rEnAcOA\n4X5cTWAHcLGP4y4gHbjej+/j4zjGT/sXYHwoTgd84euqXA71fa2vxxTgKWBaaNwg/1nrA4lAd1+u\nsY+rn4+rBtAhVDfXh+ZxDfBdbjEBV/h5JAG/A9YBZf24e/xvoCVB8mzvyx4PrAESQnW1Gzgqm894\nKjDTv+4OLAa+D42b7l+n+vj+DZTzy9oHHOPH3wFMJPhdpgAvAm/lZ9psYhri6/BEP6+ns6mnZnl8\nD5nLTCL4fS0KTfPTuND3shho4eMbDTzsx7UGdgI9gWTgceAAfj3MIfYHsllvfwDq+e92LjDAj+sI\nbABO8PFf7cun5DD/nz576DvaBHTyn/tZYGyW8t/45TYiWBevz2He9/nPdj7BNqIc0Bno6usx1cd+\nZy7x5Ph5fP0tJ1hXyxCsuwey1leW9SM9VP4ygm1YdT/+A4LfWQWgtq/jmwqz/hNs39KAqgTr0jFA\n3Vy3x1EnhIL++S9iJ8HK5YCvgKp+nIBdQNNQ+W74jbuv6CezmWdD4CBQKTTsIWBI6Ef1RWhcbx9D\non9fyceSGcdo4M+h8v8CPs0y/TT/+jLg2yzxvAj8LbQyvhwadw4wz7++CpgYGidgFYcSyKfAdaHx\nCQQb0cahH9CpBaj7qn6aKn5ee4D22ZT7I/BBDvMYTd4JJNeYgB8zlwvMB/rkUG4ucIZ/PRD4JIdy\n5Qh2EGoA9wJ/8vVYEfg78Iwvl+rjaxCa9gegb2h5p4XG1SXYOCTlNW02MQ3B7yj49xX9b7RhqJ6a\n5fE9ZC7zboKdmAbZjAsnkL+Ext8CfOZf/x8+Efr35YH9FDyBXBF6/ygw2L9+Abg/S/n5wEk5zD/r\nBvs/wKNZ6uoAkBoq3yvLZ/sqh3nfRyj55FDmTkK/72ziyfHzEOwQrAEUGjc+a31lWT+ylv8BuBI4\nimAnpFxoXD/gG/+6QOs/QSJeQJAsE3Krg8y/4tqFdb5zrhJwMtCKYO8SoBbBjzvNNx23Ap/54RAk\nisXZzK8esMU5tyM0bDnBHl2m9aHXe4BN7tAByD3+f8Vcymd9n1m2MXBCZrw+5v5AnVD5daHXu0PT\n1iNovQDggl/BylDZxsDTofluIUgy4c8VLv8zCrqHHlbQJbOdYCMAQX3XJGitZVefOdVzfv0sJkl3\n+2b4Nv85qnDoO89tWa8RtF7w/9/IrpBzbg8wmUMr+BiClbqHHzYmyyQ5fR+NgQ9C9T2XYKN/VD6m\nzU74u91J8P3Vy1Imt+8h0z3AIOfcqlzK5BZb1t/ZboJWcUHlVm+/y7IONOSXnzUn9QjW18z4dvr4\ncvqdL89j3ll/fy0kfaygK3c78E8O/f6yk9vnqQes9utqOJ7cZFe+nl9OGWBtaDkvErREMuPI9/rv\nnPsaeI6gRbtB0kuSKucWWHFNIAA458YQ7O087gdtItg4H+ucq+r/qrjggDsEldX0l3NiDVBdUqXQ\nsEbA6thE/jMrgTGheKu64OyYm/Mx7VqCHyYQdJSG3/t535Rl3uWcc+NDZcI/zKwuJ2gGn06w0U7N\nXBRBXe8l+/rMqZ4haCGWD72vk02Zn2JScLzj98ClQDXnXFWCJnzmsZ7cljUU6COpPUFz/L85lIMg\nSZxK0P0wyb8/i6ArbGwu04WtBM7OUt9lnXOF/R2Fv9uKBF0Na7KUye17yHQm8BdJFxUyjrUE3XKZ\nsZQjaK3lJLffVHZWAg9mqbfyzrm38jn9GoKNZWZ8FXx84XoPrxeN+GU9hmWN/wVgHtDcOVeZoIWq\nX0x1SG6fZy1Q36+r4Xhyk135NX45+4CaoeVUds5lHqcs8PrvnHvGOdeZoNuyBcHOR46KdQLxngLO\nkNTeOZdB0Mf8pKTaAJLqSzrLl/0P8BtJpyk44FlfUivn3EqCPc6HJJX1B7yuI9gAxdrHQAtJVyo4\ngFtG0nGSjsnHtP8DjpV0oYKDobfz8w3yYOCP8ge+/QG3SwoQWyWCH+hmgo3+PzNH+Lp+BXhCwQkI\niZK6SUohOE5zuqRLJSUpOIEg80SHacCFksorOAh8XT5iSCc4JpUk6f+A8F7Ry8D9kpr7g4DtJNXw\nMa4iSAZvAO/5lkZOxhB0Cc5xzu3Hd7URdH9uzCPGTIOBBzMPVEqqJalPPqfNzjkKTkZIBu4n6K78\n2d5xHt9DptlAL2CQpPMKEccIoLek7j6W+8h9A7oeyPUalSz+DQyQdIL/DitIOjfLDl1u83+LYL3u\n4D/3PwmOYS0LlblHUjVJDQmOVb1dgPgqAduBnZJaAVl37rLGk9vnmUDwe77dr+sXEuyk5KZ2qPwl\nBDtDnzjn1gKfA/+SVNlv05pKOslPV6D13293TpBUhmBHby+QkVtgxT6B+JX7dYJ+WoA/EBw4muib\nm18SHGDFOfcDwcHEJwn2YsdwaM+lH8Ee9hqCA1N/c859WQTx7yDYQ+zrl70OeITggFte024CLgEe\nJtjINwfGhcZ/4Oc13NfFLODsAoT3OkFzeTVBH/rELOPvJjiAPYmgefwIQd/pCoJjNb/zw6cRHDSG\noO73E6x0rxEkm9yMIuiGXOBj2cvPuxieAN4hWJG2E+wkhM9Aeg1oSw7dVyHj/XSZrY05fln5bX1A\ncKB7JPC5pB0E9XVCAabP6k3gbwR12JlD3XFZZfs9hAs456YDvwb+LakgvwGcc7OB24DhBHvQOwkO\nEu/LYZL/AK1910lurb7M+U8mOBHlOYLjW4sI+v5zch/wmp//pX49/Svwno+vKcH6FPYhwQHiaQQ7\nXv/JK66Quwla4zsIkkPW5JM1nhw/j985udC/30JwDPT9PJb/PcG6vQl4ELjYOZfZhXgVwYH5OX5Z\nIwiOvRVm/a/sP9+PBOvaZuCx3ALTz7vWjClZJJ1I0JJs7IrRj13SEGCVc+4vUceSle9O20rQpbM0\n6njyIskRxLoo6lhKmmLfAjEmJ74pfgfBWWzFJnnEI0m9fbdjBYJjjjM5dFKFKaUsgZgSyR9D2krQ\nnH8q4nBKgj4EXaxrCLpT+lpSNtaFZYwxplCsBWKMMaZQStSNwmrWrOlSU1OjDsMYY4qNtLS0Tc65\nWnmX/KUSlUBSU1OZPHly1GEYY0yxISmvK+FzZF1YxhhjCsUSiDHGmEKxBGKMMaZQLIEYY4wpFEsg\nxhhjCsUSiDHGmEKxBGKMMaZQSn0CychwDPpmETNXbYs6FGOMKVZKfQLZsTedN79fwc3D0vhx1/6o\nwzHGmGKj1CeQKuXL8Hz/TmzYvo873p7GwQy7uaQxxuRHqU8gAO0bVuXvfY5l7IKNPP3lgqjDMcaY\nYsESiNf3uIZc2qUBz3y9iK/mro86HGOMiXuWQDxJ/KNPG9rUr8ydb09j2aZdUYdkjDFxzRJISNky\nibzQvzOJCWLA0DT27D8YdUjGGBO3LIFk0bB6eZ66rAPz1+/gTx/MxJ7YaIwx2bMEko2TW9bmrtNb\n8MHU1QydWOhb5RtjTIlmCSQHA09pxmmtavOPj+eQtvzHqMMxxpi4YwkkBwkJ4onLOlCvajluGZbG\nxh37og7JGGPiiiWQXFQpV4YX+ndm254D3PbWFNIPZkQdkjHGxA1LIHloXa8yD13YlolLtvDoqPlR\nh2OMMXHDEkg+XNCxAVd1a8xLY5fwycy1UYdjjDFxwRJIPv3l3NZ0bFSVe96dzqINO6IOxxhjImcJ\nJJ+SkxJ4vn8nyiUnctMbaezclx51SMYYEylLIAVQt0o5nu3XiWWbd/P7EdPtIkNjTKlmCaSAujWt\nwR96teSTmet4+dulUYdjjDGRsQRSCDf8qglnt6nDw5/NY8LizVGHY4wxkbAEUgiSeOyS9qTWKM9t\nb01h3ba9UYdkjDFFzhJIIVVMSeLFKzuzZ/9Bbh6Wxv50u8jQGFO6WAI5DM1qV+KxS9ozdcVWHvjf\nnKjDMcaYImUJ5DCd07YuN57YhNcnLOf9KauiDscYY4qMJZAj4PdntaRrk+r86YOZzFmzPepwjDGm\nSFgCOQKSEhN4tl8nqpQrw4ChaWzbfSDqkIwxJuYsgRwhtSql8Hz/zqzdtoffvjONjAy7yNAYU7JZ\nAjmCOjeuxl9/3Zqv5m1g0DeLog7HGGNiyhLIEXZl18Zc0LE+T3y5gDELNkYdjjHGxIwlkCNMEv+8\noC0tj6rEHcOnsnLL7qhDMsaYmIhpApHUS9J8SYsk3ZvN+HskTfN/syQdlFTdj7tL0mw//C1JZWMZ\n65FULjmRwVd05mCG4+Zhaew9cDDqkIwx5oiLWQKRlAgMAs4GWgP9JLUOl3HOPeac6+Cc6wD8ERjj\nnNsiqT5wO9DFOdcGSAT6xirWWEitWYGnLuvArNXb+et/Z9mde40xJU4sWyDHA4ucc0ucc/uB4UCf\nXMr3A94KvU8CyklKAsoDa2IWaYycdsxR3H5qM95NW8XwSSujDscYY46oWCaQ+kB4q7nKD/sFSeWB\nXsB7AM651cDjwApgLbDNOfd5DGONmTtOb8GJLWrxtw9nM33l1qjDMcaYIyZeDqL3BsY557YASKpG\n0Fo5GqgHVJB0RXYTSrpR0mRJkzdujL+znhITxNOXdaBWpRRuHprGll37ow7JGGOOiFgmkNVAw9D7\nBn5Ydvry8+6r04GlzrmNzrkDwPtA9+wmdM695Jzr4pzrUqtWrSMQ9pFXrUIyg6/ozKZd+7n9rakc\ntIsMjTElQCwTyCSguaSjJSUTJImRWQtJqgKcBHwYGrwC6CqpvCQBpwFzYxhrzLVtUIUH+rThu0Wb\neOKL+VGHY4wxhy1mCcQ5lw4MBEYRbPzfcc7NljRA0oBQ0QuAz51zu0LTfg+MAKYAM32cL8Uq1qJy\n6XEN6Xd8QwZ9s5jPZ6+LOhxjjDksKkmnl3bp0sVNnjw56jBytffAQS59cQJLN+5i5G09ObpmhahD\nMsaUYpLSnHNdCjNtvBxELzXKlknk+f6dSEoUA95IY/f+9KhDMsaYQrEEEoEG1crzTL+OLNiwg3vf\nm2kXGRpjiiVLIBH5VfNa3H1mS0ZOX8OQ8cuiDscYYwrMEkiEbj6pKacfcxQP/m8uk5ZtiTocY4wp\nEEsgEUpIEP+6tD0NqpXjlmFT2LB9b9QhGWNMvlkCiViVcmUYfGVndu5NZ+CbUzlwMCPqkIwxJl8s\ngcSBVnUq8/BFbflh2RYe+mRe1OEYY0y+WAKJE3061Oea7qm8Mm4pI6cXuxsPG2NKIUsgceRP5xxD\nl8bV+MOIGSxYvyPqcIwxJleWQOJIclICg/p3omLZJAa8kcb2vQeiDskYY3JkCSTOHFW5LIMu78Ty\nLbu5+53pdpGhMSZuWQKJQ8cfXZ0/nXMMn89ZzwtjFkcdjjHGZMsSSJy6tkcqv25Xl8dHzee7hZui\nDscYY37BEkicksQjF7WjWe2K3D58Kqu37ok6JGOM+RlLIHGsQkoSg6/ozP70DG4Zmsa+9INRh2SM\nMT+xBBLnmtSqyOOXtGf6qm3cN3JO1OEYY8xPLIEUA73a1OHmk5vy1g8reGfSyqjDMcYYwBJIsfG7\nM1rQo1kN/vLhLGat3hZ1OMYYYwmkuEhKTOCZvh2pWSGZAUPT+HHX/qhDMsaUcpZAipEaFVN4/orO\nbNi+jzvensbBDLvI0BgTHUsgxUyHhlW577xjGbtgI09/uSDqcIwxpZglkGKo3/ENuaRzA575ehFf\nzV0fdTjGmFLKEkgxJIn7z29Dm/qVufPtaSzbtCvqkIwxpZAlkGKqbJlEXujfmcQEMWBoGnv220WG\nxpiiZQmkGGtYvTxPXdaB+et38KcPZtqde40xRcoSSDF3csva3HV6Cz6Yupo3Ji6POhxjTCliCaQE\nGHhKM05rVZt/fDSHtOVbog7HGFNKWAIpARISxBOXdaB+tXLcMmwKG3bsjTokY0wpYAmkhKhSrgwv\n9O/Mtj0HGPjmVA4czIg6JGNMCWcJpARpXa8yD13Ylh+WbuHRz+ZFHY4xpoSzBFLCXNCxAVd3a8y/\nv13K/2asjTocY0wJZgmkBPrzua3p1Kgq94yYzsL1O6IOxxhTQlkCKYGSkxJ4vn9nyicnctPQNHbs\nPRB1SMaYEiimCURSL0nzJS2SdG824++RNM3/zZJ0UFJ1P66qpBGS5kmaK6lbLGMtaepUKctzl3di\n+ebd3PPuDLvI0BhzxMUsgUhKBAYBZwOtgX6SWofLOOcec851cM51AP4IjHHOZV7I8DTwmXOuFdAe\nmBurWEuqrk1q8MezW/HZ7HW8NHZJ1OEYY0qYWLZAjgcWOeeWOOf2A8OBPrmU7we8BSCpCnAi8B8A\n59x+59zWGMZaYl3X82jObVuXRz6bx/hFm6IOxxhTgsQygdQHwg/wXuWH/YKk8kAv4D0/6GhgI/Cq\npKmSXpZUIYdpb5Q0WdLkjRs3HrnoSwhJPHJxO5rUqshtb01lzdY9UYdkjCkh4uUgem9gXKj7Kgno\nBLzgnOsI7AJ+cQwFwDn3knOui3OuS61atYom2mKmYkoSg6/ozL70DG4ZNoV96XbnXmPM4YtlAlkN\nNAy9b+CHZacvvvvKWwWscs5979+PIEgoppCa1a7I45e0Y9rKrdz/8ZyowzHGlACxTCCTgOaSjpaU\nTJAkRmYt5I93nAR8mDnMObcOWCmppR90GmBbvcPUq01dbjqpCUMnrmBE2qqowzHGFHNJsZqxcy5d\n0kBgFJAIvOKcmy1pgB8/2Be9APjcOZf1sXq3AcN88lkC/CZWsZYm95zZkhkrt/HnD2bSqk4l2tSv\nEnVIxphiSiXp+oAuXbq4yZMnRx1G3Nu0cx+9n/2OpETx0cCeVC2fHHVIxpiISEpzznUpzLR5dmFJ\nuk1StcLM3MSnmhVTeL5/J9Zt28udb08jI6Pk7EQYY4pOfo6BHAVMkvSOv7JcsQ7KxF7HRtX4W+9j\nGT1/I09/tTDqcIwxxVCeCcQ59xegOcFFfdcACyX9U1LTGMdmYqz/CY24qFMDnv5qIV/PWx91OMaY\nYiZfZ2G54EDJOv+XDlQDRkh6NIaxmRiTxIMXtKF13crcOXwaKzbvjjokY0wxkp9jIHdISgMeBcYB\nbZ1zNwOdgYtiHJ+JsbJlEhl8RWckcdPQNPbst4sMjTH5k58WSHXgQufcWc65d51zBwCccxnAr2Ma\nnSkSjWqU56m+HZi3bjt//u9Mu3OvMSZf8pNAPgUybzGCpMqSTgBwztkdckuIU1rW5o7TmvP+lNUM\n/X5F1OEYY4qB/CSQF4Cdofc7/TBTwtx+anNOaVmLf3w0m3+PXcJBO73XGJOL/CQQuVCfhu+6itkV\n7CY6CQniqb4dOalFbR78ZC4XDx7Pog07857QGFMq5SeBLJF0u6Qy/u8OgluLmBKoSrky/Puqzjzd\ntwNLN+3inGe+ZfCYxaQfzIg6NGNMnMlPAhkAdCe4k+4q4ATgxlgGZaIliT4d6vP5XSdySstaPPzp\nPC4aPIGF63dEHZoxJo7YvbBMrpxzfDxjLf/34Sx27TvIHac356YTm5CUGC+PkjHGHI7DuRdWnscy\nJJUFrgOOBcpmDnfOXVuYBZriRRK929ejW9Ma/N+Hs3hs1HxGzV7HYxe3p2WdSlGHZ4yJUH52I98A\n6gBnAWMIHgxlfRmlTHADxs4MurwTq3/cw6+f/Zbnvl7IATs2YkyplZ8E0sw591dgl3PuNeBcguMg\nphQ6t11dPr/rRM46tg6Pf76A8weNY+7a7VGHZYyJQH4SyAH/f6ukNkAVoHbsQjLxrkbFFJ67vBMv\n9O/E+u176f3sdzz15QL2p1trxJjSJD8J5CX/PJC/EDySdg7wSEyjMsXC2W3r8vldJ3Fuu7o89eVC\n+gwax+w126IOyxhTRHJNIJISgO3OuR+dc2Odc02cc7Wdcy8WUXwmzlWvkMzTfTvy4pWd2bhjH32e\nG8cTX1hrxJjSINcE4q86/30RxWKKsbOOrcOXvz2R3u3r8cxXCznvue+YtdpaI8aUZPnpwvpS0t2S\nGkqqnvkX88hMsVO1fDJPXtaBl6/qwpZd++kzaByPj5rPvnS7RbwxJVGeFxJKWprNYOecaxKbkArP\nLiSMH9t2H+D+/81hRNoqWhxVkccvaU+7BlWjDssYk8XhXEiYn0faHp3NX9wlDxNfqpQvw+OXtOfV\na45j+550Lnh+PI98No+9B6w1YkxJkZ8WyFXZDXfOvR6TiA6DtUDi07Y9B3jwf3N4Z/IqmtWuyGMX\nt6Njo2pRh2WMIcYtEOC40N+vgPuA8wqzMFM6VSlXhkcvbs+Q3xzHrn3pXPTCeB76ZK61Rowp5gp8\nM0VJVYHhzrlesQmp8KwFEv+27z3AQ5/M5a0fVtKkVgUeu7g9nRtba8SYqMS6BZLVLuDowizMmMpl\ny/DQhe14/drj2Xcgg4sHj+eBj+ewZ7+1RowpbvJzN96PgMxmSgLQGngnlkGZku/EFrX47M5f8fCn\n83j5u6V8NW8Dj17cjuNS7QxxY4qL/BxEPyn0Nh1Y7pxbFdOoCsm6sIqncYs28fsRM1izbQ+/6X40\n95zVknLJiVGHZUypEOsurBXA9865Mc65ccBmSamFWZgx2enRrCaj7jqRK05ozCvjltLr6bF8v2Rz\n1GEZY/KQnwTyLhC+sdFBP8yYI6ZiShL3n9+GN284gQznuOylifz9o9l2Ty1j4lh+EkiSc25/5hv/\nOjl2IZnSrHvTmnx2x4lc3a0xr45bxhUvf8+mnfuiDssYk438JJCNkn667kNSH2BT7EIypV2FlCT+\n3qcNT/ftwPRVW+nznN0m3ph4lJ8EMgD4k6QVklYAfwBuim1YxkCfDvUZMaA7Gc5x0Qvj+XjGmqhD\nMsaE5OdeWIudc10JTt9t7Zzr7pxblJ+ZS+olab6kRZLuzWb8PZKm+b9Zkg6G7/QrKVHSVEkfF+RD\nmZKjbYMqjBzYk2PrVWHgm1N5fNR8MjIKdvGrMSY28kwgkv4pqapzbqdzbqekapIeyMd0icAg4GyC\n5NNPUutwGefcY865Ds65DsAfgTHOuS2hIncAcwvygUzJU6tSCm/ecAKXdWnIc98s4sY30tix90De\nExpjYio/XVhnO+e2Zr5xzv0InJOP6Y4HFjnnlvgD78OBPrmU7we8lflGUgPgXODlfCzLlHApSYk8\nfFFb7uvdmm/mb+DC58ezfPOuqMMyplTLTwJJlJSS+UZSOSAll/KZ6gMrQ+9X+WG/IKk80At4LzT4\nKYKnIeZ6HqekGyVNljR548aN+QjLFFeSuKbH0bx+7fFs3LmP854bx3cL7XwOY6KSnwQyDPhK0nWS\nrge+AF47wnH0BsZldl9J+jWwwTmXlteEzrmXnHNdnHNdatWqdYTDMvGoR7OajLy1J0dVTuHqV3/g\n1XFLKehNQY0xhy8/B9EfAR4AjgFaAqOAxvmY92qgYeh9Az8sO30JdV8BPYDzJC0j6Po6VdLQfCzT\nlBKNapTn/Vt6cGqr2vz9ozn84b0Z9uhcY4pYfu/Gu57ghoqXAKeSvwPbk4Dmko6WlEyQJEZmLSSp\nCnAS8GHmMOfcH51zDZxzqX66r51zV+QzVlNKVExJ4sUrOnP7qc14Z/Iq+r00kQ079kYdljGlRo4J\nRFILSX+TNA94luCeWHLOneKcey6vGTvn0oGBBC2WucA7zrnZkgZIGhAqegHwuXPOjoiaAktIEL89\nsyWDLu/E3LU7OO/ZccxYtTXvCY0xhy3Hu/FKygC+Ba7LvO5D0pJ4fh663Y23dJu9Zhs3vp7Gpp37\nePTidvTpkO05G8aYkFjdjfdCYC3wjaR/SzoNUGEWYkxROLZeFUYO7EH7hlW5Y/g0Hvp0LgftokNj\nYibHBOKRd9D+AAAXF0lEQVSc+69zri/QCvgGuBOoLekFSWcWVYDGFESNiikMve4E+p/QiBfHLOH6\n1yax3S46NCYm8nMW1i7n3JvOud4EZ1JNJbgfljFxKTkpgQcvaMsD57fh24WbOH/QOJZs3Bl1WMaU\nOAV6Jrpz7kd/3cVpsQrImCPliq6NGXr9CWzdfYA+g8Yxev6GqEMypkQpUAIxprjp2qQGH97ag/pV\ny3HtkEn8e+wSu+jQmCPEEogp8RpWL8/7t3SnV5s6PPjJXH73znT2HrCLDo05XJZATKlQPjmJQZd3\n4rdntOD9qau57KWJrN9uFx0aczgsgZhSQxK3n9acF6/szKL1O+j97HdMXfFj1GEZU2xZAjGlzlnH\n1uH9W3qQUiaBy16ayHtpq6IOyZhiyRKIKZVa1qnEyFt70qVxNX737nQe+HgO6QdzfXKAMSYLSyCm\n1KpWIZnXrj2ea7qn8vJ3S/nNkEls220XHRqTX5ZATKlWJjGB+847locvbMvEJZs5//lxLNqwI+qw\njCkWLIEYA/Q9vhFv3dCVHXsPcP6g8Xw9b33UIRkT9yyBGON1Sa3OhwN7klqzPNe9NpnnRy+yiw6N\nyYUlEGNC6lctx7s3defX7erx6GfzuWP4NPbst4sOjclOUtQBGBNvyiUn8kzfDrSqU4nHP5/PrNXb\nGHByU87vUJ/kJNvnMiaTrQ3GZEMSt57SjCG/OZ6yZRL5/YgZnPjoN/x77BJ27kuPOjxj4kKOTyQs\njuyJhCYWnHOMXbiJF0YvYuKSLVQum8RV3VK5pkcqNSumRB2eMYflcJ5IaAnEmAKYtnIrg0cvZtSc\ndSQnJnBpl4bc8KsmNKpRPurQjCkUSyCeJRBTVBZv3MlLY5bw/tRVHMxw/LpdPQac1JTW9SpHHZox\nBWIJxLMEYoraum17eWXcUoZNXM6u/Qc5sUUtbj6pKV2bVEdS1OEZkydLIJ4lEBOVbbsPMPT75bw6\nbimbdu6nfcOq3HxSU85sfRQJCZZITPyyBOJZAjFR23vgICPSVvHS2CWs2LKbJrUqcNOJTTi/Y31S\nkhKjDs+YX7AE4lkCMfEi/WAGn85ax+Axi5m9ZjtHVU7hup5H0+/4RlQqWybq8Iz5iSUQzxKIiTfO\nOb5duInBYxYzfvFmKpVN4qpujbmm+9HUqmSnAJvoWQLxLIGYeDZ95VYGj1nMZ7PXUSYxgUu7NODG\nXzW1U4BNpCyBeJZATHGwZONOXhq7hPenrCY9I4Nz2tZlwElNaVO/StShmVLIEohnCcQUJ+u3Z54C\nvIKd+9L5VfOa3HxyU7o1qWGnAJsiYwnEswRiiqNtew4w7PvlvPLdMjbt3Ef7BlW4+eSmnNG6Dol2\nCrCJMUsgniUQU5ztPXCQ96YEpwAv37ybJjUrcOOJTbigk50CbGLHEohnCcSUBAczHJ/OWsvgMYuZ\ntXo7tSsFpwD379qYiin2BAZzZFkC8SyBmJLEOce4RZt5Ycwixi3aTN0qZXnowrac3LJ21KGZEuRw\nEog9D8SYOCWJns1rMuz6rrx3czcqpCRxzauT+P2I6WzbcyDq8IyJbQKR1EvSfEmLJN2bzfh7JE3z\nf7MkHZRUXVJDSd9ImiNptqQ7YhmnMfGuc+PqfHxbT245uSkj0lZx1pNj+WbehqjDMqVczLqwJCUC\nC4AzgFXAJKCfc25ODuV7A3c5506VVBeo65ybIqkSkAacn9O0mawLy5QG01du5Z4R01mwficXd27A\nX89tTZXydnsUUzjx2oV1PLDIObfEObcfGA70yaV8P+AtAOfcWufcFP96BzAXqB/DWI0pNto3rMpH\nt/Xk1lOa8sHU1Zz51Bi+nrc+6rBMKRTLBFIfWBl6v4ockoCk8kAv4L1sxqUCHYHvc5j2RkmTJU3e\nuHHjYYZsTPGQkpTIPWe14r+39KBquWSuHTKZ374zjW277diIKTrxchC9NzDOObclPFBSRYKkcqdz\nbnt2EzrnXnLOdXHOdalVq1YRhGpM/GjboAojb+vBbac248NpazjjyTF8OcdaI6ZoxDKBrAYaht43\n8MOy0xfffZVJUhmC5DHMOfd+TCI0pgRISUrkd2e25MNbe1C9QjLXvz6Zu96extbd+6MOzZRwsUwg\nk4Dmko6WlEyQJEZmLSSpCnAS8GFomID/AHOdc0/EMEZjSow29aswcmBPbj+tOR9NX8MZT47lC2uN\nmBiKWQJxzqUDA4FRBAfB33HOzZY0QNKAUNELgM+dc7tCw3oAVwKnhk7zPSdWsRpTUiQnJfDbM1rw\n31t7ULNiCje8Ppk7h0/lx13WGjFHnl2JbkwJtT89g+dHL+K5rxdRtXwyD17QhrOOrRN1WCbOxOtp\nvMaYCCUnJXDn6S0YObAntSulcNMbadz+1lS2WGvEHCGWQIwp4VrXq8yHA3vw2zNa8OmstZz55Bg+\nm7U26rBMCWAJxJhSoExiAref1pyRA3tSp0pZBgydwsA3p7B5576oQzPFmCUQY0qRY+pW5oNbenD3\nmS0YNXsdZz45lk9mWmvEFI4lEGNKmTKJCQw8tTkf3daTelXLccuwKdw6bAqbrDViCsgSiDGlVKs6\nlfnglu7cc1ZLvpiznjOfHMvHM9ZEHZYpRiyBGFOKJSUmcOspzfj49p40rFaOgW9O5eahaWzcYa0R\nkzdLIMYYWhxVifdu7s4ferXiq7kbOPPJMYycvoaSdJ2YOfIsgRhjgKA1cvPJTfnf7T1pVKMCt781\nlZuHTrHWiMmRJRBjzM80P6oS7w3oxr1nt+Lr+Rs448kxfDhttbVGzC9YAjHG/EJSYgIDTmrKJ7f3\nJLVGBe4YPo2b3khjw469UYdm4oglEGNMjprVDo6N/OmcVoxZsJEznhjLC6MX280ZDWA3UzTG5NPi\njTv524ez+W7RJlKSEujToR5XdUulTf0qUYdmDsPh3EzREogxpkAWrN/Ba+OX8f6U1ew5cJAujatx\nVfdUzm5ThzKJ1qlR3FgC8SyBGFN0tu05wIi0Vbw+YRnLN++mdqUULj+hEZef0IjalcpGHZ7JJ0sg\nniUQY4peRoZjzIKNvDZhGaPnb6RMojinbV2u6pZKp0ZVCR4wauLV4SSQpCMdjDGmdElIEKe0qs0p\nrWqzdNMu3piwnHcnr+TDaWtoW78KV3VrTO/29ShbJjHqUM0RZi0QY8wRt2tfOu9PXc3r45excMNO\nqldIpu9xDenftTH1q5aLOjwTYl1YniUQY+KLc44Jizfz2oRlfDFnPQBntq7DVd0b061JDeveigPW\nhWWMiUuS6N6sJt2b1WTVj7sZOnEFwyet4LPZ62h5VCWu6t6YCzrWp3yybYqKI2uBGGOK1N4DBxk5\nfQ2vjV/G7DXbqVQ2iUu7NOTKro1JrVkh6vBKHevC8iyBGFN8OOeYsuJHhoxfzqcz13LQOU5uUYur\nu6dyYvNaJCRY91ZRsATiWQIxpnjasH0vw75fwZs/rGDjjn0cXbMCV3ZtzMVdGlC5bJmowyvRLIF4\nlkCMKd72p2fw6ay1vDZ+GVNWbKV8ciIXdqrP1d1SaX5UpajDK5EsgXiWQIwpOWau2sZrE5Yxcvoa\n9qdn0L1pDa7unsrpxxxFonVvHTGWQDxLIMaUPJt37uPtySsZOmE5a7btpX7VcvTv2ojTjzmK5rUr\n2qnAh8kSiGcJxJiSK/1gBl/OXc9r45czYclmAGpWTOaEJjXo2qQG3ZrUoGmtCpZQCsiuAzHGlHhJ\niQn0alOXXm3qsnLLbiYs3syEJZuZsHgz/5uxFoDalVLomplQmtYgtUZ5SygxZAnEGFPsNKxenobV\ny3PpcQ1xzrFs824m+mQyYclmRk5fA0CdymXp1rQGXZtUp1uTmjSsXs4SyhFkXVjGmBLFOcfijbuC\nhLJkM98v2cymncETFOtXLfdT66Rrk+o0qFY+4mijZ8dAPEsgxpisnHMs3LDzpxbKxCWb+XH3AQAa\nVi9HN59QujWpSZ0qpe85JpZAPEsgxpi8ZGQ45q/f8VNC+X7pFrbtCRJKao3yvnUSHJSvXbnkJ5S4\nTSCSegFPA4nAy865h7OMvwfo798mAccAtZxzW/KaNjuWQIwxBXUwwzF37XYmLglaJ98v3cKOvekA\nNKlV4acWStcmNahZMSXiaI+8uEwgkhKBBcAZwCpgEtDPOTcnh/K9gbucc6cWdNpMlkCMMYfrYIZj\n9pptP7VQJi37kZ37goTSvHZF391VgxOa1KB6heSIoz188Xoa7/HAIufcEgBJw4E+QE5JoB/wViGn\nNcaYIyIxQbRrUJV2Dapy44lNST+YwczV25iwZDMTl2zxz4FfDkDjGuVJTkyIOGKoVj6ZdwZ0K/Ll\nxjKB1AdWht6vAk7IrqCk8kAvYGAhpr0RuBGgUaNGhxexMcZkkZSYQMdG1ejYqBq3nAwHDmYwY9VW\nJi7Zwpy124mH48hR3XAyXq4D6Q2Mc85tKeiEzrmXgJcg6MI60oEZY0xYmcQEOjeuTufG1aMOJXKx\nbHutBhqG3jfww7LTl0PdVwWd1hhjTARimUAmAc0lHS0pmSBJjMxaSFIV4CTgw4JOa4wxJjox68Jy\nzqVLGgiMIjgV9xXn3GxJA/z4wb7oBcDnzrldeU0bq1iNMcYUnF1IaIwxpdjhnMYb/flnxhhjiiVL\nIMYYYwrFEogxxphCsQRijDGmUErUQXRJG4HlUcdxmGoCm6IOIk5YXfyc1cfPWX0ccjh10dg5V6sw\nE5aoBFISSJpc2DMiShqri5+z+vg5q49DoqoL68IyxhhTKJZAjDHGFIolkPjzUtQBxBGri5+z+vg5\nq49DIqkLOwZijDGmUKwFYowxplAsgRhjjCkUSyBxQFJDSd9ImiNptqQ7oo4papISJU2V9HHUsURN\nUlVJIyTNkzRXUtE/uzSOSLrLryezJL0lqWzUMRUlSa9I2iBpVmhYdUlfSFro/1crilgsgcSHdOB3\nzrnWQFfgVkmtI44pancAc6MOIk48DXzmnGsFtKcU14uk+sDtQBfnXBuCxz30jTaqIjeE4BHgYfcC\nXznnmgNf+fcxZwkkDjjn1jrnpvjXOwg2EPWjjSo6khoA5wIvRx1L1PwD104E/gPgnNvvnNsabVSR\nSwLKSUoCygNrIo6nSDnnxgJZH//dB3jNv34NOL8oYrEEEmckpQIdge+jjSRSTwG/BzKiDiQOHA1s\nBF71XXovS6oQdVBRcc6tBh4HVgBrgW3Ouc+jjSouHOWcW+tfrwOOKoqFWgKJI5IqAu8Bdzrntkcd\nTxQk/RrY4JxLizqWOJEEdAJecM51BHZRRN0T8cj37fchSKz1gAqSrog2qvjigmsziuT6DEsgcUJS\nGYLkMcw5937U8USoB3CepGXAcOBUSUOjDSlSq4BVzrnMFukIgoRSWp0OLHXObXTOHQDeB7pHHFM8\nWC+pLoD/v6EoFmoJJA5IEkEf91zn3BNRxxMl59wfnXMNnHOpBAdHv3bOldo9TOfcOmClpJZ+0GnA\nnAhDitoKoKuk8n69OY1SfFJByEjgav/6auDDolioJZD40AO4kmBve5r/OyfqoEzcuA0YJmkG0AH4\nZ8TxRMa3xEYAU4CZBNuwUnVLE0lvAROAlpJWSboOeBg4Q9JCglbaw0USi93KxBhjTGFYC8QYY0yh\nWAIxxhhTKJZAjDHGFIolEGOMMYViCcQYY0yhWAIpISQ5Sf8Kvb9b0n1HaN5DJF18JOaVx3Iu8Xeb\n/SbL8HqSRvjXHewU5yNL0skFveuxpNGSuhyhZRfoQkBJKZK+9Ke7X5Zl3DWS6h1uXCZ/LIGUHPuA\nCyXVjDqQMH/Du/y6DrjBOXdKeKBzbo1zLjOBdQAiSSAF/Cwmf06m4FeSdwRwznVwzr2dZdw1BLc4\nMUXAEkjJkU5wQdVdWUdkbUFI2un/nyxpjKQPJS2R9LCk/pJ+kDRTUtPQbE6XNFnSAn+/qsxndjwm\naZKkGZJuCs33W0kjyeaqaUn9/PxnSXrED/s/oCfwH0mPZSmf6ssmA/8ALsvc+5RUwT8f4Qd/s8E+\nfpprJP3XPxthmaSBkn7ry0yUVN2Xu13Bc1hmSBqeTazXSBop6WuC22Qj6Z7QZ/57qOxVfth0SW+E\nYv/aD/9KUqPQd/KCj2WJr7NXfAtsSPi78nU82+91H+/3/pdIOi8f38NoHXqWyDBJ8uN6+WFTgAtD\ny8upPstJGu7j+wAol7WufLnT/HQz/XxS/PBlmTs3krr4uFKBAcBd/vv8VZZ5Vfff4QxfT+0k1QaG\nAsf5aZqGyl8MdCG46HKaj7mzgt94mqRROnS7j9GSHvGfc0HWZZt8cs7ZXwn4A3YClYFlQBXgbuA+\nP24IcHG4rP9/MrAVqAukAKuBv/txdwBPhab/jGCHoznB/ZnKAjcCf/FlUoDJBDe5O5ngpn9HZxNn\nPYLbUdQiuFHg18D5ftxoguc8ZJ0mFZjlX18DPBca90/gCv+6KrAAqODLLQIq+WVtAwb4ck8S3LAS\ngluBp2ROn82yr/Gft7p/fyZBopavj48Jbrd+rF92TV8us/xHwNX+9bXAf0N1OtzPpw+wHWjr55kG\ndPDlHHC2f/0B8DlQhuC5INP88Ny+h21AAz/fCQRJuiyw0n+XAt4BPs6jPn8LvOKHtyPYYemSpa4y\n59vCv389VM/LQnXTBRjtX98H3J3Db/pZ4G/+9amhz3tyZrzZTDM6My5fT+OBWv79ZaHPMBr4l399\nDvBl1OtwcfyzJnkJ4pzbLul1ggfu7MnnZJOcvw20pMUEGygIbhMR7kp6xzmXASyUtARoRbAxbadD\nrZsqBBul/cAPzrml2SzvOIKNx0a/zGEEG+D/5jPerM4kuPni3f59WaCRf/2NC56vskPSNoKNeeZn\na+dfzyDYY/1vLjF84ZzLfP7Cmf5vqn9fkeAztwfedc5tAgiV78ahPfw3gEdD8/3IOeckzQTWO+dm\nAkiaTZA0pxHU5WehuPc55w74aVJDMeX2Pazy853mp9lJcEPChX74UIIklDmv7OrzROAZ/9lmKLit\nSlYt/XwX+PevAbcS3J6/MHoCF/llfi2phqTKBZi+JdAG+MI3vBIJbgGfKfOmpWkcqktTAJZASp6n\nCO4T9GpoWDq+u1JSApAcGrcv9Doj9D6Dn/8+st7zxhHsvd7mnBsVHiHpZIIWSFEQcJFzbn6WGE4g\nf5/tXIKNY2/gz5LaOufSsywj/FkEPOScezHL8m4rROzheLLGmhnfAed3k8PlnHMZOnRMJrfvITzf\ng+S9zudUn3l+mDz89BskSEpFQcBs51xOjwDOrJv81IvJhh0DKWH8nu87BAekMy0DOvvX5xE07Qvq\nEkkJvs+5CTAfGAXcrOBW9EhqobwfdvQDcJKkmpISgX7AmALEsYOgWyrTKOC2UN9+x/zOyCfThs65\nb4A/EOy5V8xjslHAtQqe3YKk+r5f/muCOqrhh1f35cdz6JGr/YFv8xtfART0e5gHpIaOH/TLMq/s\n6nMscLkf1oZDLbiw+X6+zfz7Kzn03S7j0G/wotA0Wb/PsG8J6iwzGW5yeT8nJzy/+UAt+WfISyoj\n6dg8pjcFYAmkZPoXED4b698EG+3pBF0qhWkdrCDY+H9KcCxhL8EjZ+cAUyTNAl4kjz053112L/AN\nMB1Ic84V5NbT3wCtdegUzvsJEuIM3/VzfwHmlQgM9d1BU4FnXB6Pi3XB0+/eBCb46UYAlZxzs4EH\ngTG+njNvy38b8Bvf5XMlwbGlI61A34P/7m4E/ucPooefHZFTfb4AVJQ0l+BEhl888MvP9zfAu75u\nMoDBfvTfgaclTSbY48/0EXBBdgfRCY6PdPZ19zCHbleemyHAYN9dlwhcDDziv5Np2LNDjii7G68x\nxphCsRaIMcaYQrEEYowxplAsgRhjjCkUSyDGGGMKxRKIMcaYQrEEYowxplAsgRhjjCmU/wdOX0Ri\n9IeGrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1199e2278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,11), allscores)\n",
    "plt.title('Recommender accuracy when picking the top rated beers')\n",
    "plt.xlabel('Number of items recommended out of ten')\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check that random picks score about 0.5 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for randomly choosing 3 beers off the menu: 0.5341473444293866\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for u in tens.index.unique():\n",
    "    uten = tens.loc[u, ['rating_user','rating_global']]\n",
    "    scores.append(untied_rank(uten.rating_user.values, \n",
    "                    uten.rating_user.values[np.random.permutation(range(10))[:3]]))\n",
    "print(f'Accuracy for randomly choosing 3 beers off the menu: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now what about if we don't even have any global ratings for a beer?  This could be for a new beer, or maybe a brewer is trying to figure out what beer to brew in order to get good ratings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our main weapons here will be the one numerical feature that tends to correlate to ratings most, and the words comprising the brewery name, the beer name, and the beer description, as provided by the brewery.  The numerical feature is the alcohol by volume (abv) and we'll train a Linear Regressor on that plus a binary vector encoding of the words we have for each beer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set the `max_df` threshold (the highest ratio of descriptions a word can appear in before it is dropped for being considered not informative enough to keep making noise) to 0.17 -- That was the divider that just barely keeps 'hop' and 'dry' but not 'brewed' and 'ale'.  \n",
    "I also made the term vectors binary, since the goal is to identify keywords that correlate to ratings, not to classify the text as belonging to some category.  This makes the relative importance of the words easier to interpret after training, too.  If the word \"hoppy\" appears 3 times in one description, it doesn't seem like it should drive down the word's weight for all the beers whose descriptions have it only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the beer and brewery names to the description\n",
    "checkins['beer_description'] = checkins.brewery_name + ' ' + checkins.beer_name + ' ' + checkins.beer_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkin_id</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>821797539</td>\n",
       "      <td>2095023</td>\n",
       "      <td>3340203</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Stone Brewing Stone Scorpion Bowl IPA To creat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   checkin_id  beer_id  user_id  rating_user   brewery_name  \\\n",
       "0   821797539  2095023  3340203         3.75  Stone Brewing   \n",
       "\n",
       "                 beer_name      beer_style  rating_global  abv  \\\n",
       "0  Stone Scorpion Bowl IPA  IPA - American        3.73789  7.5   \n",
       "\n",
       "                                    beer_description  \n",
       "0  Stone Brewing Stone Scorpion Bowl IPA To creat...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87017, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize just one of each beer description, to not skew document frequency\n",
    "uniqs = checkins[['beer_id', 'beer_description']].drop_duplicates(subset=['beer_id'])\n",
    "uniqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87017, 20133)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english', min_df=5, max_df=0.17, binary=True)\n",
    "vecs = cv.fit_transform(uniqs.beer_description)\n",
    "vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're dealing with sparse matrices, so we'll need some scipy help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "# get the abv and global mean for each unique beer, to align with the term vectors for training\n",
    "uniqs['abv'] = uniqs.beer_id.map(checkins.groupby('beer_id')['abv'].mean())\n",
    "uniqs['rating_global'] = uniqs.beer_id.map(checkins.groupby('beer_id')['rating_global'].mean())\n",
    "# tack the abvs onto the vecs, after scaling them down to around the binary 1's\n",
    "vecs = hstack([vecs, uniqs.abv.values[:, np.newaxis] / 5.0])  # need the new axis for hstack\n",
    "vecs = csr_matrix(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87017, 20134)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at how the global ratings are distributed, just to know how random guessing would do for predicting ratings for a new beer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEKCAYAAAAxXHOuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyoHFzMyycmAxM7Os/j9WCJRpB376qgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1174e3208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ignore the couple of ratings that are outliers to the downside, for clarity in the chart\n",
    "uniqs[uniqs.rating_global > 2.4].rating_global.plot(kind='hist', bins=20, color='darkgreen')\n",
    "plt.xlabel('global mean rating by beer')\n",
    "plt.ylabel('count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a normal distribution leaning a little bit left for whatever reason.  \n",
    "The standard deviation should be a pretty good indicator of RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard deviation of the first ratings: 0.27731986651059803\n",
      "RMSE of the test batch: 0.2713745087355389\n"
     ]
    }
   ],
   "source": [
    "# shuffle the ratings\n",
    "globmeans = np.random.permutation(uniqs.rating_global.values)\n",
    "# Calculate the mean of all but 1000 beers\n",
    "head = globmeans[:-1000]\n",
    "tail = globmeans[-1000:]\n",
    "meanhead = np.mean(head)\n",
    "# See how far each of the final 1000 is from that mean\n",
    "devs = tail - meanhead\n",
    "# Get the RMSE of those estimates\n",
    "sumsqerr = np.dot(devs, devs)\n",
    "rmse = np.sqrt(sumsqerr / len(devs))\n",
    "print(f'standard deviation of the first ratings: {np.std(head)}')\n",
    "print(f'RMSE of the test batch: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's kind of a baseline goal to beat, and we'll see how much better a Regressor can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've fit a Vectorizer to all words and added abvs/5, but we'll only train on some of them, and then test on the rest.  \n",
    "So we need to split off the test group now.  \n",
    "To the tens group from before, we'll add the elevens, for more numbers.  We can test the Regression on their global means and then see how recommendations based on the model's predictions do with our custom accuracy score from before.  Most likely, the model will fare halfway between random choices and known global means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testers = checkins[(checkins.user_id.map(usercounts) == 10) | \n",
    "                   (checkins.user_id.map(usercounts) == 11)].set_index('user_id').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6759"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're just using the unique term vectors to train and test on, so now is the time to split off all the beers that these tens and elevens have rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testIDs = set(testers.beer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4513, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbeers = uniqs[uniqs.beer_id.apply(lambda id: id in testIDs)]\n",
    "testbeers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82504, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainbeers = uniqs[uniqs.beer_id.apply(lambda id: id not in testIDs)]\n",
    "trainbeers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the vecs sparse array is struggling to split into train and test based on the above boolean array, so plan B:\n",
    "uniqs.reset_index(inplace=True)\n",
    "# now with integer range as index, the uniqs/vecs index can be looked up for each beer_id\n",
    "beer_id_to_vecs_index = dict(zip(uniqs.beer_id, uniqs.index))\n",
    "vi_test = testbeers.beer_id.map(beer_id_to_vecs_index)\n",
    "vi_train = trainbeers.beer_id.map(beer_id_to_vecs_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX = vecs.toarray()[vi_train, :]\n",
    "testX = vecs.toarray()[vi_test, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82504 training beers and 4513 test beers\n"
     ]
    }
   ],
   "source": [
    "trainY = trainbeers.rating_global\n",
    "testY = testbeers.rating_global\n",
    "print(f'{len(trainY)} training beers and {len(testY)} test beers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 3.45, NNZs: 18391, Bias: 0.113478, T: 82504, Avg. loss: 0.247669\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.79, NNZs: 18185, Bias: 0.167238, T: 165008, Avg. loss: 0.203619\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.03, NNZs: 18071, Bias: 0.211476, T: 247512, Avg. loss: 0.190149\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.21, NNZs: 17973, Bias: 0.250494, T: 330016, Avg. loss: 0.181073\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.37, NNZs: 17890, Bias: 0.285942, T: 412520, Avg. loss: 0.173974\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.49, NNZs: 17833, Bias: 0.318665, T: 495024, Avg. loss: 0.168024\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 4.63, NNZs: 17780, Bias: 0.349613, T: 577528, Avg. loss: 0.162971\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.73, NNZs: 17746, Bias: 0.378543, T: 660032, Avg. loss: 0.158427\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.83, NNZs: 17727, Bias: 0.406207, T: 742536, Avg. loss: 0.154334\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4.91, NNZs: 17687, Bias: 0.432489, T: 825040, Avg. loss: 0.150625\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 5.00, NNZs: 17652, Bias: 0.457821, T: 907544, Avg. loss: 0.147197\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 5.08, NNZs: 17610, Bias: 0.482231, T: 990048, Avg. loss: 0.144050\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 5.15, NNZs: 17598, Bias: 0.505776, T: 1072552, Avg. loss: 0.141088\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 5.22, NNZs: 17555, Bias: 0.528523, T: 1155056, Avg. loss: 0.138281\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 5.28, NNZs: 17509, Bias: 0.550528, T: 1237560, Avg. loss: 0.135680\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 5.34, NNZs: 17512, Bias: 0.571959, T: 1320064, Avg. loss: 0.133182\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 5.41, NNZs: 17474, Bias: 0.592931, T: 1402568, Avg. loss: 0.130823\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 5.45, NNZs: 17457, Bias: 0.613049, T: 1485072, Avg. loss: 0.128598\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 5.51, NNZs: 17431, Bias: 0.632878, T: 1567576, Avg. loss: 0.126438\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 5.56, NNZs: 17402, Bias: 0.652188, T: 1650080, Avg. loss: 0.124376\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 5.60, NNZs: 17377, Bias: 0.670998, T: 1732584, Avg. loss: 0.122409\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 5.65, NNZs: 17352, Bias: 0.689412, T: 1815088, Avg. loss: 0.120503\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 5.69, NNZs: 17320, Bias: 0.707468, T: 1897592, Avg. loss: 0.118709\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 5.73, NNZs: 17292, Bias: 0.725177, T: 1980096, Avg. loss: 0.116936\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 5.77, NNZs: 17271, Bias: 0.742423, T: 2062600, Avg. loss: 0.115241\n",
      "Total training time: 1.52 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 5.81, NNZs: 17265, Bias: 0.759411, T: 2145104, Avg. loss: 0.113609\n",
      "Total training time: 1.57 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 5.85, NNZs: 17226, Bias: 0.776109, T: 2227608, Avg. loss: 0.112036\n",
      "Total training time: 1.62 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 5.88, NNZs: 17201, Bias: 0.792493, T: 2310112, Avg. loss: 0.110489\n",
      "Total training time: 1.68 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 5.91, NNZs: 17196, Bias: 0.808508, T: 2392616, Avg. loss: 0.109003\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 5.95, NNZs: 17179, Bias: 0.824302, T: 2475120, Avg. loss: 0.107583\n",
      "Total training time: 1.79 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 5.98, NNZs: 17175, Bias: 0.839863, T: 2557624, Avg. loss: 0.106166\n",
      "Total training time: 1.84 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 6.01, NNZs: 17156, Bias: 0.855064, T: 2640128, Avg. loss: 0.104819\n",
      "Total training time: 1.89 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 6.04, NNZs: 17136, Bias: 0.870114, T: 2722632, Avg. loss: 0.103492\n",
      "Total training time: 1.95 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6.07, NNZs: 17122, Bias: 0.884920, T: 2805136, Avg. loss: 0.102223\n",
      "Total training time: 2.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 6.10, NNZs: 17103, Bias: 0.899463, T: 2887640, Avg. loss: 0.100963\n",
      "Total training time: 2.10 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 6.13, NNZs: 17073, Bias: 0.913858, T: 2970144, Avg. loss: 0.099725\n",
      "Total training time: 2.15 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 6.15, NNZs: 17050, Bias: 0.927939, T: 3052648, Avg. loss: 0.098564\n",
      "Total training time: 2.20 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 6.18, NNZs: 17029, Bias: 0.941900, T: 3135152, Avg. loss: 0.097405\n",
      "Total training time: 2.25 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6.20, NNZs: 17011, Bias: 0.955551, T: 3217656, Avg. loss: 0.096273\n",
      "Total training time: 2.30 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 6.22, NNZs: 17002, Bias: 0.969132, T: 3300160, Avg. loss: 0.095169\n",
      "Total training time: 2.36 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 6.25, NNZs: 16990, Bias: 0.982472, T: 3382664, Avg. loss: 0.094109\n",
      "Total training time: 2.43 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 6.27, NNZs: 16984, Bias: 0.995634, T: 3465168, Avg. loss: 0.093051\n",
      "Total training time: 2.48 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 6.29, NNZs: 16969, Bias: 1.008660, T: 3547672, Avg. loss: 0.092029\n",
      "Total training time: 2.54 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 6.31, NNZs: 16954, Bias: 1.021431, T: 3630176, Avg. loss: 0.091027\n",
      "Total training time: 2.59 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 6.33, NNZs: 16949, Bias: 1.034107, T: 3712680, Avg. loss: 0.090037\n",
      "Total training time: 2.64 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 6.35, NNZs: 16937, Bias: 1.046610, T: 3795184, Avg. loss: 0.089061\n",
      "Total training time: 2.69 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 6.37, NNZs: 16918, Bias: 1.058955, T: 3877688, Avg. loss: 0.088143\n",
      "Total training time: 2.77 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 6.39, NNZs: 16896, Bias: 1.071213, T: 3960192, Avg. loss: 0.087220\n",
      "Total training time: 2.83 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 6.41, NNZs: 16885, Bias: 1.083150, T: 4042696, Avg. loss: 0.086313\n",
      "Total training time: 2.88 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 6.43, NNZs: 16871, Bias: 1.095131, T: 4125200, Avg. loss: 0.085446\n",
      "Total training time: 2.94 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 6.44, NNZs: 16861, Bias: 1.106870, T: 4207704, Avg. loss: 0.084575\n",
      "Total training time: 3.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 6.46, NNZs: 16844, Bias: 1.118510, T: 4290208, Avg. loss: 0.083732\n",
      "Total training time: 3.05 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 6.48, NNZs: 16837, Bias: 1.130069, T: 4372712, Avg. loss: 0.082890\n",
      "Total training time: 3.11 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 6.50, NNZs: 16824, Bias: 1.141382, T: 4455216, Avg. loss: 0.082069\n",
      "Total training time: 3.17 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 6.51, NNZs: 16797, Bias: 1.152667, T: 4537720, Avg. loss: 0.081274\n",
      "Total training time: 3.23 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 6.53, NNZs: 16799, Bias: 1.163765, T: 4620224, Avg. loss: 0.080498\n",
      "Total training time: 3.29 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 6.54, NNZs: 16792, Bias: 1.174749, T: 4702728, Avg. loss: 0.079732\n",
      "Total training time: 3.34 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 6.56, NNZs: 16777, Bias: 1.185658, T: 4785232, Avg. loss: 0.078966\n",
      "Total training time: 3.39 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 6.57, NNZs: 16759, Bias: 1.196433, T: 4867736, Avg. loss: 0.078245\n",
      "Total training time: 3.45 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 6.58, NNZs: 16748, Bias: 1.207071, T: 4950240, Avg. loss: 0.077501\n",
      "Total training time: 3.50 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 6.60, NNZs: 16741, Bias: 1.217635, T: 5032744, Avg. loss: 0.076793\n",
      "Total training time: 3.55 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 6.61, NNZs: 16726, Bias: 1.228106, T: 5115248, Avg. loss: 0.076089\n",
      "Total training time: 3.60 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 6.62, NNZs: 16717, Bias: 1.238407, T: 5197752, Avg. loss: 0.075395\n",
      "Total training time: 3.65 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 6.64, NNZs: 16703, Bias: 1.248644, T: 5280256, Avg. loss: 0.074725\n",
      "Total training time: 3.71 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 6.65, NNZs: 16688, Bias: 1.258780, T: 5362760, Avg. loss: 0.074061\n",
      "Total training time: 3.76 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 6.66, NNZs: 16687, Bias: 1.268841, T: 5445264, Avg. loss: 0.073399\n",
      "Total training time: 3.81 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 6.67, NNZs: 16672, Bias: 1.278763, T: 5527768, Avg. loss: 0.072754\n",
      "Total training time: 3.87 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 6.68, NNZs: 16657, Bias: 1.288621, T: 5610272, Avg. loss: 0.072119\n",
      "Total training time: 3.92 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 6.69, NNZs: 16638, Bias: 1.298360, T: 5692776, Avg. loss: 0.071497\n",
      "Total training time: 3.98 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 6.71, NNZs: 16619, Bias: 1.308096, T: 5775280, Avg. loss: 0.070882\n",
      "Total training time: 4.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 6.72, NNZs: 16612, Bias: 1.317655, T: 5857784, Avg. loss: 0.070272\n",
      "Total training time: 4.11 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 6.73, NNZs: 16599, Bias: 1.327100, T: 5940288, Avg. loss: 0.069676\n",
      "Total training time: 4.32 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 6.74, NNZs: 16592, Bias: 1.336488, T: 6022792, Avg. loss: 0.069092\n",
      "Total training time: 4.44 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 6.74, NNZs: 16575, Bias: 1.345756, T: 6105296, Avg. loss: 0.068524\n",
      "Total training time: 4.51 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 6.75, NNZs: 16567, Bias: 1.355022, T: 6187800, Avg. loss: 0.067953\n",
      "Total training time: 4.59 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 6.76, NNZs: 16553, Bias: 1.364170, T: 6270304, Avg. loss: 0.067390\n",
      "Total training time: 4.67 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 6.77, NNZs: 16546, Bias: 1.373244, T: 6352808, Avg. loss: 0.066847\n",
      "Total training time: 4.76 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 6.78, NNZs: 16534, Bias: 1.382207, T: 6435312, Avg. loss: 0.066296\n",
      "Total training time: 4.81 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 6.79, NNZs: 16533, Bias: 1.391115, T: 6517816, Avg. loss: 0.065769\n",
      "Total training time: 4.87 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 6.80, NNZs: 16516, Bias: 1.399953, T: 6600320, Avg. loss: 0.065248\n",
      "Total training time: 4.93 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 6.81, NNZs: 16498, Bias: 1.408674, T: 6682824, Avg. loss: 0.064731\n",
      "Total training time: 5.01 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 6.81, NNZs: 16483, Bias: 1.417367, T: 6765328, Avg. loss: 0.064219\n",
      "Total training time: 5.07 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 6.82, NNZs: 16471, Bias: 1.425960, T: 6847832, Avg. loss: 0.063717\n",
      "Total training time: 5.13 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 6.83, NNZs: 16468, Bias: 1.434528, T: 6930336, Avg. loss: 0.063226\n",
      "Total training time: 5.19 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 6.84, NNZs: 16452, Bias: 1.443006, T: 7012840, Avg. loss: 0.062717\n",
      "Total training time: 5.24 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 6.84, NNZs: 16448, Bias: 1.451382, T: 7095344, Avg. loss: 0.062246\n",
      "Total training time: 5.30 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 6.85, NNZs: 16443, Bias: 1.459707, T: 7177848, Avg. loss: 0.061768\n",
      "Total training time: 5.35 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 6.86, NNZs: 16439, Bias: 1.467961, T: 7260352, Avg. loss: 0.061303\n",
      "Total training time: 5.41 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 6.87, NNZs: 16432, Bias: 1.476169, T: 7342856, Avg. loss: 0.060839\n",
      "Total training time: 5.46 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 6.87, NNZs: 16418, Bias: 1.484330, T: 7425360, Avg. loss: 0.060391\n",
      "Total training time: 5.51 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 6.88, NNZs: 16409, Bias: 1.492379, T: 7507864, Avg. loss: 0.059938\n",
      "Total training time: 5.56 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 6.89, NNZs: 16399, Bias: 1.500363, T: 7590368, Avg. loss: 0.059494\n",
      "Total training time: 5.62 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 6.89, NNZs: 16393, Bias: 1.508330, T: 7672872, Avg. loss: 0.059058\n",
      "Total training time: 5.68 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 6.90, NNZs: 16384, Bias: 1.516187, T: 7755376, Avg. loss: 0.058618\n",
      "Total training time: 5.82 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 6.90, NNZs: 16373, Bias: 1.524014, T: 7837880, Avg. loss: 0.058202\n",
      "Total training time: 5.92 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 6.91, NNZs: 16370, Bias: 1.531730, T: 7920384, Avg. loss: 0.057776\n",
      "Total training time: 6.05 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 6.91, NNZs: 16367, Bias: 1.539460, T: 8002888, Avg. loss: 0.057372\n",
      "Total training time: 6.17 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 6.92, NNZs: 16349, Bias: 1.547145, T: 8085392, Avg. loss: 0.056951\n",
      "Total training time: 6.26 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 6.92, NNZs: 16337, Bias: 1.554688, T: 8167896, Avg. loss: 0.056553\n",
      "Total training time: 6.40 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 6.93, NNZs: 16331, Bias: 1.562232, T: 8250400, Avg. loss: 0.056153\n",
      "Total training time: 6.46 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 6.93, NNZs: 16319, Bias: 1.569689, T: 8332904, Avg. loss: 0.055766\n",
      "Total training time: 6.52 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 6.94, NNZs: 16304, Bias: 1.577131, T: 8415408, Avg. loss: 0.055374\n",
      "Total training time: 6.57 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 6.94, NNZs: 16298, Bias: 1.584477, T: 8497912, Avg. loss: 0.054993\n",
      "Total training time: 6.62 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 6.95, NNZs: 16283, Bias: 1.591800, T: 8580416, Avg. loss: 0.054612\n",
      "Total training time: 6.67 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 6.95, NNZs: 16266, Bias: 1.599032, T: 8662920, Avg. loss: 0.054241\n",
      "Total training time: 6.72 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 6.96, NNZs: 16250, Bias: 1.606227, T: 8745424, Avg. loss: 0.053871\n",
      "Total training time: 6.78 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 6.96, NNZs: 16242, Bias: 1.613423, T: 8827928, Avg. loss: 0.053508\n",
      "Total training time: 6.83 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 6.97, NNZs: 16226, Bias: 1.620517, T: 8910432, Avg. loss: 0.053151\n",
      "Total training time: 6.88 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 6.97, NNZs: 16213, Bias: 1.627594, T: 8992936, Avg. loss: 0.052793\n",
      "Total training time: 6.95 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 6.97, NNZs: 16199, Bias: 1.634566, T: 9075440, Avg. loss: 0.052441\n",
      "Total training time: 7.04 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 6.98, NNZs: 16196, Bias: 1.641540, T: 9157944, Avg. loss: 0.052093\n",
      "Total training time: 7.12 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 6.98, NNZs: 16180, Bias: 1.648453, T: 9240448, Avg. loss: 0.051750\n",
      "Total training time: 7.21 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 6.99, NNZs: 16175, Bias: 1.655300, T: 9322952, Avg. loss: 0.051406\n",
      "Total training time: 7.26 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 6.99, NNZs: 16168, Bias: 1.662082, T: 9405456, Avg. loss: 0.051079\n",
      "Total training time: 7.31 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 6.99, NNZs: 16154, Bias: 1.668862, T: 9487960, Avg. loss: 0.050751\n",
      "Total training time: 7.36 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 7.00, NNZs: 16147, Bias: 1.675606, T: 9570464, Avg. loss: 0.050417\n",
      "Total training time: 7.41 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 7.00, NNZs: 16139, Bias: 1.682286, T: 9652968, Avg. loss: 0.050098\n",
      "Total training time: 7.48 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 7.00, NNZs: 16129, Bias: 1.688892, T: 9735472, Avg. loss: 0.049779\n",
      "Total training time: 7.53 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 7.00, NNZs: 16123, Bias: 1.695498, T: 9817976, Avg. loss: 0.049465\n",
      "Total training time: 7.58 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 7.01, NNZs: 16109, Bias: 1.701998, T: 9900480, Avg. loss: 0.049149\n",
      "Total training time: 7.64 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 7.01, NNZs: 16095, Bias: 1.708519, T: 9982984, Avg. loss: 0.048852\n",
      "Total training time: 7.69 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 7.01, NNZs: 16079, Bias: 1.714969, T: 10065488, Avg. loss: 0.048539\n",
      "Total training time: 7.75 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 7.02, NNZs: 16073, Bias: 1.721389, T: 10147992, Avg. loss: 0.048239\n",
      "Total training time: 7.81 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 7.02, NNZs: 16069, Bias: 1.727755, T: 10230496, Avg. loss: 0.047941\n",
      "Total training time: 7.86 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 7.02, NNZs: 16061, Bias: 1.734126, T: 10313000, Avg. loss: 0.047647\n",
      "Total training time: 7.91 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 7.02, NNZs: 16048, Bias: 1.740387, T: 10395504, Avg. loss: 0.047350\n",
      "Total training time: 7.96 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 7.02, NNZs: 16042, Bias: 1.746624, T: 10478008, Avg. loss: 0.047069\n",
      "Total training time: 8.01 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 7.03, NNZs: 16037, Bias: 1.752848, T: 10560512, Avg. loss: 0.046785\n",
      "Total training time: 8.07 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 7.03, NNZs: 16027, Bias: 1.759026, T: 10643016, Avg. loss: 0.046503\n",
      "Total training time: 8.12 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 7.03, NNZs: 16017, Bias: 1.765166, T: 10725520, Avg. loss: 0.046227\n",
      "Total training time: 8.18 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 7.03, NNZs: 16003, Bias: 1.771233, T: 10808024, Avg. loss: 0.045947\n",
      "Total training time: 8.23 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 7.04, NNZs: 15999, Bias: 1.777347, T: 10890528, Avg. loss: 0.045672\n",
      "Total training time: 8.28 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 7.04, NNZs: 15980, Bias: 1.783326, T: 10973032, Avg. loss: 0.045407\n",
      "Total training time: 8.34 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 7.04, NNZs: 15969, Bias: 1.789314, T: 11055536, Avg. loss: 0.045139\n",
      "Total training time: 8.40 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 7.04, NNZs: 15968, Bias: 1.795224, T: 11138040, Avg. loss: 0.044878\n",
      "Total training time: 8.45 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 7.04, NNZs: 15956, Bias: 1.801141, T: 11220544, Avg. loss: 0.044612\n",
      "Total training time: 8.50 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 7.04, NNZs: 15940, Bias: 1.807019, T: 11303048, Avg. loss: 0.044361\n",
      "Total training time: 8.56 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 7.05, NNZs: 15933, Bias: 1.812881, T: 11385552, Avg. loss: 0.044103\n",
      "Total training time: 8.62 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 7.05, NNZs: 15922, Bias: 1.818678, T: 11468056, Avg. loss: 0.043846\n",
      "Total training time: 8.68 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 7.05, NNZs: 15905, Bias: 1.824431, T: 11550560, Avg. loss: 0.043605\n",
      "Total training time: 8.74 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 7.05, NNZs: 15893, Bias: 1.830169, T: 11633064, Avg. loss: 0.043354\n",
      "Total training time: 8.79 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 7.05, NNZs: 15875, Bias: 1.835834, T: 11715568, Avg. loss: 0.043112\n",
      "Total training time: 8.84 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 7.05, NNZs: 15866, Bias: 1.841520, T: 11798072, Avg. loss: 0.042870\n",
      "Total training time: 8.89 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 7.05, NNZs: 15856, Bias: 1.847116, T: 11880576, Avg. loss: 0.042633\n",
      "Total training time: 8.95 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 7.05, NNZs: 15846, Bias: 1.852744, T: 11963080, Avg. loss: 0.042397\n",
      "Total training time: 9.02 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 7.05, NNZs: 15842, Bias: 1.858288, T: 12045584, Avg. loss: 0.042166\n",
      "Total training time: 9.07 seconds.\n",
      "-- Epoch 147\n",
      "Norm: 7.06, NNZs: 15833, Bias: 1.863843, T: 12128088, Avg. loss: 0.041933\n",
      "Total training time: 9.12 seconds.\n",
      "-- Epoch 148\n",
      "Norm: 7.06, NNZs: 15824, Bias: 1.869356, T: 12210592, Avg. loss: 0.041698\n",
      "Total training time: 9.19 seconds.\n",
      "-- Epoch 149\n",
      "Norm: 7.06, NNZs: 15812, Bias: 1.874775, T: 12293096, Avg. loss: 0.041471\n",
      "Total training time: 9.26 seconds.\n",
      "-- Epoch 150\n",
      "Norm: 7.06, NNZs: 15793, Bias: 1.880239, T: 12375600, Avg. loss: 0.041247\n",
      "Total training time: 9.34 seconds.\n",
      "-- Epoch 151\n",
      "Norm: 7.06, NNZs: 15784, Bias: 1.885659, T: 12458104, Avg. loss: 0.041027\n",
      "Total training time: 9.49 seconds.\n",
      "-- Epoch 152\n",
      "Norm: 7.06, NNZs: 15778, Bias: 1.890988, T: 12540608, Avg. loss: 0.040806\n",
      "Total training time: 9.56 seconds.\n",
      "-- Epoch 153\n",
      "Norm: 7.06, NNZs: 15763, Bias: 1.896355, T: 12623112, Avg. loss: 0.040588\n",
      "Total training time: 9.63 seconds.\n",
      "-- Epoch 154\n",
      "Norm: 7.06, NNZs: 15754, Bias: 1.901630, T: 12705616, Avg. loss: 0.040368\n",
      "Total training time: 9.70 seconds.\n",
      "-- Epoch 155\n",
      "Norm: 7.06, NNZs: 15749, Bias: 1.906931, T: 12788120, Avg. loss: 0.040156\n",
      "Total training time: 9.77 seconds.\n",
      "-- Epoch 156\n",
      "Norm: 7.06, NNZs: 15746, Bias: 1.912166, T: 12870624, Avg. loss: 0.039941\n",
      "Total training time: 9.83 seconds.\n",
      "-- Epoch 157\n",
      "Norm: 7.06, NNZs: 15740, Bias: 1.917380, T: 12953128, Avg. loss: 0.039733\n",
      "Total training time: 9.89 seconds.\n",
      "-- Epoch 158\n",
      "Norm: 7.06, NNZs: 15733, Bias: 1.922570, T: 13035632, Avg. loss: 0.039531\n",
      "Total training time: 9.95 seconds.\n",
      "-- Epoch 159\n",
      "Norm: 7.06, NNZs: 15720, Bias: 1.927745, T: 13118136, Avg. loss: 0.039323\n",
      "Total training time: 10.01 seconds.\n",
      "-- Epoch 160\n",
      "Norm: 7.06, NNZs: 15716, Bias: 1.932905, T: 13200640, Avg. loss: 0.039118\n",
      "Total training time: 10.06 seconds.\n",
      "-- Epoch 161\n",
      "Norm: 7.06, NNZs: 15704, Bias: 1.938006, T: 13283144, Avg. loss: 0.038921\n",
      "Total training time: 10.14 seconds.\n",
      "-- Epoch 162\n",
      "Norm: 7.07, NNZs: 15697, Bias: 1.943100, T: 13365648, Avg. loss: 0.038718\n",
      "Total training time: 10.21 seconds.\n",
      "-- Epoch 163\n",
      "Norm: 7.07, NNZs: 15691, Bias: 1.948131, T: 13448152, Avg. loss: 0.038516\n",
      "Total training time: 10.26 seconds.\n",
      "-- Epoch 164\n",
      "Norm: 7.07, NNZs: 15683, Bias: 1.953154, T: 13530656, Avg. loss: 0.038324\n",
      "Total training time: 10.31 seconds.\n",
      "-- Epoch 165\n",
      "Norm: 7.07, NNZs: 15683, Bias: 1.958153, T: 13613160, Avg. loss: 0.038128\n",
      "Total training time: 10.36 seconds.\n",
      "-- Epoch 166\n",
      "Norm: 7.07, NNZs: 15670, Bias: 1.963116, T: 13695664, Avg. loss: 0.037942\n",
      "Total training time: 10.41 seconds.\n",
      "-- Epoch 167\n",
      "Norm: 7.07, NNZs: 15662, Bias: 1.968055, T: 13778168, Avg. loss: 0.037745\n",
      "Total training time: 10.47 seconds.\n",
      "-- Epoch 168\n",
      "Norm: 7.07, NNZs: 15650, Bias: 1.972965, T: 13860672, Avg. loss: 0.037562\n",
      "Total training time: 10.52 seconds.\n",
      "-- Epoch 169\n",
      "Norm: 7.06, NNZs: 15642, Bias: 1.977822, T: 13943176, Avg. loss: 0.037376\n",
      "Total training time: 10.57 seconds.\n",
      "-- Epoch 170\n",
      "Norm: 7.07, NNZs: 15631, Bias: 1.982718, T: 14025680, Avg. loss: 0.037194\n",
      "Total training time: 10.63 seconds.\n",
      "-- Epoch 171\n",
      "Norm: 7.07, NNZs: 15622, Bias: 1.987532, T: 14108184, Avg. loss: 0.037006\n",
      "Total training time: 10.70 seconds.\n",
      "-- Epoch 172\n",
      "Norm: 7.06, NNZs: 15610, Bias: 1.992342, T: 14190688, Avg. loss: 0.036819\n",
      "Total training time: 10.75 seconds.\n",
      "-- Epoch 173\n",
      "Norm: 7.06, NNZs: 15601, Bias: 1.997133, T: 14273192, Avg. loss: 0.036648\n",
      "Total training time: 10.80 seconds.\n",
      "-- Epoch 174\n",
      "Norm: 7.06, NNZs: 15592, Bias: 2.001885, T: 14355696, Avg. loss: 0.036464\n",
      "Total training time: 10.86 seconds.\n",
      "-- Epoch 175\n",
      "Norm: 7.06, NNZs: 15581, Bias: 2.006604, T: 14438200, Avg. loss: 0.036292\n",
      "Total training time: 10.91 seconds.\n",
      "-- Epoch 176\n",
      "Norm: 7.06, NNZs: 15567, Bias: 2.011319, T: 14520704, Avg. loss: 0.036115\n",
      "Total training time: 10.96 seconds.\n",
      "-- Epoch 177\n",
      "Norm: 7.06, NNZs: 15563, Bias: 2.015993, T: 14603208, Avg. loss: 0.035946\n",
      "Total training time: 11.01 seconds.\n",
      "-- Epoch 178\n",
      "Norm: 7.06, NNZs: 15558, Bias: 2.020672, T: 14685712, Avg. loss: 0.035774\n",
      "Total training time: 11.07 seconds.\n",
      "-- Epoch 179\n",
      "Norm: 7.06, NNZs: 15546, Bias: 2.025274, T: 14768216, Avg. loss: 0.035604\n",
      "Total training time: 11.14 seconds.\n",
      "-- Epoch 180\n",
      "Norm: 7.06, NNZs: 15532, Bias: 2.029924, T: 14850720, Avg. loss: 0.035438\n",
      "Total training time: 11.19 seconds.\n",
      "-- Epoch 181\n",
      "Norm: 7.06, NNZs: 15521, Bias: 2.034499, T: 14933224, Avg. loss: 0.035272\n",
      "Total training time: 11.24 seconds.\n",
      "-- Epoch 182\n",
      "Norm: 7.06, NNZs: 15516, Bias: 2.039029, T: 15015728, Avg. loss: 0.035105\n",
      "Total training time: 11.30 seconds.\n",
      "-- Epoch 183\n",
      "Norm: 7.06, NNZs: 15508, Bias: 2.043576, T: 15098232, Avg. loss: 0.034941\n",
      "Total training time: 11.41 seconds.\n",
      "-- Epoch 184\n",
      "Norm: 7.06, NNZs: 15504, Bias: 2.048094, T: 15180736, Avg. loss: 0.034781\n",
      "Total training time: 11.49 seconds.\n",
      "-- Epoch 185\n",
      "Norm: 7.06, NNZs: 15496, Bias: 2.052575, T: 15263240, Avg. loss: 0.034619\n",
      "Total training time: 11.54 seconds.\n",
      "-- Epoch 186\n",
      "Norm: 7.06, NNZs: 15488, Bias: 2.057059, T: 15345744, Avg. loss: 0.034457\n",
      "Total training time: 11.61 seconds.\n",
      "-- Epoch 187\n",
      "Norm: 7.06, NNZs: 15486, Bias: 2.061528, T: 15428248, Avg. loss: 0.034304\n",
      "Total training time: 11.66 seconds.\n",
      "-- Epoch 188\n",
      "Norm: 7.06, NNZs: 15476, Bias: 2.065942, T: 15510752, Avg. loss: 0.034145\n",
      "Total training time: 11.71 seconds.\n",
      "-- Epoch 189\n",
      "Norm: 7.06, NNZs: 15458, Bias: 2.070335, T: 15593256, Avg. loss: 0.033987\n",
      "Total training time: 11.77 seconds.\n",
      "-- Epoch 190\n",
      "Norm: 7.06, NNZs: 15451, Bias: 2.074710, T: 15675760, Avg. loss: 0.033837\n",
      "Total training time: 11.83 seconds.\n",
      "-- Epoch 191\n",
      "Norm: 7.05, NNZs: 15437, Bias: 2.079059, T: 15758264, Avg. loss: 0.033688\n",
      "Total training time: 11.88 seconds.\n",
      "-- Epoch 192\n",
      "Norm: 7.05, NNZs: 15429, Bias: 2.083420, T: 15840768, Avg. loss: 0.033530\n",
      "Total training time: 11.94 seconds.\n",
      "-- Epoch 193\n",
      "Norm: 7.05, NNZs: 15424, Bias: 2.087752, T: 15923272, Avg. loss: 0.033382\n",
      "Total training time: 11.99 seconds.\n",
      "-- Epoch 194\n",
      "Norm: 7.05, NNZs: 15420, Bias: 2.092017, T: 16005776, Avg. loss: 0.033240\n",
      "Total training time: 12.05 seconds.\n",
      "-- Epoch 195\n",
      "Norm: 7.05, NNZs: 15413, Bias: 2.096285, T: 16088280, Avg. loss: 0.033092\n",
      "Total training time: 12.10 seconds.\n",
      "-- Epoch 196\n",
      "Norm: 7.05, NNZs: 15402, Bias: 2.100540, T: 16170784, Avg. loss: 0.032947\n",
      "Total training time: 12.15 seconds.\n",
      "-- Epoch 197\n",
      "Norm: 7.05, NNZs: 15390, Bias: 2.104787, T: 16253288, Avg. loss: 0.032801\n",
      "Total training time: 12.20 seconds.\n",
      "-- Epoch 198\n",
      "Norm: 7.05, NNZs: 15388, Bias: 2.108919, T: 16335792, Avg. loss: 0.032653\n",
      "Total training time: 12.26 seconds.\n",
      "-- Epoch 199\n",
      "Norm: 7.05, NNZs: 15377, Bias: 2.113145, T: 16418296, Avg. loss: 0.032522\n",
      "Total training time: 12.31 seconds.\n",
      "-- Epoch 200\n",
      "Norm: 7.05, NNZs: 15360, Bias: 2.117325, T: 16500800, Avg. loss: 0.032377\n",
      "Total training time: 12.36 seconds.\n",
      "-- Epoch 201\n",
      "Norm: 7.05, NNZs: 15353, Bias: 2.121469, T: 16583304, Avg. loss: 0.032237\n",
      "Total training time: 12.42 seconds.\n",
      "-- Epoch 202\n",
      "Norm: 7.05, NNZs: 15342, Bias: 2.125618, T: 16665808, Avg. loss: 0.032098\n",
      "Total training time: 12.47 seconds.\n",
      "-- Epoch 203\n",
      "Norm: 7.04, NNZs: 15336, Bias: 2.129670, T: 16748312, Avg. loss: 0.031965\n",
      "Total training time: 12.52 seconds.\n",
      "-- Epoch 204\n",
      "Norm: 7.04, NNZs: 15328, Bias: 2.133780, T: 16830816, Avg. loss: 0.031827\n",
      "Total training time: 12.57 seconds.\n",
      "-- Epoch 205\n",
      "Norm: 7.04, NNZs: 15318, Bias: 2.137843, T: 16913320, Avg. loss: 0.031692\n",
      "Total training time: 12.62 seconds.\n",
      "-- Epoch 206\n",
      "Norm: 7.04, NNZs: 15308, Bias: 2.141851, T: 16995824, Avg. loss: 0.031558\n",
      "Total training time: 12.68 seconds.\n",
      "-- Epoch 207\n",
      "Norm: 7.04, NNZs: 15297, Bias: 2.145912, T: 17078328, Avg. loss: 0.031428\n",
      "Total training time: 12.73 seconds.\n",
      "-- Epoch 208\n",
      "Norm: 7.04, NNZs: 15291, Bias: 2.149910, T: 17160832, Avg. loss: 0.031293\n",
      "Total training time: 12.77 seconds.\n",
      "-- Epoch 209\n",
      "Norm: 7.04, NNZs: 15280, Bias: 2.153926, T: 17243336, Avg. loss: 0.031168\n",
      "Total training time: 12.83 seconds.\n",
      "-- Epoch 210\n",
      "Norm: 7.04, NNZs: 15266, Bias: 2.157870, T: 17325840, Avg. loss: 0.031039\n",
      "Total training time: 12.89 seconds.\n",
      "-- Epoch 211\n",
      "Norm: 7.03, NNZs: 15258, Bias: 2.161833, T: 17408344, Avg. loss: 0.030910\n",
      "Total training time: 12.94 seconds.\n",
      "-- Epoch 212\n",
      "Norm: 7.03, NNZs: 15251, Bias: 2.165758, T: 17490848, Avg. loss: 0.030785\n",
      "Total training time: 12.99 seconds.\n",
      "-- Epoch 213\n",
      "Norm: 7.03, NNZs: 15246, Bias: 2.169665, T: 17573352, Avg. loss: 0.030655\n",
      "Total training time: 13.04 seconds.\n",
      "-- Epoch 214\n",
      "Norm: 7.03, NNZs: 15243, Bias: 2.173556, T: 17655856, Avg. loss: 0.030534\n",
      "Total training time: 13.10 seconds.\n",
      "-- Epoch 215\n",
      "Norm: 7.03, NNZs: 15241, Bias: 2.177448, T: 17738360, Avg. loss: 0.030406\n",
      "Total training time: 13.15 seconds.\n",
      "-- Epoch 216\n",
      "Norm: 7.03, NNZs: 15240, Bias: 2.181309, T: 17820864, Avg. loss: 0.030287\n",
      "Total training time: 13.22 seconds.\n",
      "-- Epoch 217\n",
      "Norm: 7.03, NNZs: 15232, Bias: 2.185164, T: 17903368, Avg. loss: 0.030167\n",
      "Total training time: 13.31 seconds.\n",
      "-- Epoch 218\n",
      "Norm: 7.03, NNZs: 15214, Bias: 2.188969, T: 17985872, Avg. loss: 0.030046\n",
      "Total training time: 13.39 seconds.\n",
      "-- Epoch 219\n",
      "Norm: 7.02, NNZs: 15205, Bias: 2.192748, T: 18068376, Avg. loss: 0.029929\n",
      "Total training time: 13.47 seconds.\n",
      "-- Epoch 220\n",
      "Norm: 7.02, NNZs: 15192, Bias: 2.196549, T: 18150880, Avg. loss: 0.029804\n",
      "Total training time: 13.54 seconds.\n",
      "-- Epoch 221\n",
      "Norm: 7.02, NNZs: 15182, Bias: 2.200314, T: 18233384, Avg. loss: 0.029692\n",
      "Total training time: 13.61 seconds.\n",
      "-- Epoch 222\n",
      "Norm: 7.02, NNZs: 15170, Bias: 2.204064, T: 18315888, Avg. loss: 0.029575\n",
      "Total training time: 13.70 seconds.\n",
      "-- Epoch 223\n",
      "Norm: 7.02, NNZs: 15151, Bias: 2.207821, T: 18398392, Avg. loss: 0.029456\n",
      "Total training time: 13.76 seconds.\n",
      "-- Epoch 224\n",
      "Norm: 7.02, NNZs: 15143, Bias: 2.211510, T: 18480896, Avg. loss: 0.029340\n",
      "Total training time: 13.82 seconds.\n",
      "-- Epoch 225\n",
      "Norm: 7.02, NNZs: 15134, Bias: 2.215234, T: 18563400, Avg. loss: 0.029229\n",
      "Total training time: 13.88 seconds.\n",
      "-- Epoch 226\n",
      "Norm: 7.01, NNZs: 15124, Bias: 2.218894, T: 18645904, Avg. loss: 0.029118\n",
      "Total training time: 13.93 seconds.\n",
      "-- Epoch 227\n",
      "Norm: 7.01, NNZs: 15111, Bias: 2.222563, T: 18728408, Avg. loss: 0.029007\n",
      "Total training time: 13.99 seconds.\n",
      "-- Epoch 228\n",
      "Norm: 7.01, NNZs: 15098, Bias: 2.226233, T: 18810912, Avg. loss: 0.028891\n",
      "Total training time: 14.04 seconds.\n",
      "-- Epoch 229\n",
      "Norm: 7.01, NNZs: 15085, Bias: 2.229850, T: 18893416, Avg. loss: 0.028784\n",
      "Total training time: 14.10 seconds.\n",
      "-- Epoch 230\n",
      "Norm: 7.01, NNZs: 15070, Bias: 2.233468, T: 18975920, Avg. loss: 0.028676\n",
      "Total training time: 14.15 seconds.\n",
      "-- Epoch 231\n",
      "Norm: 7.01, NNZs: 15068, Bias: 2.237082, T: 19058424, Avg. loss: 0.028567\n",
      "Total training time: 14.21 seconds.\n",
      "-- Epoch 232\n",
      "Norm: 7.00, NNZs: 15060, Bias: 2.240640, T: 19140928, Avg. loss: 0.028458\n",
      "Total training time: 14.27 seconds.\n",
      "-- Epoch 233\n",
      "Norm: 7.00, NNZs: 15049, Bias: 2.244215, T: 19223432, Avg. loss: 0.028352\n",
      "Total training time: 14.32 seconds.\n",
      "-- Epoch 234\n",
      "Norm: 7.00, NNZs: 15040, Bias: 2.247791, T: 19305936, Avg. loss: 0.028247\n",
      "Total training time: 14.38 seconds.\n",
      "-- Epoch 235\n",
      "Norm: 7.00, NNZs: 15040, Bias: 2.251320, T: 19388440, Avg. loss: 0.028141\n",
      "Total training time: 14.43 seconds.\n",
      "-- Epoch 236\n",
      "Norm: 7.00, NNZs: 15038, Bias: 2.254809, T: 19470944, Avg. loss: 0.028036\n",
      "Total training time: 14.49 seconds.\n",
      "-- Epoch 237\n",
      "Norm: 7.00, NNZs: 15031, Bias: 2.258345, T: 19553448, Avg. loss: 0.027937\n",
      "Total training time: 14.54 seconds.\n",
      "-- Epoch 238\n",
      "Norm: 6.99, NNZs: 15024, Bias: 2.261834, T: 19635952, Avg. loss: 0.027831\n",
      "Total training time: 14.59 seconds.\n",
      "-- Epoch 239\n",
      "Norm: 6.99, NNZs: 15013, Bias: 2.265298, T: 19718456, Avg. loss: 0.027731\n",
      "Total training time: 14.69 seconds.\n",
      "-- Epoch 240\n",
      "Norm: 6.99, NNZs: 14999, Bias: 2.268740, T: 19800960, Avg. loss: 0.027632\n",
      "Total training time: 14.74 seconds.\n",
      "-- Epoch 241\n",
      "Norm: 6.99, NNZs: 14987, Bias: 2.272205, T: 19883464, Avg. loss: 0.027530\n",
      "Total training time: 14.79 seconds.\n",
      "-- Epoch 242\n",
      "Norm: 6.99, NNZs: 14976, Bias: 2.275643, T: 19965968, Avg. loss: 0.027433\n",
      "Total training time: 14.84 seconds.\n",
      "-- Epoch 243\n",
      "Norm: 6.99, NNZs: 14970, Bias: 2.279047, T: 20048472, Avg. loss: 0.027333\n",
      "Total training time: 14.89 seconds.\n",
      "-- Epoch 244\n",
      "Norm: 6.98, NNZs: 14958, Bias: 2.282460, T: 20130976, Avg. loss: 0.027235\n",
      "Total training time: 14.95 seconds.\n",
      "-- Epoch 245\n",
      "Norm: 6.98, NNZs: 14952, Bias: 2.285845, T: 20213480, Avg. loss: 0.027138\n",
      "Total training time: 15.01 seconds.\n",
      "-- Epoch 246\n",
      "Norm: 6.98, NNZs: 14945, Bias: 2.289200, T: 20295984, Avg. loss: 0.027042\n",
      "Total training time: 15.05 seconds.\n",
      "-- Epoch 247\n",
      "Norm: 6.98, NNZs: 14941, Bias: 2.292537, T: 20378488, Avg. loss: 0.026947\n",
      "Total training time: 15.11 seconds.\n",
      "-- Epoch 248\n",
      "Norm: 6.98, NNZs: 14938, Bias: 2.295884, T: 20460992, Avg. loss: 0.026853\n",
      "Total training time: 15.17 seconds.\n",
      "-- Epoch 249\n",
      "Norm: 6.97, NNZs: 14934, Bias: 2.299230, T: 20543496, Avg. loss: 0.026757\n",
      "Total training time: 15.22 seconds.\n",
      "-- Epoch 250\n",
      "Norm: 6.97, NNZs: 14925, Bias: 2.302544, T: 20626000, Avg. loss: 0.026665\n",
      "Total training time: 15.26 seconds.\n",
      "-- Epoch 251\n",
      "Norm: 6.97, NNZs: 14912, Bias: 2.305801, T: 20708504, Avg. loss: 0.026573\n",
      "Total training time: 15.32 seconds.\n",
      "-- Epoch 252\n",
      "Norm: 6.97, NNZs: 14909, Bias: 2.309121, T: 20791008, Avg. loss: 0.026480\n",
      "Total training time: 15.37 seconds.\n",
      "-- Epoch 253\n",
      "Norm: 6.97, NNZs: 14901, Bias: 2.312364, T: 20873512, Avg. loss: 0.026388\n",
      "Total training time: 15.43 seconds.\n",
      "-- Epoch 254\n",
      "Norm: 6.96, NNZs: 14886, Bias: 2.315619, T: 20956016, Avg. loss: 0.026300\n",
      "Total training time: 15.48 seconds.\n",
      "-- Epoch 255\n",
      "Norm: 6.96, NNZs: 14873, Bias: 2.318881, T: 21038520, Avg. loss: 0.026208\n",
      "Total training time: 15.53 seconds.\n",
      "-- Epoch 256\n",
      "Norm: 6.96, NNZs: 14857, Bias: 2.322096, T: 21121024, Avg. loss: 0.026118\n",
      "Total training time: 15.59 seconds.\n",
      "-- Epoch 257\n",
      "Norm: 6.96, NNZs: 14846, Bias: 2.325305, T: 21203528, Avg. loss: 0.026032\n",
      "Total training time: 15.64 seconds.\n",
      "-- Epoch 258\n",
      "Norm: 6.96, NNZs: 14833, Bias: 2.328509, T: 21286032, Avg. loss: 0.025945\n",
      "Total training time: 15.69 seconds.\n",
      "-- Epoch 259\n",
      "Norm: 6.96, NNZs: 14820, Bias: 2.331704, T: 21368536, Avg. loss: 0.025858\n",
      "Total training time: 15.74 seconds.\n",
      "-- Epoch 260\n",
      "Norm: 6.95, NNZs: 14810, Bias: 2.334855, T: 21451040, Avg. loss: 0.025767\n",
      "Total training time: 15.80 seconds.\n",
      "-- Epoch 261\n",
      "Norm: 6.95, NNZs: 14803, Bias: 2.338022, T: 21533544, Avg. loss: 0.025686\n",
      "Total training time: 15.85 seconds.\n",
      "-- Epoch 262\n",
      "Norm: 6.95, NNZs: 14794, Bias: 2.341186, T: 21616048, Avg. loss: 0.025601\n",
      "Total training time: 15.91 seconds.\n",
      "-- Epoch 263\n",
      "Norm: 6.95, NNZs: 14785, Bias: 2.344315, T: 21698552, Avg. loss: 0.025515\n",
      "Total training time: 15.99 seconds.\n",
      "-- Epoch 264\n",
      "Norm: 6.95, NNZs: 14782, Bias: 2.347447, T: 21781056, Avg. loss: 0.025431\n",
      "Total training time: 16.08 seconds.\n",
      "-- Epoch 265\n",
      "Norm: 6.94, NNZs: 14778, Bias: 2.350526, T: 21863560, Avg. loss: 0.025347\n",
      "Total training time: 16.15 seconds.\n",
      "-- Epoch 266\n",
      "Norm: 6.94, NNZs: 14768, Bias: 2.353655, T: 21946064, Avg. loss: 0.025265\n",
      "Total training time: 16.22 seconds.\n",
      "-- Epoch 267\n",
      "Norm: 6.94, NNZs: 14756, Bias: 2.356711, T: 22028568, Avg. loss: 0.025183\n",
      "Total training time: 16.28 seconds.\n",
      "-- Epoch 268\n",
      "Norm: 6.94, NNZs: 14746, Bias: 2.359774, T: 22111072, Avg. loss: 0.025100\n",
      "Total training time: 16.33 seconds.\n",
      "-- Epoch 269\n",
      "Norm: 6.94, NNZs: 14731, Bias: 2.362820, T: 22193576, Avg. loss: 0.025021\n",
      "Total training time: 16.39 seconds.\n",
      "-- Epoch 270\n",
      "Norm: 6.93, NNZs: 14722, Bias: 2.365890, T: 22276080, Avg. loss: 0.024942\n",
      "Total training time: 16.44 seconds.\n",
      "-- Epoch 271\n",
      "Norm: 6.93, NNZs: 14715, Bias: 2.368909, T: 22358584, Avg. loss: 0.024863\n",
      "Total training time: 16.50 seconds.\n",
      "-- Epoch 272\n",
      "Norm: 6.93, NNZs: 14704, Bias: 2.371912, T: 22441088, Avg. loss: 0.024782\n",
      "Total training time: 16.57 seconds.\n",
      "-- Epoch 273\n",
      "Norm: 6.93, NNZs: 14699, Bias: 2.374944, T: 22523592, Avg. loss: 0.024705\n",
      "Total training time: 16.65 seconds.\n",
      "-- Epoch 274\n",
      "Norm: 6.93, NNZs: 14690, Bias: 2.377934, T: 22606096, Avg. loss: 0.024627\n",
      "Total training time: 16.71 seconds.\n",
      "-- Epoch 275\n",
      "Norm: 6.92, NNZs: 14680, Bias: 2.380905, T: 22688600, Avg. loss: 0.024549\n",
      "Total training time: 16.77 seconds.\n",
      "-- Epoch 276\n",
      "Norm: 6.92, NNZs: 14679, Bias: 2.383899, T: 22771104, Avg. loss: 0.024472\n",
      "Total training time: 16.83 seconds.\n",
      "-- Epoch 277\n",
      "Norm: 6.92, NNZs: 14668, Bias: 2.386847, T: 22853608, Avg. loss: 0.024398\n",
      "Total training time: 16.90 seconds.\n",
      "-- Epoch 278\n",
      "Norm: 6.92, NNZs: 14657, Bias: 2.389762, T: 22936112, Avg. loss: 0.024318\n",
      "Total training time: 16.96 seconds.\n",
      "-- Epoch 279\n",
      "Norm: 6.92, NNZs: 14651, Bias: 2.392728, T: 23018616, Avg. loss: 0.024247\n",
      "Total training time: 17.01 seconds.\n",
      "-- Epoch 280\n",
      "Norm: 6.91, NNZs: 14639, Bias: 2.395660, T: 23101120, Avg. loss: 0.024171\n",
      "Total training time: 17.07 seconds.\n",
      "-- Epoch 281\n",
      "Norm: 6.91, NNZs: 14629, Bias: 2.398555, T: 23183624, Avg. loss: 0.024099\n",
      "Total training time: 17.12 seconds.\n",
      "-- Epoch 282\n",
      "Norm: 6.91, NNZs: 14616, Bias: 2.401452, T: 23266128, Avg. loss: 0.024024\n",
      "Total training time: 17.17 seconds.\n",
      "-- Epoch 283\n",
      "Norm: 6.91, NNZs: 14608, Bias: 2.404332, T: 23348632, Avg. loss: 0.023952\n",
      "Total training time: 17.22 seconds.\n",
      "-- Epoch 284\n",
      "Norm: 6.90, NNZs: 14599, Bias: 2.407217, T: 23431136, Avg. loss: 0.023880\n",
      "Total training time: 17.31 seconds.\n",
      "-- Epoch 285\n",
      "Norm: 6.90, NNZs: 14591, Bias: 2.410094, T: 23513640, Avg. loss: 0.023806\n",
      "Total training time: 17.38 seconds.\n",
      "-- Epoch 286\n",
      "Norm: 6.90, NNZs: 14583, Bias: 2.412929, T: 23596144, Avg. loss: 0.023736\n",
      "Total training time: 17.44 seconds.\n",
      "-- Epoch 287\n",
      "Norm: 6.90, NNZs: 14572, Bias: 2.415779, T: 23678648, Avg. loss: 0.023665\n",
      "Total training time: 17.49 seconds.\n",
      "-- Epoch 288\n",
      "Norm: 6.90, NNZs: 14569, Bias: 2.418595, T: 23761152, Avg. loss: 0.023597\n",
      "Total training time: 17.55 seconds.\n",
      "-- Epoch 289\n",
      "Norm: 6.89, NNZs: 14561, Bias: 2.421402, T: 23843656, Avg. loss: 0.023525\n",
      "Total training time: 17.63 seconds.\n",
      "-- Epoch 290\n",
      "Norm: 6.89, NNZs: 14552, Bias: 2.424231, T: 23926160, Avg. loss: 0.023456\n",
      "Total training time: 17.70 seconds.\n",
      "-- Epoch 291\n",
      "Norm: 6.89, NNZs: 14541, Bias: 2.427007, T: 24008664, Avg. loss: 0.023389\n",
      "Total training time: 17.77 seconds.\n",
      "-- Epoch 292\n",
      "Norm: 6.89, NNZs: 14532, Bias: 2.429782, T: 24091168, Avg. loss: 0.023321\n",
      "Total training time: 17.84 seconds.\n",
      "-- Epoch 293\n",
      "Norm: 6.89, NNZs: 14523, Bias: 2.432562, T: 24173672, Avg. loss: 0.023251\n",
      "Total training time: 17.91 seconds.\n",
      "-- Epoch 294\n",
      "Norm: 6.88, NNZs: 14509, Bias: 2.435317, T: 24256176, Avg. loss: 0.023186\n",
      "Total training time: 17.96 seconds.\n",
      "-- Epoch 295\n",
      "Norm: 6.88, NNZs: 14502, Bias: 2.438084, T: 24338680, Avg. loss: 0.023115\n",
      "Total training time: 18.02 seconds.\n",
      "-- Epoch 296\n",
      "Norm: 6.88, NNZs: 14491, Bias: 2.440827, T: 24421184, Avg. loss: 0.023053\n",
      "Total training time: 18.09 seconds.\n",
      "-- Epoch 297\n",
      "Norm: 6.88, NNZs: 14481, Bias: 2.443552, T: 24503688, Avg. loss: 0.022987\n",
      "Total training time: 18.15 seconds.\n",
      "-- Epoch 298\n",
      "Norm: 6.87, NNZs: 14472, Bias: 2.446251, T: 24586192, Avg. loss: 0.022921\n",
      "Total training time: 18.22 seconds.\n",
      "-- Epoch 299\n",
      "Norm: 6.87, NNZs: 14462, Bias: 2.448965, T: 24668696, Avg. loss: 0.022856\n",
      "Total training time: 18.29 seconds.\n",
      "-- Epoch 300\n",
      "Norm: 6.87, NNZs: 14448, Bias: 2.451663, T: 24751200, Avg. loss: 0.022790\n",
      "Total training time: 18.36 seconds.\n",
      "-- Epoch 301\n",
      "Norm: 6.87, NNZs: 14445, Bias: 2.454355, T: 24833704, Avg. loss: 0.022729\n",
      "Total training time: 18.44 seconds.\n",
      "-- Epoch 302\n",
      "Norm: 6.87, NNZs: 14432, Bias: 2.457021, T: 24916208, Avg. loss: 0.022665\n",
      "Total training time: 18.52 seconds.\n",
      "-- Epoch 303\n",
      "Norm: 6.86, NNZs: 14429, Bias: 2.459679, T: 24998712, Avg. loss: 0.022603\n",
      "Total training time: 18.60 seconds.\n",
      "-- Epoch 304\n",
      "Norm: 6.86, NNZs: 14421, Bias: 2.462349, T: 25081216, Avg. loss: 0.022539\n",
      "Total training time: 18.69 seconds.\n",
      "-- Epoch 305\n",
      "Norm: 6.86, NNZs: 14418, Bias: 2.464968, T: 25163720, Avg. loss: 0.022475\n",
      "Total training time: 18.77 seconds.\n",
      "-- Epoch 306\n",
      "Norm: 6.86, NNZs: 14399, Bias: 2.467625, T: 25246224, Avg. loss: 0.022415\n",
      "Total training time: 18.86 seconds.\n",
      "-- Epoch 307\n",
      "Norm: 6.85, NNZs: 14385, Bias: 2.470239, T: 25328728, Avg. loss: 0.022354\n",
      "Total training time: 18.95 seconds.\n",
      "-- Epoch 308\n",
      "Norm: 6.85, NNZs: 14371, Bias: 2.472856, T: 25411232, Avg. loss: 0.022295\n",
      "Total training time: 19.05 seconds.\n",
      "-- Epoch 309\n",
      "Norm: 6.85, NNZs: 14364, Bias: 2.475468, T: 25493736, Avg. loss: 0.022233\n",
      "Total training time: 19.17 seconds.\n",
      "-- Epoch 310\n",
      "Norm: 6.85, NNZs: 14355, Bias: 2.478035, T: 25576240, Avg. loss: 0.022171\n",
      "Total training time: 19.35 seconds.\n",
      "-- Epoch 311\n",
      "Norm: 6.85, NNZs: 14351, Bias: 2.480651, T: 25658744, Avg. loss: 0.022113\n",
      "Total training time: 19.47 seconds.\n",
      "-- Epoch 312\n",
      "Norm: 6.84, NNZs: 14343, Bias: 2.483212, T: 25741248, Avg. loss: 0.022053\n",
      "Total training time: 19.58 seconds.\n",
      "-- Epoch 313\n",
      "Norm: 6.84, NNZs: 14341, Bias: 2.485771, T: 25823752, Avg. loss: 0.021995\n",
      "Total training time: 19.76 seconds.\n",
      "-- Epoch 314\n",
      "Norm: 6.84, NNZs: 14340, Bias: 2.488340, T: 25906256, Avg. loss: 0.021935\n",
      "Total training time: 19.91 seconds.\n",
      "-- Epoch 315\n",
      "Norm: 6.84, NNZs: 14337, Bias: 2.490871, T: 25988760, Avg. loss: 0.021879\n",
      "Total training time: 20.00 seconds.\n",
      "-- Epoch 316\n",
      "Norm: 6.83, NNZs: 14325, Bias: 2.493415, T: 26071264, Avg. loss: 0.021821\n",
      "Total training time: 20.09 seconds.\n",
      "-- Epoch 317\n",
      "Norm: 6.83, NNZs: 14320, Bias: 2.495935, T: 26153768, Avg. loss: 0.021762\n",
      "Total training time: 20.18 seconds.\n",
      "-- Epoch 318\n",
      "Norm: 6.83, NNZs: 14314, Bias: 2.498465, T: 26236272, Avg. loss: 0.021708\n",
      "Total training time: 20.38 seconds.\n",
      "-- Epoch 319\n",
      "Norm: 6.83, NNZs: 14305, Bias: 2.500961, T: 26318776, Avg. loss: 0.021651\n",
      "Total training time: 20.50 seconds.\n",
      "-- Epoch 320\n",
      "Norm: 6.83, NNZs: 14299, Bias: 2.503443, T: 26401280, Avg. loss: 0.021594\n",
      "Total training time: 20.67 seconds.\n",
      "-- Epoch 321\n",
      "Norm: 6.82, NNZs: 14291, Bias: 2.505929, T: 26483784, Avg. loss: 0.021540\n",
      "Total training time: 20.81 seconds.\n",
      "-- Epoch 322\n",
      "Norm: 6.82, NNZs: 14287, Bias: 2.508425, T: 26566288, Avg. loss: 0.021483\n",
      "Total training time: 20.90 seconds.\n",
      "-- Epoch 323\n",
      "Norm: 6.82, NNZs: 14278, Bias: 2.510892, T: 26648792, Avg. loss: 0.021428\n",
      "Total training time: 20.96 seconds.\n",
      "-- Epoch 324\n",
      "Norm: 6.82, NNZs: 14272, Bias: 2.513348, T: 26731296, Avg. loss: 0.021374\n",
      "Total training time: 21.03 seconds.\n",
      "-- Epoch 325\n",
      "Norm: 6.81, NNZs: 14264, Bias: 2.515810, T: 26813800, Avg. loss: 0.021320\n",
      "Total training time: 21.12 seconds.\n",
      "-- Epoch 326\n",
      "Norm: 6.81, NNZs: 14255, Bias: 2.518245, T: 26896304, Avg. loss: 0.021266\n",
      "Total training time: 21.24 seconds.\n",
      "-- Epoch 327\n",
      "Norm: 6.81, NNZs: 14245, Bias: 2.520658, T: 26978808, Avg. loss: 0.021208\n",
      "Total training time: 21.40 seconds.\n",
      "-- Epoch 328\n",
      "Norm: 6.81, NNZs: 14240, Bias: 2.523126, T: 27061312, Avg. loss: 0.021158\n",
      "Total training time: 21.65 seconds.\n",
      "-- Epoch 329\n",
      "Norm: 6.81, NNZs: 14227, Bias: 2.525507, T: 27143816, Avg. loss: 0.021107\n",
      "Total training time: 21.77 seconds.\n",
      "-- Epoch 330\n",
      "Norm: 6.80, NNZs: 14221, Bias: 2.527931, T: 27226320, Avg. loss: 0.021053\n",
      "Total training time: 21.89 seconds.\n",
      "-- Epoch 331\n",
      "Norm: 6.80, NNZs: 14214, Bias: 2.530320, T: 27308824, Avg. loss: 0.020998\n",
      "Total training time: 22.02 seconds.\n",
      "-- Epoch 332\n",
      "Norm: 6.80, NNZs: 14194, Bias: 2.532683, T: 27391328, Avg. loss: 0.020949\n",
      "Total training time: 22.22 seconds.\n",
      "-- Epoch 333\n",
      "Norm: 6.80, NNZs: 14183, Bias: 2.535053, T: 27473832, Avg. loss: 0.020898\n",
      "Total training time: 22.31 seconds.\n",
      "-- Epoch 334\n",
      "Norm: 6.79, NNZs: 14173, Bias: 2.537451, T: 27556336, Avg. loss: 0.020849\n",
      "Total training time: 22.42 seconds.\n",
      "-- Epoch 335\n",
      "Norm: 6.79, NNZs: 14164, Bias: 2.539816, T: 27638840, Avg. loss: 0.020794\n",
      "Total training time: 22.49 seconds.\n",
      "-- Epoch 336\n",
      "Norm: 6.79, NNZs: 14155, Bias: 2.542169, T: 27721344, Avg. loss: 0.020747\n",
      "Total training time: 22.56 seconds.\n",
      "-- Epoch 337\n",
      "Norm: 6.79, NNZs: 14147, Bias: 2.544497, T: 27803848, Avg. loss: 0.020696\n",
      "Total training time: 22.69 seconds.\n",
      "-- Epoch 338\n",
      "Norm: 6.78, NNZs: 14134, Bias: 2.546822, T: 27886352, Avg. loss: 0.020643\n",
      "Total training time: 22.78 seconds.\n",
      "-- Epoch 339\n",
      "Norm: 6.78, NNZs: 14127, Bias: 2.549171, T: 27968856, Avg. loss: 0.020598\n",
      "Total training time: 22.84 seconds.\n",
      "-- Epoch 340\n",
      "Norm: 6.78, NNZs: 14122, Bias: 2.551484, T: 28051360, Avg. loss: 0.020551\n",
      "Total training time: 22.91 seconds.\n",
      "-- Epoch 341\n",
      "Norm: 6.78, NNZs: 14116, Bias: 2.553789, T: 28133864, Avg. loss: 0.020499\n",
      "Total training time: 22.98 seconds.\n",
      "-- Epoch 342\n",
      "Norm: 6.78, NNZs: 14105, Bias: 2.556096, T: 28216368, Avg. loss: 0.020453\n",
      "Total training time: 23.04 seconds.\n",
      "-- Epoch 343\n",
      "Norm: 6.77, NNZs: 14103, Bias: 2.558385, T: 28298872, Avg. loss: 0.020404\n",
      "Total training time: 23.11 seconds.\n",
      "-- Epoch 344\n",
      "Norm: 6.77, NNZs: 14094, Bias: 2.560654, T: 28381376, Avg. loss: 0.020355\n",
      "Total training time: 23.17 seconds.\n",
      "-- Epoch 345\n",
      "Norm: 6.77, NNZs: 14092, Bias: 2.562940, T: 28463880, Avg. loss: 0.020310\n",
      "Total training time: 23.24 seconds.\n",
      "-- Epoch 346\n",
      "Norm: 6.77, NNZs: 14084, Bias: 2.565214, T: 28546384, Avg. loss: 0.020261\n",
      "Total training time: 23.30 seconds.\n",
      "-- Epoch 347\n",
      "Norm: 6.76, NNZs: 14077, Bias: 2.567473, T: 28628888, Avg. loss: 0.020214\n",
      "Total training time: 23.38 seconds.\n",
      "-- Epoch 348\n",
      "Norm: 6.76, NNZs: 14070, Bias: 2.569736, T: 28711392, Avg. loss: 0.020168\n",
      "Total training time: 23.45 seconds.\n",
      "-- Epoch 349\n",
      "Norm: 6.76, NNZs: 14069, Bias: 2.571983, T: 28793896, Avg. loss: 0.020122\n",
      "Total training time: 23.53 seconds.\n",
      "-- Epoch 350\n",
      "Norm: 6.76, NNZs: 14058, Bias: 2.574213, T: 28876400, Avg. loss: 0.020076\n",
      "Total training time: 23.60 seconds.\n",
      "-- Epoch 351\n",
      "Norm: 6.75, NNZs: 14044, Bias: 2.576427, T: 28958904, Avg. loss: 0.020031\n",
      "Total training time: 23.68 seconds.\n",
      "-- Epoch 352\n",
      "Norm: 6.75, NNZs: 14032, Bias: 2.578648, T: 29041408, Avg. loss: 0.019984\n",
      "Total training time: 23.74 seconds.\n",
      "-- Epoch 353\n",
      "Norm: 6.75, NNZs: 14027, Bias: 2.580879, T: 29123912, Avg. loss: 0.019941\n",
      "Total training time: 23.81 seconds.\n",
      "-- Epoch 354\n",
      "Norm: 6.75, NNZs: 14023, Bias: 2.583071, T: 29206416, Avg. loss: 0.019894\n",
      "Total training time: 23.88 seconds.\n",
      "-- Epoch 355\n",
      "Norm: 6.75, NNZs: 14014, Bias: 2.585255, T: 29288920, Avg. loss: 0.019852\n",
      "Total training time: 23.94 seconds.\n",
      "-- Epoch 356\n",
      "Norm: 6.74, NNZs: 14006, Bias: 2.587450, T: 29371424, Avg. loss: 0.019808\n",
      "Total training time: 24.00 seconds.\n",
      "-- Epoch 357\n",
      "Norm: 6.74, NNZs: 13997, Bias: 2.589626, T: 29453928, Avg. loss: 0.019763\n",
      "Total training time: 24.07 seconds.\n",
      "-- Epoch 358\n",
      "Norm: 6.74, NNZs: 13987, Bias: 2.591800, T: 29536432, Avg. loss: 0.019719\n",
      "Total training time: 24.31 seconds.\n",
      "-- Epoch 359\n",
      "Norm: 6.74, NNZs: 13977, Bias: 2.593959, T: 29618936, Avg. loss: 0.019677\n",
      "Total training time: 24.39 seconds.\n",
      "-- Epoch 360\n",
      "Norm: 6.73, NNZs: 13961, Bias: 2.596118, T: 29701440, Avg. loss: 0.019634\n",
      "Total training time: 24.45 seconds.\n",
      "-- Epoch 361\n",
      "Norm: 6.73, NNZs: 13952, Bias: 2.598278, T: 29783944, Avg. loss: 0.019591\n",
      "Total training time: 24.51 seconds.\n",
      "-- Epoch 362\n",
      "Norm: 6.73, NNZs: 13945, Bias: 2.600412, T: 29866448, Avg. loss: 0.019549\n",
      "Total training time: 24.57 seconds.\n",
      "-- Epoch 363\n",
      "Norm: 6.73, NNZs: 13939, Bias: 2.602527, T: 29948952, Avg. loss: 0.019506\n",
      "Total training time: 24.63 seconds.\n",
      "-- Epoch 364\n",
      "Norm: 6.72, NNZs: 13929, Bias: 2.604650, T: 30031456, Avg. loss: 0.019465\n",
      "Total training time: 24.69 seconds.\n",
      "-- Epoch 365\n",
      "Norm: 6.72, NNZs: 13917, Bias: 2.606789, T: 30113960, Avg. loss: 0.019424\n",
      "Total training time: 24.74 seconds.\n",
      "-- Epoch 366\n",
      "Norm: 6.72, NNZs: 13909, Bias: 2.608870, T: 30196464, Avg. loss: 0.019382\n",
      "Total training time: 24.79 seconds.\n",
      "-- Epoch 367\n",
      "Norm: 6.72, NNZs: 13900, Bias: 2.611010, T: 30278968, Avg. loss: 0.019341\n",
      "Total training time: 24.84 seconds.\n",
      "-- Epoch 368\n",
      "Norm: 6.72, NNZs: 13889, Bias: 2.613094, T: 30361472, Avg. loss: 0.019300\n",
      "Total training time: 24.90 seconds.\n",
      "-- Epoch 369\n",
      "Norm: 6.71, NNZs: 13877, Bias: 2.615167, T: 30443976, Avg. loss: 0.019260\n",
      "Total training time: 24.96 seconds.\n",
      "-- Epoch 370\n",
      "Norm: 6.71, NNZs: 13874, Bias: 2.617257, T: 30526480, Avg. loss: 0.019218\n",
      "Total training time: 25.03 seconds.\n",
      "-- Epoch 371\n",
      "Norm: 6.71, NNZs: 13865, Bias: 2.619315, T: 30608984, Avg. loss: 0.019178\n",
      "Total training time: 25.10 seconds.\n",
      "-- Epoch 372\n",
      "Norm: 6.71, NNZs: 13860, Bias: 2.621394, T: 30691488, Avg. loss: 0.019140\n",
      "Total training time: 25.17 seconds.\n",
      "-- Epoch 373\n",
      "Norm: 6.70, NNZs: 13853, Bias: 2.623451, T: 30773992, Avg. loss: 0.019101\n",
      "Total training time: 25.25 seconds.\n",
      "-- Epoch 374\n",
      "Norm: 6.70, NNZs: 13842, Bias: 2.625510, T: 30856496, Avg. loss: 0.019062\n",
      "Total training time: 25.34 seconds.\n",
      "-- Epoch 375\n",
      "Norm: 6.70, NNZs: 13834, Bias: 2.627552, T: 30939000, Avg. loss: 0.019023\n",
      "Total training time: 25.40 seconds.\n",
      "-- Epoch 376\n",
      "Norm: 6.70, NNZs: 13828, Bias: 2.629593, T: 31021504, Avg. loss: 0.018984\n",
      "Total training time: 25.46 seconds.\n",
      "-- Epoch 377\n",
      "Norm: 6.70, NNZs: 13823, Bias: 2.631627, T: 31104008, Avg. loss: 0.018944\n",
      "Total training time: 25.53 seconds.\n",
      "-- Epoch 378\n",
      "Norm: 6.69, NNZs: 13815, Bias: 2.633647, T: 31186512, Avg. loss: 0.018905\n",
      "Total training time: 25.59 seconds.\n",
      "-- Epoch 379\n",
      "Norm: 6.69, NNZs: 13815, Bias: 2.635649, T: 31269016, Avg. loss: 0.018869\n",
      "Total training time: 25.65 seconds.\n",
      "-- Epoch 380\n",
      "Norm: 6.69, NNZs: 13804, Bias: 2.637664, T: 31351520, Avg. loss: 0.018830\n",
      "Total training time: 25.72 seconds.\n",
      "-- Epoch 381\n",
      "Norm: 6.69, NNZs: 13793, Bias: 2.639673, T: 31434024, Avg. loss: 0.018790\n",
      "Total training time: 25.79 seconds.\n",
      "-- Epoch 382\n",
      "Norm: 6.68, NNZs: 13783, Bias: 2.641656, T: 31516528, Avg. loss: 0.018756\n",
      "Total training time: 25.85 seconds.\n",
      "-- Epoch 383\n",
      "Norm: 6.68, NNZs: 13779, Bias: 2.643659, T: 31599032, Avg. loss: 0.018719\n",
      "Total training time: 25.91 seconds.\n",
      "-- Epoch 384\n",
      "Norm: 6.68, NNZs: 13773, Bias: 2.645607, T: 31681536, Avg. loss: 0.018680\n",
      "Total training time: 25.97 seconds.\n",
      "-- Epoch 385\n",
      "Norm: 6.68, NNZs: 13769, Bias: 2.647597, T: 31764040, Avg. loss: 0.018645\n",
      "Total training time: 26.03 seconds.\n",
      "-- Epoch 386\n",
      "Norm: 6.67, NNZs: 13762, Bias: 2.649587, T: 31846544, Avg. loss: 0.018609\n",
      "Total training time: 26.08 seconds.\n",
      "-- Epoch 387\n",
      "Norm: 6.67, NNZs: 13751, Bias: 2.651524, T: 31929048, Avg. loss: 0.018571\n",
      "Total training time: 26.14 seconds.\n",
      "-- Epoch 388\n",
      "Norm: 6.67, NNZs: 13744, Bias: 2.653499, T: 32011552, Avg. loss: 0.018536\n",
      "Total training time: 26.19 seconds.\n",
      "-- Epoch 389\n",
      "Norm: 6.67, NNZs: 13732, Bias: 2.655441, T: 32094056, Avg. loss: 0.018501\n",
      "Total training time: 26.26 seconds.\n",
      "-- Epoch 390\n",
      "Norm: 6.66, NNZs: 13723, Bias: 2.657366, T: 32176560, Avg. loss: 0.018465\n",
      "Total training time: 26.31 seconds.\n",
      "-- Epoch 391\n",
      "Norm: 6.66, NNZs: 13720, Bias: 2.659333, T: 32259064, Avg. loss: 0.018431\n",
      "Total training time: 26.37 seconds.\n",
      "-- Epoch 392\n",
      "Norm: 6.66, NNZs: 13709, Bias: 2.661246, T: 32341568, Avg. loss: 0.018395\n",
      "Total training time: 26.43 seconds.\n",
      "-- Epoch 393\n",
      "Norm: 6.66, NNZs: 13702, Bias: 2.663178, T: 32424072, Avg. loss: 0.018359\n",
      "Total training time: 26.48 seconds.\n",
      "-- Epoch 394\n",
      "Norm: 6.66, NNZs: 13698, Bias: 2.665088, T: 32506576, Avg. loss: 0.018326\n",
      "Total training time: 26.53 seconds.\n",
      "-- Epoch 395\n",
      "Norm: 6.65, NNZs: 13690, Bias: 2.667015, T: 32589080, Avg. loss: 0.018290\n",
      "Total training time: 26.59 seconds.\n",
      "-- Epoch 396\n",
      "Norm: 6.65, NNZs: 13681, Bias: 2.668884, T: 32671584, Avg. loss: 0.018257\n",
      "Total training time: 26.64 seconds.\n",
      "-- Epoch 397\n",
      "Norm: 6.65, NNZs: 13675, Bias: 2.670801, T: 32754088, Avg. loss: 0.018222\n",
      "Total training time: 26.71 seconds.\n",
      "-- Epoch 398\n",
      "Norm: 6.65, NNZs: 13658, Bias: 2.672672, T: 32836592, Avg. loss: 0.018189\n",
      "Total training time: 26.79 seconds.\n",
      "-- Epoch 399\n",
      "Norm: 6.64, NNZs: 13648, Bias: 2.674567, T: 32919096, Avg. loss: 0.018153\n",
      "Total training time: 26.87 seconds.\n",
      "-- Epoch 400\n",
      "Norm: 6.64, NNZs: 13636, Bias: 2.676438, T: 33001600, Avg. loss: 0.018119\n",
      "Total training time: 26.97 seconds.\n",
      "-- Epoch 401\n",
      "Norm: 6.64, NNZs: 13632, Bias: 2.678330, T: 33084104, Avg. loss: 0.018088\n",
      "Total training time: 27.03 seconds.\n",
      "-- Epoch 402\n",
      "Norm: 6.64, NNZs: 13625, Bias: 2.680201, T: 33166608, Avg. loss: 0.018056\n",
      "Total training time: 27.09 seconds.\n",
      "-- Epoch 403\n",
      "Norm: 6.64, NNZs: 13618, Bias: 2.682047, T: 33249112, Avg. loss: 0.018019\n",
      "Total training time: 27.16 seconds.\n",
      "-- Epoch 404\n",
      "Norm: 6.63, NNZs: 13612, Bias: 2.683879, T: 33331616, Avg. loss: 0.017987\n",
      "Total training time: 27.21 seconds.\n",
      "-- Epoch 405\n",
      "Norm: 6.63, NNZs: 13601, Bias: 2.685744, T: 33414120, Avg. loss: 0.017958\n",
      "Total training time: 27.26 seconds.\n",
      "-- Epoch 406\n",
      "Norm: 6.63, NNZs: 13593, Bias: 2.687577, T: 33496624, Avg. loss: 0.017924\n",
      "Total training time: 27.32 seconds.\n",
      "-- Epoch 407\n",
      "Norm: 6.63, NNZs: 13581, Bias: 2.689404, T: 33579128, Avg. loss: 0.017892\n",
      "Total training time: 27.38 seconds.\n",
      "-- Epoch 408\n",
      "Norm: 6.62, NNZs: 13573, Bias: 2.691226, T: 33661632, Avg. loss: 0.017859\n",
      "Total training time: 27.44 seconds.\n",
      "-- Epoch 409\n",
      "Norm: 6.62, NNZs: 13561, Bias: 2.693043, T: 33744136, Avg. loss: 0.017829\n",
      "Total training time: 27.49 seconds.\n",
      "-- Epoch 410\n",
      "Norm: 6.62, NNZs: 13553, Bias: 2.694862, T: 33826640, Avg. loss: 0.017796\n",
      "Total training time: 27.54 seconds.\n",
      "-- Epoch 411\n",
      "Norm: 6.62, NNZs: 13545, Bias: 2.696677, T: 33909144, Avg. loss: 0.017766\n",
      "Total training time: 27.60 seconds.\n",
      "-- Epoch 412\n",
      "Norm: 6.62, NNZs: 13540, Bias: 2.698498, T: 33991648, Avg. loss: 0.017736\n",
      "Total training time: 27.66 seconds.\n",
      "-- Epoch 413\n",
      "Norm: 6.61, NNZs: 13533, Bias: 2.700283, T: 34074152, Avg. loss: 0.017705\n",
      "Total training time: 27.71 seconds.\n",
      "-- Epoch 414\n",
      "Norm: 6.61, NNZs: 13523, Bias: 2.702082, T: 34156656, Avg. loss: 0.017674\n",
      "Total training time: 27.77 seconds.\n",
      "-- Epoch 415\n",
      "Norm: 6.61, NNZs: 13519, Bias: 2.703852, T: 34239160, Avg. loss: 0.017642\n",
      "Total training time: 27.83 seconds.\n",
      "-- Epoch 416\n",
      "Norm: 6.61, NNZs: 13514, Bias: 2.705642, T: 34321664, Avg. loss: 0.017611\n",
      "Total training time: 27.91 seconds.\n",
      "-- Epoch 417\n",
      "Norm: 6.60, NNZs: 13507, Bias: 2.707397, T: 34404168, Avg. loss: 0.017581\n",
      "Total training time: 27.96 seconds.\n",
      "-- Epoch 418\n",
      "Norm: 6.60, NNZs: 13503, Bias: 2.709178, T: 34486672, Avg. loss: 0.017554\n",
      "Total training time: 28.02 seconds.\n",
      "-- Epoch 419\n",
      "Norm: 6.60, NNZs: 13497, Bias: 2.710948, T: 34569176, Avg. loss: 0.017523\n",
      "Total training time: 28.08 seconds.\n",
      "-- Epoch 420\n",
      "Norm: 6.60, NNZs: 13495, Bias: 2.712733, T: 34651680, Avg. loss: 0.017492\n",
      "Total training time: 28.14 seconds.\n",
      "-- Epoch 421\n",
      "Norm: 6.59, NNZs: 13490, Bias: 2.714438, T: 34734184, Avg. loss: 0.017462\n",
      "Total training time: 28.19 seconds.\n",
      "-- Epoch 422\n",
      "Norm: 6.59, NNZs: 13481, Bias: 2.716218, T: 34816688, Avg. loss: 0.017434\n",
      "Total training time: 28.25 seconds.\n",
      "-- Epoch 423\n",
      "Norm: 6.59, NNZs: 13467, Bias: 2.717959, T: 34899192, Avg. loss: 0.017406\n",
      "Total training time: 28.31 seconds.\n",
      "-- Epoch 424\n",
      "Norm: 6.59, NNZs: 13463, Bias: 2.719680, T: 34981696, Avg. loss: 0.017375\n",
      "Total training time: 28.37 seconds.\n",
      "-- Epoch 425\n",
      "Norm: 6.59, NNZs: 13452, Bias: 2.721421, T: 35064200, Avg. loss: 0.017348\n",
      "Total training time: 28.43 seconds.\n",
      "-- Epoch 426\n",
      "Norm: 6.58, NNZs: 13446, Bias: 2.723128, T: 35146704, Avg. loss: 0.017319\n",
      "Total training time: 28.49 seconds.\n",
      "-- Epoch 427\n",
      "Norm: 6.58, NNZs: 13435, Bias: 2.724846, T: 35229208, Avg. loss: 0.017289\n",
      "Total training time: 28.55 seconds.\n",
      "-- Epoch 428\n",
      "Norm: 6.58, NNZs: 13428, Bias: 2.726587, T: 35311712, Avg. loss: 0.017262\n",
      "Total training time: 28.60 seconds.\n",
      "-- Epoch 429\n",
      "Norm: 6.58, NNZs: 13421, Bias: 2.728267, T: 35394216, Avg. loss: 0.017235\n",
      "Total training time: 28.65 seconds.\n",
      "-- Epoch 430\n",
      "Norm: 6.57, NNZs: 13414, Bias: 2.729988, T: 35476720, Avg. loss: 0.017205\n",
      "Total training time: 28.71 seconds.\n",
      "-- Epoch 431\n",
      "Norm: 6.57, NNZs: 13408, Bias: 2.731645, T: 35559224, Avg. loss: 0.017175\n",
      "Total training time: 28.78 seconds.\n",
      "-- Epoch 432\n",
      "Norm: 6.57, NNZs: 13401, Bias: 2.733393, T: 35641728, Avg. loss: 0.017149\n",
      "Total training time: 28.83 seconds.\n",
      "-- Epoch 433\n",
      "Norm: 6.57, NNZs: 13388, Bias: 2.735061, T: 35724232, Avg. loss: 0.017122\n",
      "Total training time: 28.88 seconds.\n",
      "-- Epoch 434\n",
      "Norm: 6.57, NNZs: 13381, Bias: 2.736724, T: 35806736, Avg. loss: 0.017096\n",
      "Total training time: 28.94 seconds.\n",
      "-- Epoch 435\n",
      "Norm: 6.56, NNZs: 13377, Bias: 2.738394, T: 35889240, Avg. loss: 0.017069\n",
      "Total training time: 29.00 seconds.\n",
      "-- Epoch 436\n",
      "Norm: 6.56, NNZs: 13373, Bias: 2.740062, T: 35971744, Avg. loss: 0.017041\n",
      "Total training time: 29.05 seconds.\n",
      "-- Epoch 437\n",
      "Norm: 6.56, NNZs: 13372, Bias: 2.741735, T: 36054248, Avg. loss: 0.017013\n",
      "Total training time: 29.10 seconds.\n",
      "-- Epoch 438\n",
      "Norm: 6.56, NNZs: 13368, Bias: 2.743385, T: 36136752, Avg. loss: 0.016988\n",
      "Total training time: 29.16 seconds.\n",
      "-- Epoch 439\n",
      "Norm: 6.55, NNZs: 13361, Bias: 2.745053, T: 36219256, Avg. loss: 0.016961\n",
      "Total training time: 29.22 seconds.\n",
      "-- Epoch 440\n",
      "Norm: 6.55, NNZs: 13349, Bias: 2.746709, T: 36301760, Avg. loss: 0.016936\n",
      "Total training time: 29.27 seconds.\n",
      "-- Epoch 441\n",
      "Norm: 6.55, NNZs: 13338, Bias: 2.748344, T: 36384264, Avg. loss: 0.016910\n",
      "Total training time: 29.34 seconds.\n",
      "-- Epoch 442\n",
      "Norm: 6.55, NNZs: 13334, Bias: 2.749983, T: 36466768, Avg. loss: 0.016883\n",
      "Total training time: 29.40 seconds.\n",
      "-- Epoch 443\n",
      "Norm: 6.55, NNZs: 13325, Bias: 2.751619, T: 36549272, Avg. loss: 0.016855\n",
      "Total training time: 29.47 seconds.\n",
      "-- Epoch 444\n",
      "Norm: 6.54, NNZs: 13321, Bias: 2.753237, T: 36631776, Avg. loss: 0.016833\n",
      "Total training time: 29.55 seconds.\n",
      "-- Epoch 445\n",
      "Norm: 6.54, NNZs: 13314, Bias: 2.754863, T: 36714280, Avg. loss: 0.016807\n",
      "Total training time: 29.61 seconds.\n",
      "-- Epoch 446\n",
      "Norm: 6.54, NNZs: 13307, Bias: 2.756462, T: 36796784, Avg. loss: 0.016780\n",
      "Total training time: 29.68 seconds.\n",
      "-- Epoch 447\n",
      "Norm: 6.54, NNZs: 13299, Bias: 2.758086, T: 36879288, Avg. loss: 0.016754\n",
      "Total training time: 29.73 seconds.\n",
      "-- Epoch 448\n",
      "Norm: 6.53, NNZs: 13290, Bias: 2.759688, T: 36961792, Avg. loss: 0.016730\n",
      "Total training time: 29.81 seconds.\n",
      "-- Epoch 449\n",
      "Norm: 6.53, NNZs: 13285, Bias: 2.761304, T: 37044296, Avg. loss: 0.016706\n",
      "Total training time: 29.86 seconds.\n",
      "-- Epoch 450\n",
      "Norm: 6.53, NNZs: 13279, Bias: 2.762889, T: 37126800, Avg. loss: 0.016681\n",
      "Total training time: 29.93 seconds.\n",
      "-- Epoch 451\n",
      "Norm: 6.53, NNZs: 13272, Bias: 2.764480, T: 37209304, Avg. loss: 0.016656\n",
      "Total training time: 29.98 seconds.\n",
      "-- Epoch 452\n",
      "Norm: 6.53, NNZs: 13256, Bias: 2.766039, T: 37291808, Avg. loss: 0.016628\n",
      "Total training time: 30.04 seconds.\n",
      "-- Epoch 453\n",
      "Norm: 6.52, NNZs: 13249, Bias: 2.767647, T: 37374312, Avg. loss: 0.016608\n",
      "Total training time: 30.12 seconds.\n",
      "-- Epoch 454\n",
      "Norm: 6.52, NNZs: 13242, Bias: 2.769224, T: 37456816, Avg. loss: 0.016579\n",
      "Total training time: 30.19 seconds.\n",
      "-- Epoch 455\n",
      "Norm: 6.52, NNZs: 13237, Bias: 2.770798, T: 37539320, Avg. loss: 0.016557\n",
      "Total training time: 30.24 seconds.\n",
      "-- Epoch 456\n",
      "Norm: 6.52, NNZs: 13228, Bias: 2.772366, T: 37621824, Avg. loss: 0.016533\n",
      "Total training time: 30.30 seconds.\n",
      "-- Epoch 457\n",
      "Norm: 6.52, NNZs: 13217, Bias: 2.773921, T: 37704328, Avg. loss: 0.016509\n",
      "Total training time: 30.37 seconds.\n",
      "-- Epoch 458\n",
      "Norm: 6.51, NNZs: 13213, Bias: 2.775470, T: 37786832, Avg. loss: 0.016487\n",
      "Total training time: 30.43 seconds.\n",
      "-- Epoch 459\n",
      "Norm: 6.51, NNZs: 13210, Bias: 2.777033, T: 37869336, Avg. loss: 0.016462\n",
      "Total training time: 30.49 seconds.\n",
      "-- Epoch 460\n",
      "Norm: 6.51, NNZs: 13199, Bias: 2.778576, T: 37951840, Avg. loss: 0.016440\n",
      "Total training time: 30.54 seconds.\n",
      "-- Epoch 461\n",
      "Norm: 6.51, NNZs: 13191, Bias: 2.780130, T: 38034344, Avg. loss: 0.016416\n",
      "Total training time: 30.60 seconds.\n",
      "-- Epoch 462\n",
      "Norm: 6.50, NNZs: 13182, Bias: 2.781638, T: 38116848, Avg. loss: 0.016393\n",
      "Total training time: 30.67 seconds.\n",
      "-- Epoch 463\n",
      "Norm: 6.50, NNZs: 13177, Bias: 2.783176, T: 38199352, Avg. loss: 0.016370\n",
      "Total training time: 30.72 seconds.\n",
      "-- Epoch 464\n",
      "Norm: 6.50, NNZs: 13172, Bias: 2.784694, T: 38281856, Avg. loss: 0.016346\n",
      "Total training time: 30.78 seconds.\n",
      "-- Epoch 465\n",
      "Norm: 6.50, NNZs: 13163, Bias: 2.786234, T: 38364360, Avg. loss: 0.016324\n",
      "Total training time: 30.83 seconds.\n",
      "-- Epoch 466\n",
      "Norm: 6.50, NNZs: 13162, Bias: 2.787755, T: 38446864, Avg. loss: 0.016300\n",
      "Total training time: 30.91 seconds.\n",
      "-- Epoch 467\n",
      "Norm: 6.49, NNZs: 13157, Bias: 2.789263, T: 38529368, Avg. loss: 0.016279\n",
      "Total training time: 30.96 seconds.\n",
      "-- Epoch 468\n",
      "Norm: 6.49, NNZs: 13149, Bias: 2.790765, T: 38611872, Avg. loss: 0.016257\n",
      "Total training time: 31.01 seconds.\n",
      "-- Epoch 469\n",
      "Norm: 6.49, NNZs: 13138, Bias: 2.792267, T: 38694376, Avg. loss: 0.016235\n",
      "Total training time: 31.07 seconds.\n",
      "-- Epoch 470\n",
      "Norm: 6.49, NNZs: 13130, Bias: 2.793771, T: 38776880, Avg. loss: 0.016211\n",
      "Total training time: 31.13 seconds.\n",
      "-- Epoch 471\n",
      "Norm: 6.49, NNZs: 13127, Bias: 2.795262, T: 38859384, Avg. loss: 0.016190\n",
      "Total training time: 31.19 seconds.\n",
      "-- Epoch 472\n",
      "Norm: 6.48, NNZs: 13116, Bias: 2.796744, T: 38941888, Avg. loss: 0.016168\n",
      "Total training time: 31.24 seconds.\n",
      "-- Epoch 473\n",
      "Norm: 6.48, NNZs: 13105, Bias: 2.798244, T: 39024392, Avg. loss: 0.016147\n",
      "Total training time: 31.30 seconds.\n",
      "-- Epoch 474\n",
      "Norm: 6.48, NNZs: 13095, Bias: 2.799704, T: 39106896, Avg. loss: 0.016126\n",
      "Total training time: 31.36 seconds.\n",
      "-- Epoch 475\n",
      "Norm: 6.48, NNZs: 13090, Bias: 2.801205, T: 39189400, Avg. loss: 0.016104\n",
      "Total training time: 31.41 seconds.\n",
      "-- Epoch 476\n",
      "Norm: 6.48, NNZs: 13084, Bias: 2.802697, T: 39271904, Avg. loss: 0.016081\n",
      "Total training time: 31.47 seconds.\n",
      "-- Epoch 477\n",
      "Norm: 6.47, NNZs: 13077, Bias: 2.804130, T: 39354408, Avg. loss: 0.016061\n",
      "Total training time: 31.52 seconds.\n",
      "-- Epoch 478\n",
      "Norm: 6.47, NNZs: 13065, Bias: 2.805617, T: 39436912, Avg. loss: 0.016039\n",
      "Total training time: 31.59 seconds.\n",
      "-- Epoch 479\n",
      "Norm: 6.47, NNZs: 13060, Bias: 2.807055, T: 39519416, Avg. loss: 0.016020\n",
      "Total training time: 31.65 seconds.\n",
      "-- Epoch 480\n",
      "Norm: 6.47, NNZs: 13049, Bias: 2.808503, T: 39601920, Avg. loss: 0.015997\n",
      "Total training time: 31.73 seconds.\n",
      "-- Epoch 481\n",
      "Norm: 6.46, NNZs: 13038, Bias: 2.809949, T: 39684424, Avg. loss: 0.015977\n",
      "Total training time: 31.80 seconds.\n",
      "-- Epoch 482\n",
      "Norm: 6.46, NNZs: 13028, Bias: 2.811401, T: 39766928, Avg. loss: 0.015955\n",
      "Total training time: 31.87 seconds.\n",
      "-- Epoch 483\n",
      "Norm: 6.46, NNZs: 13019, Bias: 2.812850, T: 39849432, Avg. loss: 0.015934\n",
      "Total training time: 31.93 seconds.\n",
      "-- Epoch 484\n",
      "Norm: 6.46, NNZs: 13019, Bias: 2.814261, T: 39931936, Avg. loss: 0.015914\n",
      "Total training time: 32.02 seconds.\n",
      "-- Epoch 485\n",
      "Norm: 6.46, NNZs: 13011, Bias: 2.815721, T: 40014440, Avg. loss: 0.015895\n",
      "Total training time: 32.10 seconds.\n",
      "-- Epoch 486\n",
      "Norm: 6.45, NNZs: 13006, Bias: 2.817137, T: 40096944, Avg. loss: 0.015876\n",
      "Total training time: 32.17 seconds.\n",
      "-- Epoch 487\n",
      "Norm: 6.45, NNZs: 13000, Bias: 2.818544, T: 40179448, Avg. loss: 0.015854\n",
      "Total training time: 32.25 seconds.\n",
      "-- Epoch 488\n",
      "Norm: 6.45, NNZs: 12998, Bias: 2.819954, T: 40261952, Avg. loss: 0.015835\n",
      "Total training time: 32.32 seconds.\n",
      "-- Epoch 489\n",
      "Norm: 6.45, NNZs: 12988, Bias: 2.821390, T: 40344456, Avg. loss: 0.015816\n",
      "Total training time: 32.38 seconds.\n",
      "-- Epoch 490\n",
      "Norm: 6.45, NNZs: 12978, Bias: 2.822795, T: 40426960, Avg. loss: 0.015795\n",
      "Total training time: 32.45 seconds.\n",
      "-- Epoch 491\n",
      "Norm: 6.44, NNZs: 12980, Bias: 2.824188, T: 40509464, Avg. loss: 0.015776\n",
      "Total training time: 32.52 seconds.\n",
      "-- Epoch 492\n",
      "Norm: 6.44, NNZs: 12980, Bias: 2.825607, T: 40591968, Avg. loss: 0.015757\n",
      "Total training time: 32.58 seconds.\n",
      "-- Epoch 493\n",
      "Norm: 6.44, NNZs: 12973, Bias: 2.826998, T: 40674472, Avg. loss: 0.015737\n",
      "Total training time: 32.64 seconds.\n",
      "-- Epoch 494\n",
      "Norm: 6.44, NNZs: 12959, Bias: 2.828395, T: 40756976, Avg. loss: 0.015717\n",
      "Total training time: 32.72 seconds.\n",
      "-- Epoch 495\n",
      "Norm: 6.43, NNZs: 12957, Bias: 2.829763, T: 40839480, Avg. loss: 0.015698\n",
      "Total training time: 32.90 seconds.\n",
      "-- Epoch 496\n",
      "Norm: 6.43, NNZs: 12949, Bias: 2.831186, T: 40921984, Avg. loss: 0.015679\n",
      "Total training time: 33.18 seconds.\n",
      "-- Epoch 497\n",
      "Norm: 6.43, NNZs: 12946, Bias: 2.832536, T: 41004488, Avg. loss: 0.015660\n",
      "Total training time: 33.26 seconds.\n",
      "-- Epoch 498\n",
      "Norm: 6.43, NNZs: 12935, Bias: 2.833910, T: 41086992, Avg. loss: 0.015642\n",
      "Total training time: 33.34 seconds.\n",
      "-- Epoch 499\n",
      "Norm: 6.43, NNZs: 12932, Bias: 2.835291, T: 41169496, Avg. loss: 0.015624\n",
      "Total training time: 33.41 seconds.\n",
      "-- Epoch 500\n",
      "Norm: 6.42, NNZs: 12931, Bias: 2.836647, T: 41252000, Avg. loss: 0.015604\n",
      "Total training time: 33.49 seconds.\n",
      "-- Epoch 501\n",
      "Norm: 6.42, NNZs: 12925, Bias: 2.838017, T: 41334504, Avg. loss: 0.015586\n",
      "Total training time: 33.56 seconds.\n",
      "-- Epoch 502\n",
      "Norm: 6.42, NNZs: 12924, Bias: 2.839383, T: 41417008, Avg. loss: 0.015568\n",
      "Total training time: 33.63 seconds.\n",
      "-- Epoch 503\n",
      "Norm: 6.42, NNZs: 12922, Bias: 2.840734, T: 41499512, Avg. loss: 0.015549\n",
      "Total training time: 33.71 seconds.\n",
      "-- Epoch 504\n",
      "Norm: 6.42, NNZs: 12913, Bias: 2.842100, T: 41582016, Avg. loss: 0.015530\n",
      "Total training time: 33.78 seconds.\n",
      "-- Epoch 505\n",
      "Norm: 6.41, NNZs: 12903, Bias: 2.843422, T: 41664520, Avg. loss: 0.015513\n",
      "Total training time: 33.83 seconds.\n",
      "-- Epoch 506\n",
      "Norm: 6.41, NNZs: 12895, Bias: 2.844765, T: 41747024, Avg. loss: 0.015493\n",
      "Total training time: 33.90 seconds.\n",
      "-- Epoch 507\n",
      "Norm: 6.41, NNZs: 12891, Bias: 2.846106, T: 41829528, Avg. loss: 0.015476\n",
      "Total training time: 33.96 seconds.\n",
      "-- Epoch 508\n",
      "Norm: 6.41, NNZs: 12882, Bias: 2.847453, T: 41912032, Avg. loss: 0.015460\n",
      "Total training time: 34.02 seconds.\n",
      "-- Epoch 509\n",
      "Norm: 6.41, NNZs: 12878, Bias: 2.848779, T: 41994536, Avg. loss: 0.015440\n",
      "Total training time: 34.09 seconds.\n",
      "-- Epoch 510\n",
      "Norm: 6.40, NNZs: 12874, Bias: 2.850110, T: 42077040, Avg. loss: 0.015419\n",
      "Total training time: 34.15 seconds.\n",
      "-- Epoch 511\n",
      "Norm: 6.40, NNZs: 12863, Bias: 2.851436, T: 42159544, Avg. loss: 0.015404\n",
      "Total training time: 34.22 seconds.\n",
      "-- Epoch 512\n",
      "Norm: 6.40, NNZs: 12852, Bias: 2.852743, T: 42242048, Avg. loss: 0.015387\n",
      "Total training time: 34.29 seconds.\n",
      "-- Epoch 513\n",
      "Norm: 6.40, NNZs: 12848, Bias: 2.854060, T: 42324552, Avg. loss: 0.015370\n",
      "Total training time: 34.38 seconds.\n",
      "-- Epoch 514\n",
      "Norm: 6.40, NNZs: 12841, Bias: 2.855387, T: 42407056, Avg. loss: 0.015353\n",
      "Total training time: 34.45 seconds.\n",
      "-- Epoch 515\n",
      "Norm: 6.39, NNZs: 12835, Bias: 2.856678, T: 42489560, Avg. loss: 0.015335\n",
      "Total training time: 34.53 seconds.\n",
      "-- Epoch 516\n",
      "Norm: 6.39, NNZs: 12823, Bias: 2.857994, T: 42572064, Avg. loss: 0.015320\n",
      "Total training time: 34.61 seconds.\n",
      "-- Epoch 517\n",
      "Norm: 6.39, NNZs: 12821, Bias: 2.859279, T: 42654568, Avg. loss: 0.015303\n",
      "Total training time: 34.70 seconds.\n",
      "-- Epoch 518\n",
      "Norm: 6.39, NNZs: 12813, Bias: 2.860593, T: 42737072, Avg. loss: 0.015284\n",
      "Total training time: 34.77 seconds.\n",
      "-- Epoch 519\n",
      "Norm: 6.39, NNZs: 12803, Bias: 2.861882, T: 42819576, Avg. loss: 0.015269\n",
      "Total training time: 34.85 seconds.\n",
      "-- Epoch 520\n",
      "Norm: 6.38, NNZs: 12798, Bias: 2.863157, T: 42902080, Avg. loss: 0.015251\n",
      "Total training time: 34.94 seconds.\n",
      "-- Epoch 521\n",
      "Norm: 6.38, NNZs: 12791, Bias: 2.864459, T: 42984584, Avg. loss: 0.015235\n",
      "Total training time: 35.00 seconds.\n",
      "-- Epoch 522\n",
      "Norm: 6.38, NNZs: 12783, Bias: 2.865720, T: 43067088, Avg. loss: 0.015219\n",
      "Total training time: 35.07 seconds.\n",
      "-- Epoch 523\n",
      "Norm: 6.38, NNZs: 12783, Bias: 2.867011, T: 43149592, Avg. loss: 0.015203\n",
      "Total training time: 35.14 seconds.\n",
      "-- Epoch 524\n",
      "Norm: 6.38, NNZs: 12779, Bias: 2.868271, T: 43232096, Avg. loss: 0.015186\n",
      "Total training time: 35.19 seconds.\n",
      "-- Epoch 525\n",
      "Norm: 6.37, NNZs: 12771, Bias: 2.869541, T: 43314600, Avg. loss: 0.015170\n",
      "Total training time: 35.24 seconds.\n",
      "-- Epoch 526\n",
      "Norm: 6.37, NNZs: 12767, Bias: 2.870802, T: 43397104, Avg. loss: 0.015154\n",
      "Total training time: 35.29 seconds.\n",
      "-- Epoch 527\n",
      "Norm: 6.37, NNZs: 12758, Bias: 2.872062, T: 43479608, Avg. loss: 0.015137\n",
      "Total training time: 35.35 seconds.\n",
      "-- Epoch 528\n",
      "Norm: 6.37, NNZs: 12752, Bias: 2.873317, T: 43562112, Avg. loss: 0.015121\n",
      "Total training time: 35.41 seconds.\n",
      "-- Epoch 529\n",
      "Norm: 6.37, NNZs: 12741, Bias: 2.874563, T: 43644616, Avg. loss: 0.015105\n",
      "Total training time: 35.46 seconds.\n",
      "-- Epoch 530\n",
      "Norm: 6.36, NNZs: 12737, Bias: 2.875832, T: 43727120, Avg. loss: 0.015090\n",
      "Total training time: 35.51 seconds.\n",
      "-- Epoch 531\n",
      "Norm: 6.36, NNZs: 12730, Bias: 2.877068, T: 43809624, Avg. loss: 0.015074\n",
      "Total training time: 35.57 seconds.\n",
      "-- Epoch 532\n",
      "Norm: 6.36, NNZs: 12725, Bias: 2.878310, T: 43892128, Avg. loss: 0.015057\n",
      "Total training time: 35.63 seconds.\n",
      "-- Epoch 533\n",
      "Norm: 6.36, NNZs: 12717, Bias: 2.879553, T: 43974632, Avg. loss: 0.015043\n",
      "Total training time: 35.68 seconds.\n",
      "-- Epoch 534\n",
      "Norm: 6.36, NNZs: 12706, Bias: 2.880816, T: 44057136, Avg. loss: 0.015025\n",
      "Total training time: 35.73 seconds.\n",
      "-- Epoch 535\n",
      "Norm: 6.35, NNZs: 12697, Bias: 2.882028, T: 44139640, Avg. loss: 0.015012\n",
      "Total training time: 35.79 seconds.\n",
      "-- Epoch 536\n",
      "Norm: 6.35, NNZs: 12688, Bias: 2.883254, T: 44222144, Avg. loss: 0.014995\n",
      "Total training time: 35.84 seconds.\n",
      "-- Epoch 537\n",
      "Norm: 6.35, NNZs: 12688, Bias: 2.884481, T: 44304648, Avg. loss: 0.014981\n",
      "Total training time: 35.89 seconds.\n",
      "-- Epoch 538\n",
      "Norm: 6.35, NNZs: 12685, Bias: 2.885682, T: 44387152, Avg. loss: 0.014964\n",
      "Total training time: 35.94 seconds.\n",
      "-- Epoch 539\n",
      "Norm: 6.35, NNZs: 12678, Bias: 2.886910, T: 44469656, Avg. loss: 0.014950\n",
      "Total training time: 36.00 seconds.\n",
      "-- Epoch 540\n",
      "Norm: 6.34, NNZs: 12675, Bias: 2.888139, T: 44552160, Avg. loss: 0.014935\n",
      "Total training time: 36.06 seconds.\n",
      "-- Epoch 541\n",
      "Norm: 6.34, NNZs: 12669, Bias: 2.889336, T: 44634664, Avg. loss: 0.014920\n",
      "Total training time: 36.13 seconds.\n",
      "-- Epoch 542\n",
      "Norm: 6.34, NNZs: 12660, Bias: 2.890539, T: 44717168, Avg. loss: 0.014906\n",
      "Total training time: 36.19 seconds.\n",
      "-- Epoch 543\n",
      "Norm: 6.34, NNZs: 12654, Bias: 2.891747, T: 44799672, Avg. loss: 0.014889\n",
      "Total training time: 36.25 seconds.\n",
      "-- Epoch 544\n",
      "Norm: 6.34, NNZs: 12648, Bias: 2.892946, T: 44882176, Avg. loss: 0.014874\n",
      "Total training time: 36.30 seconds.\n",
      "-- Epoch 545\n",
      "Norm: 6.33, NNZs: 12643, Bias: 2.894150, T: 44964680, Avg. loss: 0.014862\n",
      "Total training time: 36.35 seconds.\n",
      "-- Epoch 546\n",
      "Norm: 6.33, NNZs: 12635, Bias: 2.895322, T: 45047184, Avg. loss: 0.014847\n",
      "Total training time: 36.40 seconds.\n",
      "-- Epoch 547\n",
      "Norm: 6.33, NNZs: 12631, Bias: 2.896526, T: 45129688, Avg. loss: 0.014833\n",
      "Total training time: 36.46 seconds.\n",
      "-- Epoch 548\n",
      "Norm: 6.33, NNZs: 12625, Bias: 2.897716, T: 45212192, Avg. loss: 0.014818\n",
      "Total training time: 36.52 seconds.\n",
      "-- Epoch 549\n",
      "Norm: 6.33, NNZs: 12615, Bias: 2.898890, T: 45294696, Avg. loss: 0.014803\n",
      "Total training time: 36.57 seconds.\n",
      "-- Epoch 550\n",
      "Norm: 6.33, NNZs: 12604, Bias: 2.900080, T: 45377200, Avg. loss: 0.014789\n",
      "Total training time: 36.63 seconds.\n",
      "-- Epoch 551\n",
      "Norm: 6.32, NNZs: 12600, Bias: 2.901242, T: 45459704, Avg. loss: 0.014776\n",
      "Total training time: 36.70 seconds.\n",
      "-- Epoch 552\n",
      "Norm: 6.32, NNZs: 12590, Bias: 2.902427, T: 45542208, Avg. loss: 0.014762\n",
      "Total training time: 36.75 seconds.\n",
      "-- Epoch 553\n",
      "Norm: 6.32, NNZs: 12581, Bias: 2.903591, T: 45624712, Avg. loss: 0.014748\n",
      "Total training time: 36.80 seconds.\n",
      "-- Epoch 554\n",
      "Norm: 6.32, NNZs: 12578, Bias: 2.904771, T: 45707216, Avg. loss: 0.014734\n",
      "Total training time: 36.85 seconds.\n",
      "-- Epoch 555\n",
      "Norm: 6.32, NNZs: 12574, Bias: 2.905924, T: 45789720, Avg. loss: 0.014720\n",
      "Total training time: 36.92 seconds.\n",
      "-- Epoch 556\n",
      "Norm: 6.31, NNZs: 12567, Bias: 2.907078, T: 45872224, Avg. loss: 0.014706\n",
      "Total training time: 36.97 seconds.\n",
      "-- Epoch 557\n",
      "Norm: 6.31, NNZs: 12559, Bias: 2.908237, T: 45954728, Avg. loss: 0.014692\n",
      "Total training time: 37.02 seconds.\n",
      "-- Epoch 558\n",
      "Norm: 6.31, NNZs: 12553, Bias: 2.909386, T: 46037232, Avg. loss: 0.014677\n",
      "Total training time: 37.09 seconds.\n",
      "-- Epoch 559\n",
      "Norm: 6.31, NNZs: 12544, Bias: 2.910537, T: 46119736, Avg. loss: 0.014664\n",
      "Total training time: 37.16 seconds.\n",
      "-- Epoch 560\n",
      "Norm: 6.31, NNZs: 12537, Bias: 2.911663, T: 46202240, Avg. loss: 0.014651\n",
      "Total training time: 37.22 seconds.\n",
      "-- Epoch 561\n",
      "Norm: 6.30, NNZs: 12529, Bias: 2.912824, T: 46284744, Avg. loss: 0.014636\n",
      "Total training time: 37.28 seconds.\n",
      "-- Epoch 562\n",
      "Norm: 6.30, NNZs: 12523, Bias: 2.913963, T: 46367248, Avg. loss: 0.014623\n",
      "Total training time: 37.33 seconds.\n",
      "-- Epoch 563\n",
      "Norm: 6.30, NNZs: 12518, Bias: 2.915093, T: 46449752, Avg. loss: 0.014611\n",
      "Total training time: 37.39 seconds.\n",
      "-- Epoch 564\n",
      "Norm: 6.30, NNZs: 12506, Bias: 2.916242, T: 46532256, Avg. loss: 0.014597\n",
      "Total training time: 37.44 seconds.\n",
      "-- Epoch 565\n",
      "Norm: 6.30, NNZs: 12501, Bias: 2.917356, T: 46614760, Avg. loss: 0.014585\n",
      "Total training time: 37.50 seconds.\n",
      "-- Epoch 566\n",
      "Norm: 6.29, NNZs: 12495, Bias: 2.918481, T: 46697264, Avg. loss: 0.014571\n",
      "Total training time: 37.55 seconds.\n",
      "-- Epoch 567\n",
      "Norm: 6.29, NNZs: 12490, Bias: 2.919621, T: 46779768, Avg. loss: 0.014559\n",
      "Total training time: 37.61 seconds.\n",
      "-- Epoch 568\n",
      "Norm: 6.29, NNZs: 12478, Bias: 2.920718, T: 46862272, Avg. loss: 0.014544\n",
      "Total training time: 37.66 seconds.\n",
      "-- Epoch 569\n",
      "Norm: 6.29, NNZs: 12473, Bias: 2.921841, T: 46944776, Avg. loss: 0.014533\n",
      "Total training time: 37.72 seconds.\n",
      "-- Epoch 570\n",
      "Norm: 6.29, NNZs: 12466, Bias: 2.922944, T: 47027280, Avg. loss: 0.014520\n",
      "Total training time: 37.77 seconds.\n",
      "-- Epoch 571\n",
      "Norm: 6.29, NNZs: 12461, Bias: 2.924050, T: 47109784, Avg. loss: 0.014506\n",
      "Total training time: 37.84 seconds.\n",
      "-- Epoch 572\n",
      "Norm: 6.28, NNZs: 12455, Bias: 2.925161, T: 47192288, Avg. loss: 0.014494\n",
      "Total training time: 37.89 seconds.\n",
      "-- Epoch 573\n",
      "Norm: 6.28, NNZs: 12448, Bias: 2.926264, T: 47274792, Avg. loss: 0.014481\n",
      "Total training time: 37.96 seconds.\n",
      "-- Epoch 574\n",
      "Norm: 6.28, NNZs: 12441, Bias: 2.927375, T: 47357296, Avg. loss: 0.014469\n",
      "Total training time: 38.03 seconds.\n",
      "-- Epoch 575\n",
      "Norm: 6.28, NNZs: 12437, Bias: 2.928475, T: 47439800, Avg. loss: 0.014457\n",
      "Total training time: 38.09 seconds.\n",
      "-- Epoch 576\n",
      "Norm: 6.28, NNZs: 12429, Bias: 2.929561, T: 47522304, Avg. loss: 0.014444\n",
      "Total training time: 38.14 seconds.\n",
      "-- Epoch 577\n",
      "Norm: 6.27, NNZs: 12427, Bias: 2.930651, T: 47604808, Avg. loss: 0.014432\n",
      "Total training time: 38.19 seconds.\n",
      "-- Epoch 578\n",
      "Norm: 6.27, NNZs: 12422, Bias: 2.931745, T: 47687312, Avg. loss: 0.014420\n",
      "Total training time: 38.25 seconds.\n",
      "-- Epoch 579\n",
      "Norm: 6.27, NNZs: 12419, Bias: 2.932827, T: 47769816, Avg. loss: 0.014407\n",
      "Total training time: 38.33 seconds.\n",
      "-- Epoch 580\n",
      "Norm: 6.27, NNZs: 12416, Bias: 2.933915, T: 47852320, Avg. loss: 0.014396\n",
      "Total training time: 38.43 seconds.\n",
      "-- Epoch 581\n",
      "Norm: 6.27, NNZs: 12412, Bias: 2.934989, T: 47934824, Avg. loss: 0.014383\n",
      "Total training time: 38.56 seconds.\n",
      "-- Epoch 582\n",
      "Norm: 6.27, NNZs: 12400, Bias: 2.936068, T: 48017328, Avg. loss: 0.014372\n",
      "Total training time: 38.83 seconds.\n",
      "-- Epoch 583\n",
      "Norm: 6.26, NNZs: 12394, Bias: 2.937133, T: 48099832, Avg. loss: 0.014360\n",
      "Total training time: 38.90 seconds.\n",
      "-- Epoch 584\n",
      "Norm: 6.26, NNZs: 12382, Bias: 2.938195, T: 48182336, Avg. loss: 0.014347\n",
      "Total training time: 38.98 seconds.\n",
      "-- Epoch 585\n",
      "Norm: 6.26, NNZs: 12379, Bias: 2.939274, T: 48264840, Avg. loss: 0.014336\n",
      "Total training time: 39.06 seconds.\n",
      "-- Epoch 586\n",
      "Norm: 6.26, NNZs: 12373, Bias: 2.940339, T: 48347344, Avg. loss: 0.014325\n",
      "Total training time: 39.17 seconds.\n",
      "-- Epoch 587\n",
      "Norm: 6.26, NNZs: 12361, Bias: 2.941398, T: 48429848, Avg. loss: 0.014313\n",
      "Total training time: 39.26 seconds.\n",
      "-- Epoch 588\n",
      "Norm: 6.25, NNZs: 12355, Bias: 2.942442, T: 48512352, Avg. loss: 0.014300\n",
      "Total training time: 39.38 seconds.\n",
      "-- Epoch 589\n",
      "Norm: 6.25, NNZs: 12351, Bias: 2.943501, T: 48594856, Avg. loss: 0.014290\n",
      "Total training time: 39.51 seconds.\n",
      "-- Epoch 590\n",
      "Norm: 6.25, NNZs: 12347, Bias: 2.944546, T: 48677360, Avg. loss: 0.014279\n",
      "Total training time: 39.59 seconds.\n",
      "-- Epoch 591\n",
      "Norm: 6.25, NNZs: 12340, Bias: 2.945597, T: 48759864, Avg. loss: 0.014267\n",
      "Total training time: 39.67 seconds.\n",
      "-- Epoch 592\n",
      "Norm: 6.25, NNZs: 12332, Bias: 2.946629, T: 48842368, Avg. loss: 0.014253\n",
      "Total training time: 39.80 seconds.\n",
      "-- Epoch 593\n",
      "Norm: 6.25, NNZs: 12325, Bias: 2.947692, T: 48924872, Avg. loss: 0.014244\n",
      "Total training time: 39.90 seconds.\n",
      "-- Epoch 594\n",
      "Norm: 6.24, NNZs: 12317, Bias: 2.948718, T: 49007376, Avg. loss: 0.014233\n",
      "Total training time: 40.02 seconds.\n",
      "-- Epoch 595\n",
      "Norm: 6.24, NNZs: 12309, Bias: 2.949766, T: 49089880, Avg. loss: 0.014222\n",
      "Total training time: 40.14 seconds.\n",
      "-- Epoch 596\n",
      "Norm: 6.24, NNZs: 12304, Bias: 2.950792, T: 49172384, Avg. loss: 0.014211\n",
      "Total training time: 40.23 seconds.\n",
      "-- Epoch 597\n",
      "Norm: 6.24, NNZs: 12299, Bias: 2.951830, T: 49254888, Avg. loss: 0.014199\n",
      "Total training time: 40.43 seconds.\n",
      "-- Epoch 598\n",
      "Norm: 6.24, NNZs: 12291, Bias: 2.952844, T: 49337392, Avg. loss: 0.014187\n",
      "Total training time: 40.58 seconds.\n",
      "-- Epoch 599\n",
      "Norm: 6.23, NNZs: 12285, Bias: 2.953867, T: 49419896, Avg. loss: 0.014177\n",
      "Total training time: 40.70 seconds.\n",
      "-- Epoch 600\n",
      "Norm: 6.23, NNZs: 12281, Bias: 2.954885, T: 49502400, Avg. loss: 0.014166\n",
      "Total training time: 40.86 seconds.\n",
      "-- Epoch 601\n",
      "Norm: 6.23, NNZs: 12272, Bias: 2.955904, T: 49584904, Avg. loss: 0.014155\n",
      "Total training time: 41.01 seconds.\n",
      "-- Epoch 602\n",
      "Norm: 6.23, NNZs: 12263, Bias: 2.956917, T: 49667408, Avg. loss: 0.014145\n",
      "Total training time: 41.10 seconds.\n",
      "-- Epoch 603\n",
      "Norm: 6.23, NNZs: 12252, Bias: 2.957927, T: 49749912, Avg. loss: 0.014133\n",
      "Total training time: 41.31 seconds.\n",
      "-- Epoch 604\n",
      "Norm: 6.23, NNZs: 12247, Bias: 2.958935, T: 49832416, Avg. loss: 0.014124\n",
      "Total training time: 41.58 seconds.\n",
      "-- Epoch 605\n",
      "Norm: 6.22, NNZs: 12236, Bias: 2.959925, T: 49914920, Avg. loss: 0.014113\n",
      "Total training time: 41.91 seconds.\n",
      "-- Epoch 606\n",
      "Norm: 6.22, NNZs: 12228, Bias: 2.960948, T: 49997424, Avg. loss: 0.014103\n",
      "Total training time: 42.31 seconds.\n",
      "-- Epoch 607\n",
      "Norm: 6.22, NNZs: 12223, Bias: 2.961942, T: 50079928, Avg. loss: 0.014092\n",
      "Total training time: 42.58 seconds.\n",
      "-- Epoch 608\n",
      "Norm: 6.22, NNZs: 12218, Bias: 2.962933, T: 50162432, Avg. loss: 0.014081\n",
      "Total training time: 42.72 seconds.\n",
      "-- Epoch 609\n",
      "Norm: 6.22, NNZs: 12217, Bias: 2.963938, T: 50244936, Avg. loss: 0.014072\n",
      "Total training time: 42.82 seconds.\n",
      "-- Epoch 610\n",
      "Norm: 6.21, NNZs: 12209, Bias: 2.964925, T: 50327440, Avg. loss: 0.014061\n",
      "Total training time: 42.92 seconds.\n",
      "-- Epoch 611\n",
      "Norm: 6.21, NNZs: 12204, Bias: 2.965910, T: 50409944, Avg. loss: 0.014052\n",
      "Total training time: 43.01 seconds.\n",
      "-- Epoch 612\n",
      "Norm: 6.21, NNZs: 12196, Bias: 2.966900, T: 50492448, Avg. loss: 0.014040\n",
      "Total training time: 43.12 seconds.\n",
      "-- Epoch 613\n",
      "Norm: 6.21, NNZs: 12190, Bias: 2.967884, T: 50574952, Avg. loss: 0.014031\n",
      "Total training time: 43.35 seconds.\n",
      "-- Epoch 614\n",
      "Norm: 6.21, NNZs: 12185, Bias: 2.968863, T: 50657456, Avg. loss: 0.014020\n",
      "Total training time: 43.48 seconds.\n",
      "-- Epoch 615\n",
      "Norm: 6.21, NNZs: 12177, Bias: 2.969838, T: 50739960, Avg. loss: 0.014009\n",
      "Total training time: 43.63 seconds.\n",
      "-- Epoch 616\n",
      "Norm: 6.20, NNZs: 12171, Bias: 2.970820, T: 50822464, Avg. loss: 0.013999\n",
      "Total training time: 43.82 seconds.\n",
      "-- Epoch 617\n",
      "Norm: 6.20, NNZs: 12165, Bias: 2.971781, T: 50904968, Avg. loss: 0.013990\n",
      "Total training time: 44.11 seconds.\n",
      "-- Epoch 618\n",
      "Norm: 6.20, NNZs: 12160, Bias: 2.972762, T: 50987472, Avg. loss: 0.013980\n",
      "Total training time: 44.24 seconds.\n",
      "-- Epoch 619\n",
      "Norm: 6.20, NNZs: 12153, Bias: 2.973722, T: 51069976, Avg. loss: 0.013970\n",
      "Total training time: 44.37 seconds.\n",
      "-- Epoch 620\n",
      "Norm: 6.20, NNZs: 12147, Bias: 2.974681, T: 51152480, Avg. loss: 0.013960\n",
      "Total training time: 44.46 seconds.\n",
      "-- Epoch 621\n",
      "Norm: 6.20, NNZs: 12143, Bias: 2.975649, T: 51234984, Avg. loss: 0.013950\n",
      "Total training time: 44.53 seconds.\n",
      "-- Epoch 622\n",
      "Norm: 6.19, NNZs: 12139, Bias: 2.976599, T: 51317488, Avg. loss: 0.013942\n",
      "Total training time: 44.60 seconds.\n",
      "-- Epoch 623\n",
      "Norm: 6.19, NNZs: 12133, Bias: 2.977562, T: 51399992, Avg. loss: 0.013931\n",
      "Total training time: 44.68 seconds.\n",
      "-- Epoch 624\n",
      "Norm: 6.19, NNZs: 12127, Bias: 2.978505, T: 51482496, Avg. loss: 0.013921\n",
      "Total training time: 44.75 seconds.\n",
      "-- Epoch 625\n",
      "Norm: 6.19, NNZs: 12124, Bias: 2.979455, T: 51565000, Avg. loss: 0.013912\n",
      "Total training time: 44.81 seconds.\n",
      "-- Epoch 626\n",
      "Norm: 6.19, NNZs: 12115, Bias: 2.980420, T: 51647504, Avg. loss: 0.013902\n",
      "Total training time: 44.96 seconds.\n",
      "-- Epoch 627\n",
      "Norm: 6.19, NNZs: 12107, Bias: 2.981357, T: 51730008, Avg. loss: 0.013893\n",
      "Total training time: 45.25 seconds.\n",
      "-- Epoch 628\n",
      "Norm: 6.18, NNZs: 12105, Bias: 2.982285, T: 51812512, Avg. loss: 0.013883\n",
      "Total training time: 45.52 seconds.\n",
      "-- Epoch 629\n",
      "Norm: 6.18, NNZs: 12100, Bias: 2.983230, T: 51895016, Avg. loss: 0.013875\n",
      "Total training time: 45.66 seconds.\n",
      "-- Epoch 630\n",
      "Norm: 6.18, NNZs: 12092, Bias: 2.984181, T: 51977520, Avg. loss: 0.013865\n",
      "Total training time: 45.82 seconds.\n",
      "-- Epoch 631\n",
      "Norm: 6.18, NNZs: 12087, Bias: 2.985108, T: 52060024, Avg. loss: 0.013856\n",
      "Total training time: 45.95 seconds.\n",
      "Convergence after 631 epochs took 45.96 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18749775054311205"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDRegressor(penalty='elasticnet', random_state=0, max_iter=1000, tol=1e-5, l1_ratio=0.05, verbose=1)\n",
    "sgd.fit(csr_matrix(trainX), trainY)\n",
    "\n",
    "preds = sgd.predict(testX)\n",
    "diffs = preds - testY\n",
    "sumsq = np.dot(diffs, diffs)\n",
    "rmse = np.sqrt(sumsq / len(diffs))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That's a pretty good improvement from just guessing.  Let's see what words were important, and how much abv mattered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17228, 0.50686279220863983),\n",
       " (20133, 0.49121573087755716),\n",
       " (3168, 0.47855818997624389),\n",
       " (18903, -0.42229361962574269),\n",
       " (6780, 0.40464093614146163),\n",
       " (3311, 0.35504994322429345),\n",
       " (12915, -0.30869111345802763),\n",
       " (16374, 0.29445142113229972),\n",
       " (3402, 0.29318122609719283),\n",
       " (14158, 0.27980232261017818),\n",
       " (15341, 0.27888629371666618)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influencers = sorted(enumerate(sgd.coef_), key=lambda x: abs(x[1]), reverse=True)\n",
    "influencers[:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly positive weightings, and abv looks like the second on the list (20134 features after tacking on abv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_influencers(countvec, sorted_weights, start_idx, count):\n",
    "    plt.bar(np.arange(count), [(i[1]) for i in sorted_weights[start_idx:start_idx+count]],\n",
    "            color='darkgreen')\n",
    "    plt.xticks(np.arange(count), \n",
    "               [countvec.get_feature_names()[i[0]] if i[0]\n",
    "                != len(sorted_weights)-1 else 'ABV' \n",
    "                for i in sorted_weights[start_idx:start_idx+count]],\n",
    "                rotation='vertical')\n",
    "    plt.ylabel('coefficient')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAE6CAYAAAABX7UfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113b9f208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_influencers(cv, influencers, 0, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly brewery names and abv dominating the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just take it for a run through the \"menus\" and see how accurate it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random guesses first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for randomly choosing 3 beers off the menu: 0.5531046725022023\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for u in testers.index.unique():\n",
    "    udf = testers.loc[u, ['rating_user','rating_global']]\n",
    "    scores.append(untied_rank(udf.rating_user.values, \n",
    "                    udf.rating_user.values[np.random.permutation(range(len(udf)))[:3]]))\n",
    "print(f'Accuracy for randomly choosing 3 beers off the menu: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with slightly more educated guesses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "scores = []\n",
    "vecs = vecs.toarray()\n",
    "for u in tqdm(testers.index.unique()):\n",
    "    udf = testers.loc[u, ['rating_user', 'beer_id']]\n",
    "    vi_test = udf.beer_id.map(beer_id_to_vecs_index)\n",
    "    udf['preds'] = sgd.predict(vecs[vi_test, :])\n",
    "    scores.append(untied_rank(udf.rating_user.values, \n",
    "                              udf.rating_user.values[np.argsort(udf.preds.values)[:-4:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score picking the top 3 globally rated for 652 \"menus\":  0.6688086805312844\n"
     ]
    }
   ],
   "source": [
    "print(f'The average score picking the top 3 globally rated for {len(scores)} \"menus\":  {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, halfway between guessing and using the global mean ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's move on to a similar scenario, but this time we have some of the user's ratings under our belt, and can make better recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
