{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start with select columns of the biggest csv, merge them with descriptions csv, and remove users with fewer than 3 checkins and beers with fewer than 2 checkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1894852, 9)\n",
      "(114347, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "checkins = pd.read_csv('comboframe.csv', usecols=['beer_id', 'rating_user',\n",
    "                                                  'rating_global', 'user_id',\n",
    "                                                  'abv', 'brewery_name',\n",
    "                                                  'beer_style', 'beer_name',\n",
    "                                                  'checkin_id'])\n",
    "# only allow each user one rating for each beer\n",
    "checkins.drop_duplicates(subset=['beer_id', 'user_id'], inplace=True)\n",
    "print(checkins.shape)\n",
    "descrips = pd.read_csv('descriptions.csv')\n",
    "print(descrips.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1394388, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge in the descriptions and see how many checkins remain\n",
    "checkins = checkins.merge(descrips, how='inner')\n",
    "checkins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1155870, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins = checkins[checkins.user_id.map(checkins.groupby('user_id').size() > 2)]\n",
    "checkins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1129526, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins = checkins[checkins.beer_id.map(checkins.groupby('beer_id').size() > 1)]\n",
    "checkins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1129526 entries, 0 to 1394387\n",
      "Data columns (total 10 columns):\n",
      "checkin_id          1129526 non-null int64\n",
      "beer_id             1129526 non-null int64\n",
      "user_id             1129526 non-null int64\n",
      "rating_user         1129526 non-null float64\n",
      "brewery_name        1129526 non-null object\n",
      "beer_name           1129526 non-null object\n",
      "beer_style          1129526 non-null object\n",
      "rating_global       1104319 non-null float64\n",
      "abv                 1129526 non-null float64\n",
      "beer_description    1129526 non-null object\n",
      "dtypes: float64(3), int64(3), object(4)\n",
      "memory usage: 94.8+ MB\n"
     ]
    }
   ],
   "source": [
    "checkins.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1103369, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the ones with no global ratings\n",
    "checkins.dropna(subset=['rating_global'], axis=0, inplace=True)\n",
    "# and the zeros\n",
    "checkins = checkins[checkins.rating_global > 0]\n",
    "checkins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkin_id</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>821797539</td>\n",
       "      <td>2095023</td>\n",
       "      <td>3340203</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>793777280</td>\n",
       "      <td>2095023</td>\n",
       "      <td>2166716</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   checkin_id  beer_id  user_id  rating_user   brewery_name  \\\n",
       "0   821797539  2095023  3340203         3.75  Stone Brewing   \n",
       "1   793777280  2095023  2166716         3.50  Stone Brewing   \n",
       "\n",
       "                 beer_name      beer_style  rating_global  abv  \\\n",
       "0  Stone Scorpion Bowl IPA  IPA - American        3.73789  7.5   \n",
       "1  Stone Scorpion Bowl IPA  IPA - American        3.73789  7.5   \n",
       "\n",
       "                                    beer_description  \n",
       "0  To create a recipe so tropical and fruity with...  \n",
       "1  To create a recipe so tropical and fruity with...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkin_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.103369e+06</td>\n",
       "      <td>1.103369e+06</td>\n",
       "      <td>1.103369e+06</td>\n",
       "      <td>1.103369e+06</td>\n",
       "      <td>1.103369e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.546046e+08</td>\n",
       "      <td>2.094023e+06</td>\n",
       "      <td>3.826596e+00</td>\n",
       "      <td>3.828369e+00</td>\n",
       "      <td>6.927206e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.028723e+08</td>\n",
       "      <td>1.729344e+06</td>\n",
       "      <td>5.743143e-01</td>\n",
       "      <td>2.891699e-01</td>\n",
       "      <td>1.984595e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.773630e+05</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>1.536520e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.420015e+08</td>\n",
       "      <td>6.537330e+05</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>3.657270e+00</td>\n",
       "      <td>5.700000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.892611e+08</td>\n",
       "      <td>1.651536e+06</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>3.811980e+00</td>\n",
       "      <td>6.700000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.113865e+08</td>\n",
       "      <td>3.161810e+06</td>\n",
       "      <td>4.250000e+00</td>\n",
       "      <td>4.010630e+00</td>\n",
       "      <td>7.900000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.491104e+08</td>\n",
       "      <td>7.450082e+06</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>4.903410e+00</td>\n",
       "      <td>6.500000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         checkin_id       user_id   rating_user  rating_global           abv\n",
       "count  1.103369e+06  1.103369e+06  1.103369e+06   1.103369e+06  1.103369e+06\n",
       "mean   7.546046e+08  2.094023e+06  3.826596e+00   3.828369e+00  6.927206e+00\n",
       "std    1.028723e+08  1.729344e+06  5.743143e-01   2.891699e-01  1.984595e+00\n",
       "min    9.773630e+05  1.900000e+01  1.000000e-01   1.536520e+00  0.000000e+00\n",
       "25%    7.420015e+08  6.537330e+05  3.500000e+00   3.657270e+00  5.700000e+00\n",
       "50%    7.892611e+08  1.651536e+06  4.000000e+00   3.811980e+00  6.700000e+00\n",
       "75%    8.113865e+08  3.161810e+06  4.250000e+00   4.010630e+00  7.900000e+00\n",
       "max    8.491104e+08  7.450082e+06  5.000000e+00   4.903410e+00  6.500000e+01"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins[['checkin_id','user_id','rating_user','rating_global','abv']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3284"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(checkins.abv == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.100044e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.946279e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.932038e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.700000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.700000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.900000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.900000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                abv\n",
       "count  1.100044e+06\n",
       "mean   6.946279e+00\n",
       "std    1.932038e+00\n",
       "min    3.000000e-01\n",
       "25%    5.700000e+00\n",
       "50%    6.700000e+00\n",
       "75%    7.900000e+00\n",
       "max    2.900000e+01"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Those will mess up the predictions, since abv is a strong correlator with ratings.  Also get rid of that 65% abv!!\n",
    "checkins = checkins[(checkins.abv > 0) & (checkins.abv < 30)]\n",
    "checkins[['abv']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start with a scenario where we have no ratings for a user.  We'll say the user is looking at a menu of 10 beers.  With only this info, our only recourse is to recommend things in order of their global mean ratings.  Let's simulate that by taking the users who have exactly 10 ratings and seeing how the user ranked the top 3 recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4130"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a mapping from user to number of ratings can be helpful in many situations\n",
    "usercounts = checkins.groupby('user_id').size()\n",
    "tens = checkins[checkins.user_id.map(usercounts) == 10].set_index('user_id').sort_index()\n",
    "len(tens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have 413 users.  Here's the \"digital menu\" staring our first user in the face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Half Acre Beer Company</td>\n",
       "      <td>Logue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yamorido</td>\n",
       "      <td>Coup De Grace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Westside Ale Works</td>\n",
       "      <td>Weekend Juice NEIPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chilly Water Brewing Company</td>\n",
       "      <td>Wagon Wheel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6 beers brewing co.</td>\n",
       "      <td>Limelight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hemingway's Brewery</td>\n",
       "      <td>Doug's Courage XPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Upslope Brewing Company</td>\n",
       "      <td>Hazy IPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Half Acre Beer Company</td>\n",
       "      <td>Alive In Its Jaws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Uchu Brewing</td>\n",
       "      <td>Aldebaran (#65)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Y.Market Brewing</td>\n",
       "      <td>Hysteric IPA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   brewery_name            beer_name\n",
       "0        Half Acre Beer Company                Logue\n",
       "1                      Yamorido        Coup De Grace\n",
       "2            Westside Ale Works  Weekend Juice NEIPA\n",
       "3  Chilly Water Brewing Company          Wagon Wheel\n",
       "4           6 beers brewing co.            Limelight\n",
       "5           Hemingway's Brewery   Doug's Courage XPA\n",
       "6       Upslope Brewing Company             Hazy IPA\n",
       "7        Half Acre Beer Company    Alive In Its Jaws\n",
       "8                  Uchu Brewing      Aldebaran (#65)\n",
       "9              Y.Market Brewing         Hysteric IPA"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.reset_index()[['brewery_name', 'beer_name']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how those 10 are rated globally, from best to worst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_name</th>\n",
       "      <th>rating_global</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alive In Its Jaws</td>\n",
       "      <td>4.28491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logue</td>\n",
       "      <td>4.10604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aldebaran (#65)</td>\n",
       "      <td>4.00521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hazy IPA</td>\n",
       "      <td>3.87626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weekend Juice NEIPA</td>\n",
       "      <td>3.74539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hysteric IPA</td>\n",
       "      <td>3.74126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Limelight</td>\n",
       "      <td>3.67035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coup De Grace</td>\n",
       "      <td>3.64394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wagon Wheel</td>\n",
       "      <td>3.60677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Doug's Courage XPA</td>\n",
       "      <td>3.60528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             beer_name  rating_global\n",
       "7    Alive In Its Jaws        4.28491\n",
       "0                Logue        4.10604\n",
       "8      Aldebaran (#65)        4.00521\n",
       "6             Hazy IPA        3.87626\n",
       "2  Weekend Juice NEIPA        3.74539\n",
       "9         Hysteric IPA        3.74126\n",
       "4            Limelight        3.67035\n",
       "1        Coup De Grace        3.64394\n",
       "3          Wagon Wheel        3.60677\n",
       "5   Doug's Courage XPA        3.60528"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tens.head(10)\n",
    "t.reset_index()[['beer_name', 'rating_global']].sort_values('rating_global', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and how the user rated them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_name</th>\n",
       "      <th>rating_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logue</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alive In Its Jaws</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aldebaran (#65)</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coup De Grace</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Limelight</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Doug's Courage XPA</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hazy IPA</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hysteric IPA</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weekend Juice NEIPA</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wagon Wheel</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             beer_name  rating_user\n",
       "0                Logue         3.75\n",
       "7    Alive In Its Jaws         3.75\n",
       "8      Aldebaran (#65)         3.75\n",
       "1        Coup De Grace         3.50\n",
       "4            Limelight         3.50\n",
       "5   Doug's Courage XPA         3.50\n",
       "6             Hazy IPA         3.50\n",
       "9         Hysteric IPA         3.50\n",
       "2  Weekend Juice NEIPA         3.25\n",
       "3          Wagon Wheel         3.25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reset_index()[['beer_name', 'rating_user']].sort_values('rating_user', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first user, the global mean works great:  The top 3 recommendations were the 3 the user ended up rating the highest.  This user would be happy to use this recommender again.  Before this user ever gets down to the 5th recommendation, the one that was tied for last in his actual ratings, he will hopefully have given the recommender some feedback (ratings) to make more informed decisions.  Also, a user in this situation very likely may repeat orders once he's happy with one or two, so the demands of such a recommender are different from, say, a book recommender.   Now let's see how this method works for all 413 users here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a func to deal with ties in rankings\n",
    "def untied_rank(arr, vals):\n",
    "    '''\n",
    "    Measure how well the input vals (list or np.array) has chosen\n",
    "    the top values of input arr (np.array). \n",
    "    vals must be subset of arr.\n",
    "    1.0 is perfect, 0.0 is worst.\n",
    "    '''\n",
    "    fails = 0\n",
    "    poss_fails = 0\n",
    "    ordered = np.sort(arr)\n",
    "    if max(ordered) == min(ordered): return 0.5  # like guessing, if all equal\n",
    "    for i in range(len(vals)):\n",
    "        fails += sum(arr > vals[i])\n",
    "        arr = np.delete(arr, np.where(arr == vals[i])[0][0])\n",
    "        poss_fails += sum(ordered > ordered[i])\n",
    "    \n",
    "    return 1 - fails / poss_fails\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The perfect rankings for the first user, above\n",
    "untied_rank(t.rating_user.values, t.rating_user.values[np.argsort(t.rating_global.values)[:-4:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score picking the top 3 globally rated for 413 \"menus\":  0.7535366940665592\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for u in tens.index.unique():\n",
    "    uten = tens.loc[u, ['rating_user','rating_global']]\n",
    "    scores.append(untied_rank(uten.rating_user.values, \n",
    "                              uten.rating_user.values[np.argsort(uten.rating_global.values)[:-4:-1]]))\n",
    "print(f'The average score picking the top 3 globally rated for 413 \"menus\":  {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what a .75 score looks like for one user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The global rankings/recommendations for that user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_name</th>\n",
       "      <th>rating_global</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cone Wars: Idaho 7 Fresh Hop IPA</td>\n",
       "      <td>4.03846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wicked Haze</td>\n",
       "      <td>3.91730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Emergent IPA</td>\n",
       "      <td>3.91379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Melon Rye IIIPA</td>\n",
       "      <td>3.90668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Citra IPA</td>\n",
       "      <td>3.81579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Humulus Unum Amarillo</td>\n",
       "      <td>3.77632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Capo Blood Orange IPA</td>\n",
       "      <td>3.71512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fraud Alert</td>\n",
       "      <td>3.62619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hophoria IPA</td>\n",
       "      <td>3.58289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bullseye Pale Ale</td>\n",
       "      <td>3.57362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          beer_name  rating_global\n",
       "5  Cone Wars: Idaho 7 Fresh Hop IPA        4.03846\n",
       "0                       Wicked Haze        3.91730\n",
       "9                  The Emergent IPA        3.91379\n",
       "1                   Melon Rye IIIPA        3.90668\n",
       "6                         Citra IPA        3.81579\n",
       "3             Humulus Unum Amarillo        3.77632\n",
       "4             Capo Blood Orange IPA        3.71512\n",
       "2                       Fraud Alert        3.62619\n",
       "7                      Hophoria IPA        3.58289\n",
       "8                 Bullseye Pale Ale        3.57362"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tens.iloc[360:370, :]\n",
    "t.reset_index()[['beer_name', 'rating_global']].sort_values('rating_global', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and actual ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_name</th>\n",
       "      <th>rating_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wicked Haze</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cone Wars: Idaho 7 Fresh Hop IPA</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Melon Rye IIIPA</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Citra IPA</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fraud Alert</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Humulus Unum Amarillo</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Capo Blood Orange IPA</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hophoria IPA</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bullseye Pale Ale</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Emergent IPA</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          beer_name  rating_user\n",
       "0                       Wicked Haze         4.25\n",
       "5  Cone Wars: Idaho 7 Fresh Hop IPA         4.00\n",
       "1                   Melon Rye IIIPA         3.75\n",
       "6                         Citra IPA         3.75\n",
       "2                       Fraud Alert         3.50\n",
       "3             Humulus Unum Amarillo         3.50\n",
       "4             Capo Blood Orange IPA         3.50\n",
       "7                      Hophoria IPA         3.50\n",
       "8                 Bullseye Pale Ale         3.50\n",
       "9                  The Emergent IPA         3.50"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reset_index()[['beer_name', 'rating_user']].sort_values('rating_user', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's good recommendations:  The top 2 came in second and first, and the 3rd rec was actually tied for 5th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The worst-case scenario for this recommender method is when a user rates everything pretty equally, and the high global rating beers are unlikely to be picked out from the others by this user.  An example is this user whose ratings score 0.0 by this system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_name</th>\n",
       "      <th>rating_global</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Peconic Project</td>\n",
       "      <td>4.07962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wicked Smaht</td>\n",
       "      <td>3.97449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DJ Night</td>\n",
       "      <td>3.80664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sigint</td>\n",
       "      <td>3.70455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Citralization</td>\n",
       "      <td>3.70051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Go Bigg Or Go Home IPA</td>\n",
       "      <td>3.66873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Smilin' Mike</td>\n",
       "      <td>3.62981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Useful Idiot</td>\n",
       "      <td>3.59771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daayani</td>\n",
       "      <td>3.59000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West Coast IPA</td>\n",
       "      <td>3.56235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                beer_name  rating_global\n",
       "6         Peconic Project        4.07962\n",
       "7            Wicked Smaht        3.97449\n",
       "1                DJ Night        3.80664\n",
       "3                  Sigint        3.70455\n",
       "9           Citralization        3.70051\n",
       "5  Go Bigg Or Go Home IPA        3.66873\n",
       "8            Smilin' Mike        3.62981\n",
       "4           Useful Idiot         3.59771\n",
       "2                 Daayani        3.59000\n",
       "0          West Coast IPA        3.56235"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tens.iloc[90:100, :]\n",
    "t.reset_index()[['beer_name', 'rating_global']].sort_values('rating_global', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and how this user made the recommender look horrible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_name</th>\n",
       "      <th>rating_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Useful Idiot</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Go Bigg Or Go Home IPA</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West Coast IPA</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DJ Night</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daayani</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sigint</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Peconic Project</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wicked Smaht</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Smilin' Mike</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Citralization</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                beer_name  rating_user\n",
       "4           Useful Idiot          4.50\n",
       "5  Go Bigg Or Go Home IPA         4.25\n",
       "0          West Coast IPA         4.00\n",
       "1                DJ Night         4.00\n",
       "2                 Daayani         4.00\n",
       "3                  Sigint         4.00\n",
       "6         Peconic Project         4.00\n",
       "7            Wicked Smaht         4.00\n",
       "8            Smilin' Mike         4.00\n",
       "9           Citralization         4.00"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reset_index()[['beer_name', 'rating_user']].sort_values('rating_user', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommender's top 3 picks actually all tied for 3rd in the user's ratings...and for last."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, here's how the same system does for picking top 1 to top 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allscores = []\n",
    "for x in range(2,12):\n",
    "    scores = []\n",
    "    for u in tens.index.unique():\n",
    "        uten = tens.loc[u, ['rating_user','rating_global']]\n",
    "        scores.append(untied_rank(uten.rating_user.values, \n",
    "                    uten.rating_user.values[np.argsort(uten.rating_global.values)[:-x:-1]]))\n",
    "    allscores.append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmfPY8UC6PwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110ae2390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,11), allscores, color='darkgreen')\n",
    "plt.title('Recommender accuracy when picking the top rated beers')\n",
    "plt.xlabel('Number of items recommended out of ten')\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check that random picks score about 0.5 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for randomly choosing 3 beers off the menu: 0.5370659516581834\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for u in tens.index.unique():\n",
    "    uten = tens.loc[u, ['rating_user','rating_global']]\n",
    "    scores.append(untied_rank(uten.rating_user.values, \n",
    "                    uten.rating_user.values[np.random.permutation(range(10))[:3]]))\n",
    "print(f'Accuracy for randomly choosing 3 beers off the menu: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now what about if we don't even have any global ratings for a beer?  This could be for a new beer, or maybe a brewer is trying to figure out what beer to brew in order to get good ratings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our main weapons here will be the one numerical feature that tends to correlate to ratings most, and the words comprising the brewery name, the beer name, and the beer description, as provided by the brewery.  The numerical feature is the alcohol by volume (abv) and we'll train a Linear Regressor on that plus a binary vector encoding of the words we have for each beer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set the `max_df` threshold (the highest ratio of descriptions a word can appear in before it is dropped for being considered not informative enough to keep making noise) to 0.17 -- That was the divider that just barely keeps 'hop' and 'dry' but not 'brewed' and 'ale'.  \n",
    "I also made the term vectors binary, since the goal is to identify keywords that correlate to ratings, not to classify the text as belonging to some category.  This makes the relative importance of the words easier to interpret after training, too.  If the word \"hoppy\" appears 3 times in one description, it doesn't seem like it should drive down the word's weight for all the beers whose descriptions have it only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the beer and brewery names to the description\n",
    "checkins['beer_description'] = checkins.brewery_name + ' ' + checkins.beer_name + ' ' + checkins.beer_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkin_id</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>821797539</td>\n",
       "      <td>2095023</td>\n",
       "      <td>3340203</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Stone Brewing Stone Scorpion Bowl IPA To creat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   checkin_id  beer_id  user_id  rating_user   brewery_name  \\\n",
       "0   821797539  2095023  3340203         3.75  Stone Brewing   \n",
       "\n",
       "                 beer_name      beer_style  rating_global  abv  \\\n",
       "0  Stone Scorpion Bowl IPA  IPA - American        3.73789  7.5   \n",
       "\n",
       "                                    beer_description  \n",
       "0  Stone Brewing Stone Scorpion Bowl IPA To creat...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87017, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize just one of each beer description, to not skew document frequency\n",
    "uniqs = checkins[['beer_id', 'beer_description']].drop_duplicates(subset=['beer_id'])\n",
    "uniqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87017, 20133)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english', min_df=5, max_df=0.17, binary=True)\n",
    "vecs = cv.fit_transform(uniqs.beer_description)\n",
    "vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're dealing with sparse matrices, so we'll need some scipy help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "# get the abv and global mean for each unique beer, to align with the term vectors for training\n",
    "uniqs['abv'] = uniqs.beer_id.map(checkins.groupby('beer_id')['abv'].mean())\n",
    "uniqs['rating_global'] = uniqs.beer_id.map(checkins.groupby('beer_id')['rating_global'].mean())\n",
    "# tack the abvs onto the vecs, after scaling them down to around the binary 1's\n",
    "vecs = hstack([vecs, uniqs.abv.values[:, np.newaxis] / 5.0])  # need the new axis for hstack\n",
    "vecs = csr_matrix(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87017, 20134)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at how the global ratings are distributed, just to know how random guessing would do for predicting ratings for a new beer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEKCAYAAAAxXHOuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyoHFzMyycmAxM7Os/j9WCJRpB376qgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1174e3208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ignore the couple of ratings that are outliers to the downside, for clarity in the chart\n",
    "uniqs[uniqs.rating_global > 2.4].rating_global.plot(kind='hist', bins=20, color='darkgreen')\n",
    "plt.xlabel('global mean rating by beer')\n",
    "plt.ylabel('count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a normal distribution leaning a little bit left for whatever reason.  \n",
    "The standard deviation should be a pretty good indicator of RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard deviation of the first ratings: 0.27731986651059803\n",
      "RMSE of the test batch: 0.2713745087355389\n"
     ]
    }
   ],
   "source": [
    "# shuffle the ratings\n",
    "globmeans = np.random.permutation(uniqs.rating_global.values)\n",
    "# Calculate the mean of all but 1000 beers\n",
    "head = globmeans[:-1000]\n",
    "tail = globmeans[-1000:]\n",
    "meanhead = np.mean(head)\n",
    "# See how far each of the final 1000 is from that mean\n",
    "devs = tail - meanhead\n",
    "# Get the RMSE of those estimates\n",
    "sumsqerr = np.dot(devs, devs)\n",
    "rmse = np.sqrt(sumsqerr / len(devs))\n",
    "print(f'standard deviation of the first ratings: {np.std(head)}')\n",
    "print(f'RMSE of the test batch: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's kind of a baseline goal to beat, and we'll see how much better a Regressor can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've fit a Vectorizer to all words and added abvs/5, but we'll only train on some of them, and then test on the rest.  \n",
    "So we need to split off the test group now.  \n",
    "To the tens group from before, we'll add the elevens, for more numbers.  We can test the Regression on their global means and then see how recommendations based on the model's predictions do with our custom accuracy score from before.  Most likely, the model will fare halfway between random choices and known global means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testers = checkins[(checkins.user_id.map(usercounts) == 10) | \n",
    "                   (checkins.user_id.map(usercounts) == 11)].set_index('user_id').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6759"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're just using the unique term vectors to train and test on, so now is the time to split off all the beers that these tens and elevens have rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testIDs = set(testers.beer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4513, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbeers = uniqs[uniqs.beer_id.apply(lambda id: id in testIDs)]\n",
    "testbeers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82504, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainbeers = uniqs[uniqs.beer_id.apply(lambda id: id not in testIDs)]\n",
    "trainbeers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the vecs sparse array is struggling to split into train and test based on the above boolean array, so plan B:\n",
    "uniqs.reset_index(inplace=True)\n",
    "# now with integer range as index, the uniqs/vecs index can be looked up for each beer_id\n",
    "beer_id_to_vecs_index = dict(zip(uniqs.beer_id, uniqs.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vi_test = testbeers.beer_id.map(beer_id_to_vecs_index)\n",
    "vi_train = trainbeers.beer_id.map(beer_id_to_vecs_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX = vecs.toarray()[vi_train, :]\n",
    "testX = vecs.toarray()[vi_test, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82504 training beers and 4513 test beers\n"
     ]
    }
   ],
   "source": [
    "trainY = trainbeers.rating_global\n",
    "testY = testbeers.rating_global\n",
    "print(f'{len(trainY)} training beers and {len(testY)} test beers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 3.45, NNZs: 18391, Bias: 0.113478, T: 82504, Avg. loss: 0.247669\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.79, NNZs: 18185, Bias: 0.167238, T: 165008, Avg. loss: 0.203619\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.03, NNZs: 18071, Bias: 0.211476, T: 247512, Avg. loss: 0.190149\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.21, NNZs: 17973, Bias: 0.250494, T: 330016, Avg. loss: 0.181073\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.37, NNZs: 17890, Bias: 0.285942, T: 412520, Avg. loss: 0.173974\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.49, NNZs: 17833, Bias: 0.318665, T: 495024, Avg. loss: 0.168024\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 4.63, NNZs: 17780, Bias: 0.349613, T: 577528, Avg. loss: 0.162971\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.73, NNZs: 17746, Bias: 0.378543, T: 660032, Avg. loss: 0.158427\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.83, NNZs: 17727, Bias: 0.406207, T: 742536, Avg. loss: 0.154334\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4.91, NNZs: 17687, Bias: 0.432489, T: 825040, Avg. loss: 0.150625\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 5.00, NNZs: 17652, Bias: 0.457821, T: 907544, Avg. loss: 0.147197\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 5.08, NNZs: 17610, Bias: 0.482231, T: 990048, Avg. loss: 0.144050\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 5.15, NNZs: 17598, Bias: 0.505776, T: 1072552, Avg. loss: 0.141088\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 5.22, NNZs: 17555, Bias: 0.528523, T: 1155056, Avg. loss: 0.138281\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 5.28, NNZs: 17509, Bias: 0.550528, T: 1237560, Avg. loss: 0.135680\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 5.34, NNZs: 17512, Bias: 0.571959, T: 1320064, Avg. loss: 0.133182\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 5.41, NNZs: 17474, Bias: 0.592931, T: 1402568, Avg. loss: 0.130823\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 5.45, NNZs: 17457, Bias: 0.613049, T: 1485072, Avg. loss: 0.128598\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 5.51, NNZs: 17431, Bias: 0.632878, T: 1567576, Avg. loss: 0.126438\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 5.56, NNZs: 17402, Bias: 0.652188, T: 1650080, Avg. loss: 0.124376\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 5.60, NNZs: 17377, Bias: 0.670998, T: 1732584, Avg. loss: 0.122409\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 5.65, NNZs: 17352, Bias: 0.689412, T: 1815088, Avg. loss: 0.120503\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 5.69, NNZs: 17320, Bias: 0.707468, T: 1897592, Avg. loss: 0.118709\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 5.73, NNZs: 17292, Bias: 0.725177, T: 1980096, Avg. loss: 0.116936\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 5.77, NNZs: 17271, Bias: 0.742423, T: 2062600, Avg. loss: 0.115241\n",
      "Total training time: 1.52 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 5.81, NNZs: 17265, Bias: 0.759411, T: 2145104, Avg. loss: 0.113609\n",
      "Total training time: 1.57 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 5.85, NNZs: 17226, Bias: 0.776109, T: 2227608, Avg. loss: 0.112036\n",
      "Total training time: 1.62 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 5.88, NNZs: 17201, Bias: 0.792493, T: 2310112, Avg. loss: 0.110489\n",
      "Total training time: 1.68 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 5.91, NNZs: 17196, Bias: 0.808508, T: 2392616, Avg. loss: 0.109003\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 5.95, NNZs: 17179, Bias: 0.824302, T: 2475120, Avg. loss: 0.107583\n",
      "Total training time: 1.79 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 5.98, NNZs: 17175, Bias: 0.839863, T: 2557624, Avg. loss: 0.106166\n",
      "Total training time: 1.84 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 6.01, NNZs: 17156, Bias: 0.855064, T: 2640128, Avg. loss: 0.104819\n",
      "Total training time: 1.89 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 6.04, NNZs: 17136, Bias: 0.870114, T: 2722632, Avg. loss: 0.103492\n",
      "Total training time: 1.95 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6.07, NNZs: 17122, Bias: 0.884920, T: 2805136, Avg. loss: 0.102223\n",
      "Total training time: 2.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 6.10, NNZs: 17103, Bias: 0.899463, T: 2887640, Avg. loss: 0.100963\n",
      "Total training time: 2.10 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 6.13, NNZs: 17073, Bias: 0.913858, T: 2970144, Avg. loss: 0.099725\n",
      "Total training time: 2.15 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 6.15, NNZs: 17050, Bias: 0.927939, T: 3052648, Avg. loss: 0.098564\n",
      "Total training time: 2.20 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 6.18, NNZs: 17029, Bias: 0.941900, T: 3135152, Avg. loss: 0.097405\n",
      "Total training time: 2.25 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6.20, NNZs: 17011, Bias: 0.955551, T: 3217656, Avg. loss: 0.096273\n",
      "Total training time: 2.30 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 6.22, NNZs: 17002, Bias: 0.969132, T: 3300160, Avg. loss: 0.095169\n",
      "Total training time: 2.36 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 6.25, NNZs: 16990, Bias: 0.982472, T: 3382664, Avg. loss: 0.094109\n",
      "Total training time: 2.43 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 6.27, NNZs: 16984, Bias: 0.995634, T: 3465168, Avg. loss: 0.093051\n",
      "Total training time: 2.48 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 6.29, NNZs: 16969, Bias: 1.008660, T: 3547672, Avg. loss: 0.092029\n",
      "Total training time: 2.54 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 6.31, NNZs: 16954, Bias: 1.021431, T: 3630176, Avg. loss: 0.091027\n",
      "Total training time: 2.59 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 6.33, NNZs: 16949, Bias: 1.034107, T: 3712680, Avg. loss: 0.090037\n",
      "Total training time: 2.64 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 6.35, NNZs: 16937, Bias: 1.046610, T: 3795184, Avg. loss: 0.089061\n",
      "Total training time: 2.69 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 6.37, NNZs: 16918, Bias: 1.058955, T: 3877688, Avg. loss: 0.088143\n",
      "Total training time: 2.77 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 6.39, NNZs: 16896, Bias: 1.071213, T: 3960192, Avg. loss: 0.087220\n",
      "Total training time: 2.83 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 6.41, NNZs: 16885, Bias: 1.083150, T: 4042696, Avg. loss: 0.086313\n",
      "Total training time: 2.88 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 6.43, NNZs: 16871, Bias: 1.095131, T: 4125200, Avg. loss: 0.085446\n",
      "Total training time: 2.94 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 6.44, NNZs: 16861, Bias: 1.106870, T: 4207704, Avg. loss: 0.084575\n",
      "Total training time: 3.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 6.46, NNZs: 16844, Bias: 1.118510, T: 4290208, Avg. loss: 0.083732\n",
      "Total training time: 3.05 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 6.48, NNZs: 16837, Bias: 1.130069, T: 4372712, Avg. loss: 0.082890\n",
      "Total training time: 3.11 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 6.50, NNZs: 16824, Bias: 1.141382, T: 4455216, Avg. loss: 0.082069\n",
      "Total training time: 3.17 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 6.51, NNZs: 16797, Bias: 1.152667, T: 4537720, Avg. loss: 0.081274\n",
      "Total training time: 3.23 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 6.53, NNZs: 16799, Bias: 1.163765, T: 4620224, Avg. loss: 0.080498\n",
      "Total training time: 3.29 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 6.54, NNZs: 16792, Bias: 1.174749, T: 4702728, Avg. loss: 0.079732\n",
      "Total training time: 3.34 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 6.56, NNZs: 16777, Bias: 1.185658, T: 4785232, Avg. loss: 0.078966\n",
      "Total training time: 3.39 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 6.57, NNZs: 16759, Bias: 1.196433, T: 4867736, Avg. loss: 0.078245\n",
      "Total training time: 3.45 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 6.58, NNZs: 16748, Bias: 1.207071, T: 4950240, Avg. loss: 0.077501\n",
      "Total training time: 3.50 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 6.60, NNZs: 16741, Bias: 1.217635, T: 5032744, Avg. loss: 0.076793\n",
      "Total training time: 3.55 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 6.61, NNZs: 16726, Bias: 1.228106, T: 5115248, Avg. loss: 0.076089\n",
      "Total training time: 3.60 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 6.62, NNZs: 16717, Bias: 1.238407, T: 5197752, Avg. loss: 0.075395\n",
      "Total training time: 3.65 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 6.64, NNZs: 16703, Bias: 1.248644, T: 5280256, Avg. loss: 0.074725\n",
      "Total training time: 3.71 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 6.65, NNZs: 16688, Bias: 1.258780, T: 5362760, Avg. loss: 0.074061\n",
      "Total training time: 3.76 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 6.66, NNZs: 16687, Bias: 1.268841, T: 5445264, Avg. loss: 0.073399\n",
      "Total training time: 3.81 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 6.67, NNZs: 16672, Bias: 1.278763, T: 5527768, Avg. loss: 0.072754\n",
      "Total training time: 3.87 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 6.68, NNZs: 16657, Bias: 1.288621, T: 5610272, Avg. loss: 0.072119\n",
      "Total training time: 3.92 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 6.69, NNZs: 16638, Bias: 1.298360, T: 5692776, Avg. loss: 0.071497\n",
      "Total training time: 3.98 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 6.71, NNZs: 16619, Bias: 1.308096, T: 5775280, Avg. loss: 0.070882\n",
      "Total training time: 4.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 6.72, NNZs: 16612, Bias: 1.317655, T: 5857784, Avg. loss: 0.070272\n",
      "Total training time: 4.11 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 6.73, NNZs: 16599, Bias: 1.327100, T: 5940288, Avg. loss: 0.069676\n",
      "Total training time: 4.32 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 6.74, NNZs: 16592, Bias: 1.336488, T: 6022792, Avg. loss: 0.069092\n",
      "Total training time: 4.44 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 6.74, NNZs: 16575, Bias: 1.345756, T: 6105296, Avg. loss: 0.068524\n",
      "Total training time: 4.51 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 6.75, NNZs: 16567, Bias: 1.355022, T: 6187800, Avg. loss: 0.067953\n",
      "Total training time: 4.59 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 6.76, NNZs: 16553, Bias: 1.364170, T: 6270304, Avg. loss: 0.067390\n",
      "Total training time: 4.67 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 6.77, NNZs: 16546, Bias: 1.373244, T: 6352808, Avg. loss: 0.066847\n",
      "Total training time: 4.76 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 6.78, NNZs: 16534, Bias: 1.382207, T: 6435312, Avg. loss: 0.066296\n",
      "Total training time: 4.81 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 6.79, NNZs: 16533, Bias: 1.391115, T: 6517816, Avg. loss: 0.065769\n",
      "Total training time: 4.87 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 6.80, NNZs: 16516, Bias: 1.399953, T: 6600320, Avg. loss: 0.065248\n",
      "Total training time: 4.93 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 6.81, NNZs: 16498, Bias: 1.408674, T: 6682824, Avg. loss: 0.064731\n",
      "Total training time: 5.01 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 6.81, NNZs: 16483, Bias: 1.417367, T: 6765328, Avg. loss: 0.064219\n",
      "Total training time: 5.07 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 6.82, NNZs: 16471, Bias: 1.425960, T: 6847832, Avg. loss: 0.063717\n",
      "Total training time: 5.13 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 6.83, NNZs: 16468, Bias: 1.434528, T: 6930336, Avg. loss: 0.063226\n",
      "Total training time: 5.19 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 6.84, NNZs: 16452, Bias: 1.443006, T: 7012840, Avg. loss: 0.062717\n",
      "Total training time: 5.24 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 6.84, NNZs: 16448, Bias: 1.451382, T: 7095344, Avg. loss: 0.062246\n",
      "Total training time: 5.30 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 6.85, NNZs: 16443, Bias: 1.459707, T: 7177848, Avg. loss: 0.061768\n",
      "Total training time: 5.35 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 6.86, NNZs: 16439, Bias: 1.467961, T: 7260352, Avg. loss: 0.061303\n",
      "Total training time: 5.41 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 6.87, NNZs: 16432, Bias: 1.476169, T: 7342856, Avg. loss: 0.060839\n",
      "Total training time: 5.46 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 6.87, NNZs: 16418, Bias: 1.484330, T: 7425360, Avg. loss: 0.060391\n",
      "Total training time: 5.51 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 6.88, NNZs: 16409, Bias: 1.492379, T: 7507864, Avg. loss: 0.059938\n",
      "Total training time: 5.56 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 6.89, NNZs: 16399, Bias: 1.500363, T: 7590368, Avg. loss: 0.059494\n",
      "Total training time: 5.62 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 6.89, NNZs: 16393, Bias: 1.508330, T: 7672872, Avg. loss: 0.059058\n",
      "Total training time: 5.68 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 6.90, NNZs: 16384, Bias: 1.516187, T: 7755376, Avg. loss: 0.058618\n",
      "Total training time: 5.82 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 6.90, NNZs: 16373, Bias: 1.524014, T: 7837880, Avg. loss: 0.058202\n",
      "Total training time: 5.92 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 6.91, NNZs: 16370, Bias: 1.531730, T: 7920384, Avg. loss: 0.057776\n",
      "Total training time: 6.05 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 6.91, NNZs: 16367, Bias: 1.539460, T: 8002888, Avg. loss: 0.057372\n",
      "Total training time: 6.17 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 6.92, NNZs: 16349, Bias: 1.547145, T: 8085392, Avg. loss: 0.056951\n",
      "Total training time: 6.26 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 6.92, NNZs: 16337, Bias: 1.554688, T: 8167896, Avg. loss: 0.056553\n",
      "Total training time: 6.40 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 6.93, NNZs: 16331, Bias: 1.562232, T: 8250400, Avg. loss: 0.056153\n",
      "Total training time: 6.46 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 6.93, NNZs: 16319, Bias: 1.569689, T: 8332904, Avg. loss: 0.055766\n",
      "Total training time: 6.52 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 6.94, NNZs: 16304, Bias: 1.577131, T: 8415408, Avg. loss: 0.055374\n",
      "Total training time: 6.57 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 6.94, NNZs: 16298, Bias: 1.584477, T: 8497912, Avg. loss: 0.054993\n",
      "Total training time: 6.62 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 6.95, NNZs: 16283, Bias: 1.591800, T: 8580416, Avg. loss: 0.054612\n",
      "Total training time: 6.67 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 6.95, NNZs: 16266, Bias: 1.599032, T: 8662920, Avg. loss: 0.054241\n",
      "Total training time: 6.72 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 6.96, NNZs: 16250, Bias: 1.606227, T: 8745424, Avg. loss: 0.053871\n",
      "Total training time: 6.78 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 6.96, NNZs: 16242, Bias: 1.613423, T: 8827928, Avg. loss: 0.053508\n",
      "Total training time: 6.83 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 6.97, NNZs: 16226, Bias: 1.620517, T: 8910432, Avg. loss: 0.053151\n",
      "Total training time: 6.88 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 6.97, NNZs: 16213, Bias: 1.627594, T: 8992936, Avg. loss: 0.052793\n",
      "Total training time: 6.95 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 6.97, NNZs: 16199, Bias: 1.634566, T: 9075440, Avg. loss: 0.052441\n",
      "Total training time: 7.04 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 6.98, NNZs: 16196, Bias: 1.641540, T: 9157944, Avg. loss: 0.052093\n",
      "Total training time: 7.12 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 6.98, NNZs: 16180, Bias: 1.648453, T: 9240448, Avg. loss: 0.051750\n",
      "Total training time: 7.21 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 6.99, NNZs: 16175, Bias: 1.655300, T: 9322952, Avg. loss: 0.051406\n",
      "Total training time: 7.26 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 6.99, NNZs: 16168, Bias: 1.662082, T: 9405456, Avg. loss: 0.051079\n",
      "Total training time: 7.31 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 6.99, NNZs: 16154, Bias: 1.668862, T: 9487960, Avg. loss: 0.050751\n",
      "Total training time: 7.36 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 7.00, NNZs: 16147, Bias: 1.675606, T: 9570464, Avg. loss: 0.050417\n",
      "Total training time: 7.41 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 7.00, NNZs: 16139, Bias: 1.682286, T: 9652968, Avg. loss: 0.050098\n",
      "Total training time: 7.48 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 7.00, NNZs: 16129, Bias: 1.688892, T: 9735472, Avg. loss: 0.049779\n",
      "Total training time: 7.53 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 7.00, NNZs: 16123, Bias: 1.695498, T: 9817976, Avg. loss: 0.049465\n",
      "Total training time: 7.58 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 7.01, NNZs: 16109, Bias: 1.701998, T: 9900480, Avg. loss: 0.049149\n",
      "Total training time: 7.64 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 7.01, NNZs: 16095, Bias: 1.708519, T: 9982984, Avg. loss: 0.048852\n",
      "Total training time: 7.69 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 7.01, NNZs: 16079, Bias: 1.714969, T: 10065488, Avg. loss: 0.048539\n",
      "Total training time: 7.75 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 7.02, NNZs: 16073, Bias: 1.721389, T: 10147992, Avg. loss: 0.048239\n",
      "Total training time: 7.81 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 7.02, NNZs: 16069, Bias: 1.727755, T: 10230496, Avg. loss: 0.047941\n",
      "Total training time: 7.86 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 7.02, NNZs: 16061, Bias: 1.734126, T: 10313000, Avg. loss: 0.047647\n",
      "Total training time: 7.91 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 7.02, NNZs: 16048, Bias: 1.740387, T: 10395504, Avg. loss: 0.047350\n",
      "Total training time: 7.96 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 7.02, NNZs: 16042, Bias: 1.746624, T: 10478008, Avg. loss: 0.047069\n",
      "Total training time: 8.01 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 7.03, NNZs: 16037, Bias: 1.752848, T: 10560512, Avg. loss: 0.046785\n",
      "Total training time: 8.07 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 7.03, NNZs: 16027, Bias: 1.759026, T: 10643016, Avg. loss: 0.046503\n",
      "Total training time: 8.12 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 7.03, NNZs: 16017, Bias: 1.765166, T: 10725520, Avg. loss: 0.046227\n",
      "Total training time: 8.18 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 7.03, NNZs: 16003, Bias: 1.771233, T: 10808024, Avg. loss: 0.045947\n",
      "Total training time: 8.23 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 7.04, NNZs: 15999, Bias: 1.777347, T: 10890528, Avg. loss: 0.045672\n",
      "Total training time: 8.28 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 7.04, NNZs: 15980, Bias: 1.783326, T: 10973032, Avg. loss: 0.045407\n",
      "Total training time: 8.34 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 7.04, NNZs: 15969, Bias: 1.789314, T: 11055536, Avg. loss: 0.045139\n",
      "Total training time: 8.40 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 7.04, NNZs: 15968, Bias: 1.795224, T: 11138040, Avg. loss: 0.044878\n",
      "Total training time: 8.45 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 7.04, NNZs: 15956, Bias: 1.801141, T: 11220544, Avg. loss: 0.044612\n",
      "Total training time: 8.50 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 7.04, NNZs: 15940, Bias: 1.807019, T: 11303048, Avg. loss: 0.044361\n",
      "Total training time: 8.56 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 7.05, NNZs: 15933, Bias: 1.812881, T: 11385552, Avg. loss: 0.044103\n",
      "Total training time: 8.62 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 7.05, NNZs: 15922, Bias: 1.818678, T: 11468056, Avg. loss: 0.043846\n",
      "Total training time: 8.68 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 7.05, NNZs: 15905, Bias: 1.824431, T: 11550560, Avg. loss: 0.043605\n",
      "Total training time: 8.74 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 7.05, NNZs: 15893, Bias: 1.830169, T: 11633064, Avg. loss: 0.043354\n",
      "Total training time: 8.79 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 7.05, NNZs: 15875, Bias: 1.835834, T: 11715568, Avg. loss: 0.043112\n",
      "Total training time: 8.84 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 7.05, NNZs: 15866, Bias: 1.841520, T: 11798072, Avg. loss: 0.042870\n",
      "Total training time: 8.89 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 7.05, NNZs: 15856, Bias: 1.847116, T: 11880576, Avg. loss: 0.042633\n",
      "Total training time: 8.95 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 7.05, NNZs: 15846, Bias: 1.852744, T: 11963080, Avg. loss: 0.042397\n",
      "Total training time: 9.02 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 7.05, NNZs: 15842, Bias: 1.858288, T: 12045584, Avg. loss: 0.042166\n",
      "Total training time: 9.07 seconds.\n",
      "-- Epoch 147\n",
      "Norm: 7.06, NNZs: 15833, Bias: 1.863843, T: 12128088, Avg. loss: 0.041933\n",
      "Total training time: 9.12 seconds.\n",
      "-- Epoch 148\n",
      "Norm: 7.06, NNZs: 15824, Bias: 1.869356, T: 12210592, Avg. loss: 0.041698\n",
      "Total training time: 9.19 seconds.\n",
      "-- Epoch 149\n",
      "Norm: 7.06, NNZs: 15812, Bias: 1.874775, T: 12293096, Avg. loss: 0.041471\n",
      "Total training time: 9.26 seconds.\n",
      "-- Epoch 150\n",
      "Norm: 7.06, NNZs: 15793, Bias: 1.880239, T: 12375600, Avg. loss: 0.041247\n",
      "Total training time: 9.34 seconds.\n",
      "-- Epoch 151\n",
      "Norm: 7.06, NNZs: 15784, Bias: 1.885659, T: 12458104, Avg. loss: 0.041027\n",
      "Total training time: 9.49 seconds.\n",
      "-- Epoch 152\n",
      "Norm: 7.06, NNZs: 15778, Bias: 1.890988, T: 12540608, Avg. loss: 0.040806\n",
      "Total training time: 9.56 seconds.\n",
      "-- Epoch 153\n",
      "Norm: 7.06, NNZs: 15763, Bias: 1.896355, T: 12623112, Avg. loss: 0.040588\n",
      "Total training time: 9.63 seconds.\n",
      "-- Epoch 154\n",
      "Norm: 7.06, NNZs: 15754, Bias: 1.901630, T: 12705616, Avg. loss: 0.040368\n",
      "Total training time: 9.70 seconds.\n",
      "-- Epoch 155\n",
      "Norm: 7.06, NNZs: 15749, Bias: 1.906931, T: 12788120, Avg. loss: 0.040156\n",
      "Total training time: 9.77 seconds.\n",
      "-- Epoch 156\n",
      "Norm: 7.06, NNZs: 15746, Bias: 1.912166, T: 12870624, Avg. loss: 0.039941\n",
      "Total training time: 9.83 seconds.\n",
      "-- Epoch 157\n",
      "Norm: 7.06, NNZs: 15740, Bias: 1.917380, T: 12953128, Avg. loss: 0.039733\n",
      "Total training time: 9.89 seconds.\n",
      "-- Epoch 158\n",
      "Norm: 7.06, NNZs: 15733, Bias: 1.922570, T: 13035632, Avg. loss: 0.039531\n",
      "Total training time: 9.95 seconds.\n",
      "-- Epoch 159\n",
      "Norm: 7.06, NNZs: 15720, Bias: 1.927745, T: 13118136, Avg. loss: 0.039323\n",
      "Total training time: 10.01 seconds.\n",
      "-- Epoch 160\n",
      "Norm: 7.06, NNZs: 15716, Bias: 1.932905, T: 13200640, Avg. loss: 0.039118\n",
      "Total training time: 10.06 seconds.\n",
      "-- Epoch 161\n",
      "Norm: 7.06, NNZs: 15704, Bias: 1.938006, T: 13283144, Avg. loss: 0.038921\n",
      "Total training time: 10.14 seconds.\n",
      "-- Epoch 162\n",
      "Norm: 7.07, NNZs: 15697, Bias: 1.943100, T: 13365648, Avg. loss: 0.038718\n",
      "Total training time: 10.21 seconds.\n",
      "-- Epoch 163\n",
      "Norm: 7.07, NNZs: 15691, Bias: 1.948131, T: 13448152, Avg. loss: 0.038516\n",
      "Total training time: 10.26 seconds.\n",
      "-- Epoch 164\n",
      "Norm: 7.07, NNZs: 15683, Bias: 1.953154, T: 13530656, Avg. loss: 0.038324\n",
      "Total training time: 10.31 seconds.\n",
      "-- Epoch 165\n",
      "Norm: 7.07, NNZs: 15683, Bias: 1.958153, T: 13613160, Avg. loss: 0.038128\n",
      "Total training time: 10.36 seconds.\n",
      "-- Epoch 166\n",
      "Norm: 7.07, NNZs: 15670, Bias: 1.963116, T: 13695664, Avg. loss: 0.037942\n",
      "Total training time: 10.41 seconds.\n",
      "-- Epoch 167\n",
      "Norm: 7.07, NNZs: 15662, Bias: 1.968055, T: 13778168, Avg. loss: 0.037745\n",
      "Total training time: 10.47 seconds.\n",
      "-- Epoch 168\n",
      "Norm: 7.07, NNZs: 15650, Bias: 1.972965, T: 13860672, Avg. loss: 0.037562\n",
      "Total training time: 10.52 seconds.\n",
      "-- Epoch 169\n",
      "Norm: 7.06, NNZs: 15642, Bias: 1.977822, T: 13943176, Avg. loss: 0.037376\n",
      "Total training time: 10.57 seconds.\n",
      "-- Epoch 170\n",
      "Norm: 7.07, NNZs: 15631, Bias: 1.982718, T: 14025680, Avg. loss: 0.037194\n",
      "Total training time: 10.63 seconds.\n",
      "-- Epoch 171\n",
      "Norm: 7.07, NNZs: 15622, Bias: 1.987532, T: 14108184, Avg. loss: 0.037006\n",
      "Total training time: 10.70 seconds.\n",
      "-- Epoch 172\n",
      "Norm: 7.06, NNZs: 15610, Bias: 1.992342, T: 14190688, Avg. loss: 0.036819\n",
      "Total training time: 10.75 seconds.\n",
      "-- Epoch 173\n",
      "Norm: 7.06, NNZs: 15601, Bias: 1.997133, T: 14273192, Avg. loss: 0.036648\n",
      "Total training time: 10.80 seconds.\n",
      "-- Epoch 174\n",
      "Norm: 7.06, NNZs: 15592, Bias: 2.001885, T: 14355696, Avg. loss: 0.036464\n",
      "Total training time: 10.86 seconds.\n",
      "-- Epoch 175\n",
      "Norm: 7.06, NNZs: 15581, Bias: 2.006604, T: 14438200, Avg. loss: 0.036292\n",
      "Total training time: 10.91 seconds.\n",
      "-- Epoch 176\n",
      "Norm: 7.06, NNZs: 15567, Bias: 2.011319, T: 14520704, Avg. loss: 0.036115\n",
      "Total training time: 10.96 seconds.\n",
      "-- Epoch 177\n",
      "Norm: 7.06, NNZs: 15563, Bias: 2.015993, T: 14603208, Avg. loss: 0.035946\n",
      "Total training time: 11.01 seconds.\n",
      "-- Epoch 178\n",
      "Norm: 7.06, NNZs: 15558, Bias: 2.020672, T: 14685712, Avg. loss: 0.035774\n",
      "Total training time: 11.07 seconds.\n",
      "-- Epoch 179\n",
      "Norm: 7.06, NNZs: 15546, Bias: 2.025274, T: 14768216, Avg. loss: 0.035604\n",
      "Total training time: 11.14 seconds.\n",
      "-- Epoch 180\n",
      "Norm: 7.06, NNZs: 15532, Bias: 2.029924, T: 14850720, Avg. loss: 0.035438\n",
      "Total training time: 11.19 seconds.\n",
      "-- Epoch 181\n",
      "Norm: 7.06, NNZs: 15521, Bias: 2.034499, T: 14933224, Avg. loss: 0.035272\n",
      "Total training time: 11.24 seconds.\n",
      "-- Epoch 182\n",
      "Norm: 7.06, NNZs: 15516, Bias: 2.039029, T: 15015728, Avg. loss: 0.035105\n",
      "Total training time: 11.30 seconds.\n",
      "-- Epoch 183\n",
      "Norm: 7.06, NNZs: 15508, Bias: 2.043576, T: 15098232, Avg. loss: 0.034941\n",
      "Total training time: 11.41 seconds.\n",
      "-- Epoch 184\n",
      "Norm: 7.06, NNZs: 15504, Bias: 2.048094, T: 15180736, Avg. loss: 0.034781\n",
      "Total training time: 11.49 seconds.\n",
      "-- Epoch 185\n",
      "Norm: 7.06, NNZs: 15496, Bias: 2.052575, T: 15263240, Avg. loss: 0.034619\n",
      "Total training time: 11.54 seconds.\n",
      "-- Epoch 186\n",
      "Norm: 7.06, NNZs: 15488, Bias: 2.057059, T: 15345744, Avg. loss: 0.034457\n",
      "Total training time: 11.61 seconds.\n",
      "-- Epoch 187\n",
      "Norm: 7.06, NNZs: 15486, Bias: 2.061528, T: 15428248, Avg. loss: 0.034304\n",
      "Total training time: 11.66 seconds.\n",
      "-- Epoch 188\n",
      "Norm: 7.06, NNZs: 15476, Bias: 2.065942, T: 15510752, Avg. loss: 0.034145\n",
      "Total training time: 11.71 seconds.\n",
      "-- Epoch 189\n",
      "Norm: 7.06, NNZs: 15458, Bias: 2.070335, T: 15593256, Avg. loss: 0.033987\n",
      "Total training time: 11.77 seconds.\n",
      "-- Epoch 190\n",
      "Norm: 7.06, NNZs: 15451, Bias: 2.074710, T: 15675760, Avg. loss: 0.033837\n",
      "Total training time: 11.83 seconds.\n",
      "-- Epoch 191\n",
      "Norm: 7.05, NNZs: 15437, Bias: 2.079059, T: 15758264, Avg. loss: 0.033688\n",
      "Total training time: 11.88 seconds.\n",
      "-- Epoch 192\n",
      "Norm: 7.05, NNZs: 15429, Bias: 2.083420, T: 15840768, Avg. loss: 0.033530\n",
      "Total training time: 11.94 seconds.\n",
      "-- Epoch 193\n",
      "Norm: 7.05, NNZs: 15424, Bias: 2.087752, T: 15923272, Avg. loss: 0.033382\n",
      "Total training time: 11.99 seconds.\n",
      "-- Epoch 194\n",
      "Norm: 7.05, NNZs: 15420, Bias: 2.092017, T: 16005776, Avg. loss: 0.033240\n",
      "Total training time: 12.05 seconds.\n",
      "-- Epoch 195\n",
      "Norm: 7.05, NNZs: 15413, Bias: 2.096285, T: 16088280, Avg. loss: 0.033092\n",
      "Total training time: 12.10 seconds.\n",
      "-- Epoch 196\n",
      "Norm: 7.05, NNZs: 15402, Bias: 2.100540, T: 16170784, Avg. loss: 0.032947\n",
      "Total training time: 12.15 seconds.\n",
      "-- Epoch 197\n",
      "Norm: 7.05, NNZs: 15390, Bias: 2.104787, T: 16253288, Avg. loss: 0.032801\n",
      "Total training time: 12.20 seconds.\n",
      "-- Epoch 198\n",
      "Norm: 7.05, NNZs: 15388, Bias: 2.108919, T: 16335792, Avg. loss: 0.032653\n",
      "Total training time: 12.26 seconds.\n",
      "-- Epoch 199\n",
      "Norm: 7.05, NNZs: 15377, Bias: 2.113145, T: 16418296, Avg. loss: 0.032522\n",
      "Total training time: 12.31 seconds.\n",
      "-- Epoch 200\n",
      "Norm: 7.05, NNZs: 15360, Bias: 2.117325, T: 16500800, Avg. loss: 0.032377\n",
      "Total training time: 12.36 seconds.\n",
      "-- Epoch 201\n",
      "Norm: 7.05, NNZs: 15353, Bias: 2.121469, T: 16583304, Avg. loss: 0.032237\n",
      "Total training time: 12.42 seconds.\n",
      "-- Epoch 202\n",
      "Norm: 7.05, NNZs: 15342, Bias: 2.125618, T: 16665808, Avg. loss: 0.032098\n",
      "Total training time: 12.47 seconds.\n",
      "-- Epoch 203\n",
      "Norm: 7.04, NNZs: 15336, Bias: 2.129670, T: 16748312, Avg. loss: 0.031965\n",
      "Total training time: 12.52 seconds.\n",
      "-- Epoch 204\n",
      "Norm: 7.04, NNZs: 15328, Bias: 2.133780, T: 16830816, Avg. loss: 0.031827\n",
      "Total training time: 12.57 seconds.\n",
      "-- Epoch 205\n",
      "Norm: 7.04, NNZs: 15318, Bias: 2.137843, T: 16913320, Avg. loss: 0.031692\n",
      "Total training time: 12.62 seconds.\n",
      "-- Epoch 206\n",
      "Norm: 7.04, NNZs: 15308, Bias: 2.141851, T: 16995824, Avg. loss: 0.031558\n",
      "Total training time: 12.68 seconds.\n",
      "-- Epoch 207\n",
      "Norm: 7.04, NNZs: 15297, Bias: 2.145912, T: 17078328, Avg. loss: 0.031428\n",
      "Total training time: 12.73 seconds.\n",
      "-- Epoch 208\n",
      "Norm: 7.04, NNZs: 15291, Bias: 2.149910, T: 17160832, Avg. loss: 0.031293\n",
      "Total training time: 12.77 seconds.\n",
      "-- Epoch 209\n",
      "Norm: 7.04, NNZs: 15280, Bias: 2.153926, T: 17243336, Avg. loss: 0.031168\n",
      "Total training time: 12.83 seconds.\n",
      "-- Epoch 210\n",
      "Norm: 7.04, NNZs: 15266, Bias: 2.157870, T: 17325840, Avg. loss: 0.031039\n",
      "Total training time: 12.89 seconds.\n",
      "-- Epoch 211\n",
      "Norm: 7.03, NNZs: 15258, Bias: 2.161833, T: 17408344, Avg. loss: 0.030910\n",
      "Total training time: 12.94 seconds.\n",
      "-- Epoch 212\n",
      "Norm: 7.03, NNZs: 15251, Bias: 2.165758, T: 17490848, Avg. loss: 0.030785\n",
      "Total training time: 12.99 seconds.\n",
      "-- Epoch 213\n",
      "Norm: 7.03, NNZs: 15246, Bias: 2.169665, T: 17573352, Avg. loss: 0.030655\n",
      "Total training time: 13.04 seconds.\n",
      "-- Epoch 214\n",
      "Norm: 7.03, NNZs: 15243, Bias: 2.173556, T: 17655856, Avg. loss: 0.030534\n",
      "Total training time: 13.10 seconds.\n",
      "-- Epoch 215\n",
      "Norm: 7.03, NNZs: 15241, Bias: 2.177448, T: 17738360, Avg. loss: 0.030406\n",
      "Total training time: 13.15 seconds.\n",
      "-- Epoch 216\n",
      "Norm: 7.03, NNZs: 15240, Bias: 2.181309, T: 17820864, Avg. loss: 0.030287\n",
      "Total training time: 13.22 seconds.\n",
      "-- Epoch 217\n",
      "Norm: 7.03, NNZs: 15232, Bias: 2.185164, T: 17903368, Avg. loss: 0.030167\n",
      "Total training time: 13.31 seconds.\n",
      "-- Epoch 218\n",
      "Norm: 7.03, NNZs: 15214, Bias: 2.188969, T: 17985872, Avg. loss: 0.030046\n",
      "Total training time: 13.39 seconds.\n",
      "-- Epoch 219\n",
      "Norm: 7.02, NNZs: 15205, Bias: 2.192748, T: 18068376, Avg. loss: 0.029929\n",
      "Total training time: 13.47 seconds.\n",
      "-- Epoch 220\n",
      "Norm: 7.02, NNZs: 15192, Bias: 2.196549, T: 18150880, Avg. loss: 0.029804\n",
      "Total training time: 13.54 seconds.\n",
      "-- Epoch 221\n",
      "Norm: 7.02, NNZs: 15182, Bias: 2.200314, T: 18233384, Avg. loss: 0.029692\n",
      "Total training time: 13.61 seconds.\n",
      "-- Epoch 222\n",
      "Norm: 7.02, NNZs: 15170, Bias: 2.204064, T: 18315888, Avg. loss: 0.029575\n",
      "Total training time: 13.70 seconds.\n",
      "-- Epoch 223\n",
      "Norm: 7.02, NNZs: 15151, Bias: 2.207821, T: 18398392, Avg. loss: 0.029456\n",
      "Total training time: 13.76 seconds.\n",
      "-- Epoch 224\n",
      "Norm: 7.02, NNZs: 15143, Bias: 2.211510, T: 18480896, Avg. loss: 0.029340\n",
      "Total training time: 13.82 seconds.\n",
      "-- Epoch 225\n",
      "Norm: 7.02, NNZs: 15134, Bias: 2.215234, T: 18563400, Avg. loss: 0.029229\n",
      "Total training time: 13.88 seconds.\n",
      "-- Epoch 226\n",
      "Norm: 7.01, NNZs: 15124, Bias: 2.218894, T: 18645904, Avg. loss: 0.029118\n",
      "Total training time: 13.93 seconds.\n",
      "-- Epoch 227\n",
      "Norm: 7.01, NNZs: 15111, Bias: 2.222563, T: 18728408, Avg. loss: 0.029007\n",
      "Total training time: 13.99 seconds.\n",
      "-- Epoch 228\n",
      "Norm: 7.01, NNZs: 15098, Bias: 2.226233, T: 18810912, Avg. loss: 0.028891\n",
      "Total training time: 14.04 seconds.\n",
      "-- Epoch 229\n",
      "Norm: 7.01, NNZs: 15085, Bias: 2.229850, T: 18893416, Avg. loss: 0.028784\n",
      "Total training time: 14.10 seconds.\n",
      "-- Epoch 230\n",
      "Norm: 7.01, NNZs: 15070, Bias: 2.233468, T: 18975920, Avg. loss: 0.028676\n",
      "Total training time: 14.15 seconds.\n",
      "-- Epoch 231\n",
      "Norm: 7.01, NNZs: 15068, Bias: 2.237082, T: 19058424, Avg. loss: 0.028567\n",
      "Total training time: 14.21 seconds.\n",
      "-- Epoch 232\n",
      "Norm: 7.00, NNZs: 15060, Bias: 2.240640, T: 19140928, Avg. loss: 0.028458\n",
      "Total training time: 14.27 seconds.\n",
      "-- Epoch 233\n",
      "Norm: 7.00, NNZs: 15049, Bias: 2.244215, T: 19223432, Avg. loss: 0.028352\n",
      "Total training time: 14.32 seconds.\n",
      "-- Epoch 234\n",
      "Norm: 7.00, NNZs: 15040, Bias: 2.247791, T: 19305936, Avg. loss: 0.028247\n",
      "Total training time: 14.38 seconds.\n",
      "-- Epoch 235\n",
      "Norm: 7.00, NNZs: 15040, Bias: 2.251320, T: 19388440, Avg. loss: 0.028141\n",
      "Total training time: 14.43 seconds.\n",
      "-- Epoch 236\n",
      "Norm: 7.00, NNZs: 15038, Bias: 2.254809, T: 19470944, Avg. loss: 0.028036\n",
      "Total training time: 14.49 seconds.\n",
      "-- Epoch 237\n",
      "Norm: 7.00, NNZs: 15031, Bias: 2.258345, T: 19553448, Avg. loss: 0.027937\n",
      "Total training time: 14.54 seconds.\n",
      "-- Epoch 238\n",
      "Norm: 6.99, NNZs: 15024, Bias: 2.261834, T: 19635952, Avg. loss: 0.027831\n",
      "Total training time: 14.59 seconds.\n",
      "-- Epoch 239\n",
      "Norm: 6.99, NNZs: 15013, Bias: 2.265298, T: 19718456, Avg. loss: 0.027731\n",
      "Total training time: 14.69 seconds.\n",
      "-- Epoch 240\n",
      "Norm: 6.99, NNZs: 14999, Bias: 2.268740, T: 19800960, Avg. loss: 0.027632\n",
      "Total training time: 14.74 seconds.\n",
      "-- Epoch 241\n",
      "Norm: 6.99, NNZs: 14987, Bias: 2.272205, T: 19883464, Avg. loss: 0.027530\n",
      "Total training time: 14.79 seconds.\n",
      "-- Epoch 242\n",
      "Norm: 6.99, NNZs: 14976, Bias: 2.275643, T: 19965968, Avg. loss: 0.027433\n",
      "Total training time: 14.84 seconds.\n",
      "-- Epoch 243\n",
      "Norm: 6.99, NNZs: 14970, Bias: 2.279047, T: 20048472, Avg. loss: 0.027333\n",
      "Total training time: 14.89 seconds.\n",
      "-- Epoch 244\n",
      "Norm: 6.98, NNZs: 14958, Bias: 2.282460, T: 20130976, Avg. loss: 0.027235\n",
      "Total training time: 14.95 seconds.\n",
      "-- Epoch 245\n",
      "Norm: 6.98, NNZs: 14952, Bias: 2.285845, T: 20213480, Avg. loss: 0.027138\n",
      "Total training time: 15.01 seconds.\n",
      "-- Epoch 246\n",
      "Norm: 6.98, NNZs: 14945, Bias: 2.289200, T: 20295984, Avg. loss: 0.027042\n",
      "Total training time: 15.05 seconds.\n",
      "-- Epoch 247\n",
      "Norm: 6.98, NNZs: 14941, Bias: 2.292537, T: 20378488, Avg. loss: 0.026947\n",
      "Total training time: 15.11 seconds.\n",
      "-- Epoch 248\n",
      "Norm: 6.98, NNZs: 14938, Bias: 2.295884, T: 20460992, Avg. loss: 0.026853\n",
      "Total training time: 15.17 seconds.\n",
      "-- Epoch 249\n",
      "Norm: 6.97, NNZs: 14934, Bias: 2.299230, T: 20543496, Avg. loss: 0.026757\n",
      "Total training time: 15.22 seconds.\n",
      "-- Epoch 250\n",
      "Norm: 6.97, NNZs: 14925, Bias: 2.302544, T: 20626000, Avg. loss: 0.026665\n",
      "Total training time: 15.26 seconds.\n",
      "-- Epoch 251\n",
      "Norm: 6.97, NNZs: 14912, Bias: 2.305801, T: 20708504, Avg. loss: 0.026573\n",
      "Total training time: 15.32 seconds.\n",
      "-- Epoch 252\n",
      "Norm: 6.97, NNZs: 14909, Bias: 2.309121, T: 20791008, Avg. loss: 0.026480\n",
      "Total training time: 15.37 seconds.\n",
      "-- Epoch 253\n",
      "Norm: 6.97, NNZs: 14901, Bias: 2.312364, T: 20873512, Avg. loss: 0.026388\n",
      "Total training time: 15.43 seconds.\n",
      "-- Epoch 254\n",
      "Norm: 6.96, NNZs: 14886, Bias: 2.315619, T: 20956016, Avg. loss: 0.026300\n",
      "Total training time: 15.48 seconds.\n",
      "-- Epoch 255\n",
      "Norm: 6.96, NNZs: 14873, Bias: 2.318881, T: 21038520, Avg. loss: 0.026208\n",
      "Total training time: 15.53 seconds.\n",
      "-- Epoch 256\n",
      "Norm: 6.96, NNZs: 14857, Bias: 2.322096, T: 21121024, Avg. loss: 0.026118\n",
      "Total training time: 15.59 seconds.\n",
      "-- Epoch 257\n",
      "Norm: 6.96, NNZs: 14846, Bias: 2.325305, T: 21203528, Avg. loss: 0.026032\n",
      "Total training time: 15.64 seconds.\n",
      "-- Epoch 258\n",
      "Norm: 6.96, NNZs: 14833, Bias: 2.328509, T: 21286032, Avg. loss: 0.025945\n",
      "Total training time: 15.69 seconds.\n",
      "-- Epoch 259\n",
      "Norm: 6.96, NNZs: 14820, Bias: 2.331704, T: 21368536, Avg. loss: 0.025858\n",
      "Total training time: 15.74 seconds.\n",
      "-- Epoch 260\n",
      "Norm: 6.95, NNZs: 14810, Bias: 2.334855, T: 21451040, Avg. loss: 0.025767\n",
      "Total training time: 15.80 seconds.\n",
      "-- Epoch 261\n",
      "Norm: 6.95, NNZs: 14803, Bias: 2.338022, T: 21533544, Avg. loss: 0.025686\n",
      "Total training time: 15.85 seconds.\n",
      "-- Epoch 262\n",
      "Norm: 6.95, NNZs: 14794, Bias: 2.341186, T: 21616048, Avg. loss: 0.025601\n",
      "Total training time: 15.91 seconds.\n",
      "-- Epoch 263\n",
      "Norm: 6.95, NNZs: 14785, Bias: 2.344315, T: 21698552, Avg. loss: 0.025515\n",
      "Total training time: 15.99 seconds.\n",
      "-- Epoch 264\n",
      "Norm: 6.95, NNZs: 14782, Bias: 2.347447, T: 21781056, Avg. loss: 0.025431\n",
      "Total training time: 16.08 seconds.\n",
      "-- Epoch 265\n",
      "Norm: 6.94, NNZs: 14778, Bias: 2.350526, T: 21863560, Avg. loss: 0.025347\n",
      "Total training time: 16.15 seconds.\n",
      "-- Epoch 266\n",
      "Norm: 6.94, NNZs: 14768, Bias: 2.353655, T: 21946064, Avg. loss: 0.025265\n",
      "Total training time: 16.22 seconds.\n",
      "-- Epoch 267\n",
      "Norm: 6.94, NNZs: 14756, Bias: 2.356711, T: 22028568, Avg. loss: 0.025183\n",
      "Total training time: 16.28 seconds.\n",
      "-- Epoch 268\n",
      "Norm: 6.94, NNZs: 14746, Bias: 2.359774, T: 22111072, Avg. loss: 0.025100\n",
      "Total training time: 16.33 seconds.\n",
      "-- Epoch 269\n",
      "Norm: 6.94, NNZs: 14731, Bias: 2.362820, T: 22193576, Avg. loss: 0.025021\n",
      "Total training time: 16.39 seconds.\n",
      "-- Epoch 270\n",
      "Norm: 6.93, NNZs: 14722, Bias: 2.365890, T: 22276080, Avg. loss: 0.024942\n",
      "Total training time: 16.44 seconds.\n",
      "-- Epoch 271\n",
      "Norm: 6.93, NNZs: 14715, Bias: 2.368909, T: 22358584, Avg. loss: 0.024863\n",
      "Total training time: 16.50 seconds.\n",
      "-- Epoch 272\n",
      "Norm: 6.93, NNZs: 14704, Bias: 2.371912, T: 22441088, Avg. loss: 0.024782\n",
      "Total training time: 16.57 seconds.\n",
      "-- Epoch 273\n",
      "Norm: 6.93, NNZs: 14699, Bias: 2.374944, T: 22523592, Avg. loss: 0.024705\n",
      "Total training time: 16.65 seconds.\n",
      "-- Epoch 274\n",
      "Norm: 6.93, NNZs: 14690, Bias: 2.377934, T: 22606096, Avg. loss: 0.024627\n",
      "Total training time: 16.71 seconds.\n",
      "-- Epoch 275\n",
      "Norm: 6.92, NNZs: 14680, Bias: 2.380905, T: 22688600, Avg. loss: 0.024549\n",
      "Total training time: 16.77 seconds.\n",
      "-- Epoch 276\n",
      "Norm: 6.92, NNZs: 14679, Bias: 2.383899, T: 22771104, Avg. loss: 0.024472\n",
      "Total training time: 16.83 seconds.\n",
      "-- Epoch 277\n",
      "Norm: 6.92, NNZs: 14668, Bias: 2.386847, T: 22853608, Avg. loss: 0.024398\n",
      "Total training time: 16.90 seconds.\n",
      "-- Epoch 278\n",
      "Norm: 6.92, NNZs: 14657, Bias: 2.389762, T: 22936112, Avg. loss: 0.024318\n",
      "Total training time: 16.96 seconds.\n",
      "-- Epoch 279\n",
      "Norm: 6.92, NNZs: 14651, Bias: 2.392728, T: 23018616, Avg. loss: 0.024247\n",
      "Total training time: 17.01 seconds.\n",
      "-- Epoch 280\n",
      "Norm: 6.91, NNZs: 14639, Bias: 2.395660, T: 23101120, Avg. loss: 0.024171\n",
      "Total training time: 17.07 seconds.\n",
      "-- Epoch 281\n",
      "Norm: 6.91, NNZs: 14629, Bias: 2.398555, T: 23183624, Avg. loss: 0.024099\n",
      "Total training time: 17.12 seconds.\n",
      "-- Epoch 282\n",
      "Norm: 6.91, NNZs: 14616, Bias: 2.401452, T: 23266128, Avg. loss: 0.024024\n",
      "Total training time: 17.17 seconds.\n",
      "-- Epoch 283\n",
      "Norm: 6.91, NNZs: 14608, Bias: 2.404332, T: 23348632, Avg. loss: 0.023952\n",
      "Total training time: 17.22 seconds.\n",
      "-- Epoch 284\n",
      "Norm: 6.90, NNZs: 14599, Bias: 2.407217, T: 23431136, Avg. loss: 0.023880\n",
      "Total training time: 17.31 seconds.\n",
      "-- Epoch 285\n",
      "Norm: 6.90, NNZs: 14591, Bias: 2.410094, T: 23513640, Avg. loss: 0.023806\n",
      "Total training time: 17.38 seconds.\n",
      "-- Epoch 286\n",
      "Norm: 6.90, NNZs: 14583, Bias: 2.412929, T: 23596144, Avg. loss: 0.023736\n",
      "Total training time: 17.44 seconds.\n",
      "-- Epoch 287\n",
      "Norm: 6.90, NNZs: 14572, Bias: 2.415779, T: 23678648, Avg. loss: 0.023665\n",
      "Total training time: 17.49 seconds.\n",
      "-- Epoch 288\n",
      "Norm: 6.90, NNZs: 14569, Bias: 2.418595, T: 23761152, Avg. loss: 0.023597\n",
      "Total training time: 17.55 seconds.\n",
      "-- Epoch 289\n",
      "Norm: 6.89, NNZs: 14561, Bias: 2.421402, T: 23843656, Avg. loss: 0.023525\n",
      "Total training time: 17.63 seconds.\n",
      "-- Epoch 290\n",
      "Norm: 6.89, NNZs: 14552, Bias: 2.424231, T: 23926160, Avg. loss: 0.023456\n",
      "Total training time: 17.70 seconds.\n",
      "-- Epoch 291\n",
      "Norm: 6.89, NNZs: 14541, Bias: 2.427007, T: 24008664, Avg. loss: 0.023389\n",
      "Total training time: 17.77 seconds.\n",
      "-- Epoch 292\n",
      "Norm: 6.89, NNZs: 14532, Bias: 2.429782, T: 24091168, Avg. loss: 0.023321\n",
      "Total training time: 17.84 seconds.\n",
      "-- Epoch 293\n",
      "Norm: 6.89, NNZs: 14523, Bias: 2.432562, T: 24173672, Avg. loss: 0.023251\n",
      "Total training time: 17.91 seconds.\n",
      "-- Epoch 294\n",
      "Norm: 6.88, NNZs: 14509, Bias: 2.435317, T: 24256176, Avg. loss: 0.023186\n",
      "Total training time: 17.96 seconds.\n",
      "-- Epoch 295\n",
      "Norm: 6.88, NNZs: 14502, Bias: 2.438084, T: 24338680, Avg. loss: 0.023115\n",
      "Total training time: 18.02 seconds.\n",
      "-- Epoch 296\n",
      "Norm: 6.88, NNZs: 14491, Bias: 2.440827, T: 24421184, Avg. loss: 0.023053\n",
      "Total training time: 18.09 seconds.\n",
      "-- Epoch 297\n",
      "Norm: 6.88, NNZs: 14481, Bias: 2.443552, T: 24503688, Avg. loss: 0.022987\n",
      "Total training time: 18.15 seconds.\n",
      "-- Epoch 298\n",
      "Norm: 6.87, NNZs: 14472, Bias: 2.446251, T: 24586192, Avg. loss: 0.022921\n",
      "Total training time: 18.22 seconds.\n",
      "-- Epoch 299\n",
      "Norm: 6.87, NNZs: 14462, Bias: 2.448965, T: 24668696, Avg. loss: 0.022856\n",
      "Total training time: 18.29 seconds.\n",
      "-- Epoch 300\n",
      "Norm: 6.87, NNZs: 14448, Bias: 2.451663, T: 24751200, Avg. loss: 0.022790\n",
      "Total training time: 18.36 seconds.\n",
      "-- Epoch 301\n",
      "Norm: 6.87, NNZs: 14445, Bias: 2.454355, T: 24833704, Avg. loss: 0.022729\n",
      "Total training time: 18.44 seconds.\n",
      "-- Epoch 302\n",
      "Norm: 6.87, NNZs: 14432, Bias: 2.457021, T: 24916208, Avg. loss: 0.022665\n",
      "Total training time: 18.52 seconds.\n",
      "-- Epoch 303\n",
      "Norm: 6.86, NNZs: 14429, Bias: 2.459679, T: 24998712, Avg. loss: 0.022603\n",
      "Total training time: 18.60 seconds.\n",
      "-- Epoch 304\n",
      "Norm: 6.86, NNZs: 14421, Bias: 2.462349, T: 25081216, Avg. loss: 0.022539\n",
      "Total training time: 18.69 seconds.\n",
      "-- Epoch 305\n",
      "Norm: 6.86, NNZs: 14418, Bias: 2.464968, T: 25163720, Avg. loss: 0.022475\n",
      "Total training time: 18.77 seconds.\n",
      "-- Epoch 306\n",
      "Norm: 6.86, NNZs: 14399, Bias: 2.467625, T: 25246224, Avg. loss: 0.022415\n",
      "Total training time: 18.86 seconds.\n",
      "-- Epoch 307\n",
      "Norm: 6.85, NNZs: 14385, Bias: 2.470239, T: 25328728, Avg. loss: 0.022354\n",
      "Total training time: 18.95 seconds.\n",
      "-- Epoch 308\n",
      "Norm: 6.85, NNZs: 14371, Bias: 2.472856, T: 25411232, Avg. loss: 0.022295\n",
      "Total training time: 19.05 seconds.\n",
      "-- Epoch 309\n",
      "Norm: 6.85, NNZs: 14364, Bias: 2.475468, T: 25493736, Avg. loss: 0.022233\n",
      "Total training time: 19.17 seconds.\n",
      "-- Epoch 310\n",
      "Norm: 6.85, NNZs: 14355, Bias: 2.478035, T: 25576240, Avg. loss: 0.022171\n",
      "Total training time: 19.35 seconds.\n",
      "-- Epoch 311\n",
      "Norm: 6.85, NNZs: 14351, Bias: 2.480651, T: 25658744, Avg. loss: 0.022113\n",
      "Total training time: 19.47 seconds.\n",
      "-- Epoch 312\n",
      "Norm: 6.84, NNZs: 14343, Bias: 2.483212, T: 25741248, Avg. loss: 0.022053\n",
      "Total training time: 19.58 seconds.\n",
      "-- Epoch 313\n",
      "Norm: 6.84, NNZs: 14341, Bias: 2.485771, T: 25823752, Avg. loss: 0.021995\n",
      "Total training time: 19.76 seconds.\n",
      "-- Epoch 314\n",
      "Norm: 6.84, NNZs: 14340, Bias: 2.488340, T: 25906256, Avg. loss: 0.021935\n",
      "Total training time: 19.91 seconds.\n",
      "-- Epoch 315\n",
      "Norm: 6.84, NNZs: 14337, Bias: 2.490871, T: 25988760, Avg. loss: 0.021879\n",
      "Total training time: 20.00 seconds.\n",
      "-- Epoch 316\n",
      "Norm: 6.83, NNZs: 14325, Bias: 2.493415, T: 26071264, Avg. loss: 0.021821\n",
      "Total training time: 20.09 seconds.\n",
      "-- Epoch 317\n",
      "Norm: 6.83, NNZs: 14320, Bias: 2.495935, T: 26153768, Avg. loss: 0.021762\n",
      "Total training time: 20.18 seconds.\n",
      "-- Epoch 318\n",
      "Norm: 6.83, NNZs: 14314, Bias: 2.498465, T: 26236272, Avg. loss: 0.021708\n",
      "Total training time: 20.38 seconds.\n",
      "-- Epoch 319\n",
      "Norm: 6.83, NNZs: 14305, Bias: 2.500961, T: 26318776, Avg. loss: 0.021651\n",
      "Total training time: 20.50 seconds.\n",
      "-- Epoch 320\n",
      "Norm: 6.83, NNZs: 14299, Bias: 2.503443, T: 26401280, Avg. loss: 0.021594\n",
      "Total training time: 20.67 seconds.\n",
      "-- Epoch 321\n",
      "Norm: 6.82, NNZs: 14291, Bias: 2.505929, T: 26483784, Avg. loss: 0.021540\n",
      "Total training time: 20.81 seconds.\n",
      "-- Epoch 322\n",
      "Norm: 6.82, NNZs: 14287, Bias: 2.508425, T: 26566288, Avg. loss: 0.021483\n",
      "Total training time: 20.90 seconds.\n",
      "-- Epoch 323\n",
      "Norm: 6.82, NNZs: 14278, Bias: 2.510892, T: 26648792, Avg. loss: 0.021428\n",
      "Total training time: 20.96 seconds.\n",
      "-- Epoch 324\n",
      "Norm: 6.82, NNZs: 14272, Bias: 2.513348, T: 26731296, Avg. loss: 0.021374\n",
      "Total training time: 21.03 seconds.\n",
      "-- Epoch 325\n",
      "Norm: 6.81, NNZs: 14264, Bias: 2.515810, T: 26813800, Avg. loss: 0.021320\n",
      "Total training time: 21.12 seconds.\n",
      "-- Epoch 326\n",
      "Norm: 6.81, NNZs: 14255, Bias: 2.518245, T: 26896304, Avg. loss: 0.021266\n",
      "Total training time: 21.24 seconds.\n",
      "-- Epoch 327\n",
      "Norm: 6.81, NNZs: 14245, Bias: 2.520658, T: 26978808, Avg. loss: 0.021208\n",
      "Total training time: 21.40 seconds.\n",
      "-- Epoch 328\n",
      "Norm: 6.81, NNZs: 14240, Bias: 2.523126, T: 27061312, Avg. loss: 0.021158\n",
      "Total training time: 21.65 seconds.\n",
      "-- Epoch 329\n",
      "Norm: 6.81, NNZs: 14227, Bias: 2.525507, T: 27143816, Avg. loss: 0.021107\n",
      "Total training time: 21.77 seconds.\n",
      "-- Epoch 330\n",
      "Norm: 6.80, NNZs: 14221, Bias: 2.527931, T: 27226320, Avg. loss: 0.021053\n",
      "Total training time: 21.89 seconds.\n",
      "-- Epoch 331\n",
      "Norm: 6.80, NNZs: 14214, Bias: 2.530320, T: 27308824, Avg. loss: 0.020998\n",
      "Total training time: 22.02 seconds.\n",
      "-- Epoch 332\n",
      "Norm: 6.80, NNZs: 14194, Bias: 2.532683, T: 27391328, Avg. loss: 0.020949\n",
      "Total training time: 22.22 seconds.\n",
      "-- Epoch 333\n",
      "Norm: 6.80, NNZs: 14183, Bias: 2.535053, T: 27473832, Avg. loss: 0.020898\n",
      "Total training time: 22.31 seconds.\n",
      "-- Epoch 334\n",
      "Norm: 6.79, NNZs: 14173, Bias: 2.537451, T: 27556336, Avg. loss: 0.020849\n",
      "Total training time: 22.42 seconds.\n",
      "-- Epoch 335\n",
      "Norm: 6.79, NNZs: 14164, Bias: 2.539816, T: 27638840, Avg. loss: 0.020794\n",
      "Total training time: 22.49 seconds.\n",
      "-- Epoch 336\n",
      "Norm: 6.79, NNZs: 14155, Bias: 2.542169, T: 27721344, Avg. loss: 0.020747\n",
      "Total training time: 22.56 seconds.\n",
      "-- Epoch 337\n",
      "Norm: 6.79, NNZs: 14147, Bias: 2.544497, T: 27803848, Avg. loss: 0.020696\n",
      "Total training time: 22.69 seconds.\n",
      "-- Epoch 338\n",
      "Norm: 6.78, NNZs: 14134, Bias: 2.546822, T: 27886352, Avg. loss: 0.020643\n",
      "Total training time: 22.78 seconds.\n",
      "-- Epoch 339\n",
      "Norm: 6.78, NNZs: 14127, Bias: 2.549171, T: 27968856, Avg. loss: 0.020598\n",
      "Total training time: 22.84 seconds.\n",
      "-- Epoch 340\n",
      "Norm: 6.78, NNZs: 14122, Bias: 2.551484, T: 28051360, Avg. loss: 0.020551\n",
      "Total training time: 22.91 seconds.\n",
      "-- Epoch 341\n",
      "Norm: 6.78, NNZs: 14116, Bias: 2.553789, T: 28133864, Avg. loss: 0.020499\n",
      "Total training time: 22.98 seconds.\n",
      "-- Epoch 342\n",
      "Norm: 6.78, NNZs: 14105, Bias: 2.556096, T: 28216368, Avg. loss: 0.020453\n",
      "Total training time: 23.04 seconds.\n",
      "-- Epoch 343\n",
      "Norm: 6.77, NNZs: 14103, Bias: 2.558385, T: 28298872, Avg. loss: 0.020404\n",
      "Total training time: 23.11 seconds.\n",
      "-- Epoch 344\n",
      "Norm: 6.77, NNZs: 14094, Bias: 2.560654, T: 28381376, Avg. loss: 0.020355\n",
      "Total training time: 23.17 seconds.\n",
      "-- Epoch 345\n",
      "Norm: 6.77, NNZs: 14092, Bias: 2.562940, T: 28463880, Avg. loss: 0.020310\n",
      "Total training time: 23.24 seconds.\n",
      "-- Epoch 346\n",
      "Norm: 6.77, NNZs: 14084, Bias: 2.565214, T: 28546384, Avg. loss: 0.020261\n",
      "Total training time: 23.30 seconds.\n",
      "-- Epoch 347\n",
      "Norm: 6.76, NNZs: 14077, Bias: 2.567473, T: 28628888, Avg. loss: 0.020214\n",
      "Total training time: 23.38 seconds.\n",
      "-- Epoch 348\n",
      "Norm: 6.76, NNZs: 14070, Bias: 2.569736, T: 28711392, Avg. loss: 0.020168\n",
      "Total training time: 23.45 seconds.\n",
      "-- Epoch 349\n",
      "Norm: 6.76, NNZs: 14069, Bias: 2.571983, T: 28793896, Avg. loss: 0.020122\n",
      "Total training time: 23.53 seconds.\n",
      "-- Epoch 350\n",
      "Norm: 6.76, NNZs: 14058, Bias: 2.574213, T: 28876400, Avg. loss: 0.020076\n",
      "Total training time: 23.60 seconds.\n",
      "-- Epoch 351\n",
      "Norm: 6.75, NNZs: 14044, Bias: 2.576427, T: 28958904, Avg. loss: 0.020031\n",
      "Total training time: 23.68 seconds.\n",
      "-- Epoch 352\n",
      "Norm: 6.75, NNZs: 14032, Bias: 2.578648, T: 29041408, Avg. loss: 0.019984\n",
      "Total training time: 23.74 seconds.\n",
      "-- Epoch 353\n",
      "Norm: 6.75, NNZs: 14027, Bias: 2.580879, T: 29123912, Avg. loss: 0.019941\n",
      "Total training time: 23.81 seconds.\n",
      "-- Epoch 354\n",
      "Norm: 6.75, NNZs: 14023, Bias: 2.583071, T: 29206416, Avg. loss: 0.019894\n",
      "Total training time: 23.88 seconds.\n",
      "-- Epoch 355\n",
      "Norm: 6.75, NNZs: 14014, Bias: 2.585255, T: 29288920, Avg. loss: 0.019852\n",
      "Total training time: 23.94 seconds.\n",
      "-- Epoch 356\n",
      "Norm: 6.74, NNZs: 14006, Bias: 2.587450, T: 29371424, Avg. loss: 0.019808\n",
      "Total training time: 24.00 seconds.\n",
      "-- Epoch 357\n",
      "Norm: 6.74, NNZs: 13997, Bias: 2.589626, T: 29453928, Avg. loss: 0.019763\n",
      "Total training time: 24.07 seconds.\n",
      "-- Epoch 358\n",
      "Norm: 6.74, NNZs: 13987, Bias: 2.591800, T: 29536432, Avg. loss: 0.019719\n",
      "Total training time: 24.31 seconds.\n",
      "-- Epoch 359\n",
      "Norm: 6.74, NNZs: 13977, Bias: 2.593959, T: 29618936, Avg. loss: 0.019677\n",
      "Total training time: 24.39 seconds.\n",
      "-- Epoch 360\n",
      "Norm: 6.73, NNZs: 13961, Bias: 2.596118, T: 29701440, Avg. loss: 0.019634\n",
      "Total training time: 24.45 seconds.\n",
      "-- Epoch 361\n",
      "Norm: 6.73, NNZs: 13952, Bias: 2.598278, T: 29783944, Avg. loss: 0.019591\n",
      "Total training time: 24.51 seconds.\n",
      "-- Epoch 362\n",
      "Norm: 6.73, NNZs: 13945, Bias: 2.600412, T: 29866448, Avg. loss: 0.019549\n",
      "Total training time: 24.57 seconds.\n",
      "-- Epoch 363\n",
      "Norm: 6.73, NNZs: 13939, Bias: 2.602527, T: 29948952, Avg. loss: 0.019506\n",
      "Total training time: 24.63 seconds.\n",
      "-- Epoch 364\n",
      "Norm: 6.72, NNZs: 13929, Bias: 2.604650, T: 30031456, Avg. loss: 0.019465\n",
      "Total training time: 24.69 seconds.\n",
      "-- Epoch 365\n",
      "Norm: 6.72, NNZs: 13917, Bias: 2.606789, T: 30113960, Avg. loss: 0.019424\n",
      "Total training time: 24.74 seconds.\n",
      "-- Epoch 366\n",
      "Norm: 6.72, NNZs: 13909, Bias: 2.608870, T: 30196464, Avg. loss: 0.019382\n",
      "Total training time: 24.79 seconds.\n",
      "-- Epoch 367\n",
      "Norm: 6.72, NNZs: 13900, Bias: 2.611010, T: 30278968, Avg. loss: 0.019341\n",
      "Total training time: 24.84 seconds.\n",
      "-- Epoch 368\n",
      "Norm: 6.72, NNZs: 13889, Bias: 2.613094, T: 30361472, Avg. loss: 0.019300\n",
      "Total training time: 24.90 seconds.\n",
      "-- Epoch 369\n",
      "Norm: 6.71, NNZs: 13877, Bias: 2.615167, T: 30443976, Avg. loss: 0.019260\n",
      "Total training time: 24.96 seconds.\n",
      "-- Epoch 370\n",
      "Norm: 6.71, NNZs: 13874, Bias: 2.617257, T: 30526480, Avg. loss: 0.019218\n",
      "Total training time: 25.03 seconds.\n",
      "-- Epoch 371\n",
      "Norm: 6.71, NNZs: 13865, Bias: 2.619315, T: 30608984, Avg. loss: 0.019178\n",
      "Total training time: 25.10 seconds.\n",
      "-- Epoch 372\n",
      "Norm: 6.71, NNZs: 13860, Bias: 2.621394, T: 30691488, Avg. loss: 0.019140\n",
      "Total training time: 25.17 seconds.\n",
      "-- Epoch 373\n",
      "Norm: 6.70, NNZs: 13853, Bias: 2.623451, T: 30773992, Avg. loss: 0.019101\n",
      "Total training time: 25.25 seconds.\n",
      "-- Epoch 374\n",
      "Norm: 6.70, NNZs: 13842, Bias: 2.625510, T: 30856496, Avg. loss: 0.019062\n",
      "Total training time: 25.34 seconds.\n",
      "-- Epoch 375\n",
      "Norm: 6.70, NNZs: 13834, Bias: 2.627552, T: 30939000, Avg. loss: 0.019023\n",
      "Total training time: 25.40 seconds.\n",
      "-- Epoch 376\n",
      "Norm: 6.70, NNZs: 13828, Bias: 2.629593, T: 31021504, Avg. loss: 0.018984\n",
      "Total training time: 25.46 seconds.\n",
      "-- Epoch 377\n",
      "Norm: 6.70, NNZs: 13823, Bias: 2.631627, T: 31104008, Avg. loss: 0.018944\n",
      "Total training time: 25.53 seconds.\n",
      "-- Epoch 378\n",
      "Norm: 6.69, NNZs: 13815, Bias: 2.633647, T: 31186512, Avg. loss: 0.018905\n",
      "Total training time: 25.59 seconds.\n",
      "-- Epoch 379\n",
      "Norm: 6.69, NNZs: 13815, Bias: 2.635649, T: 31269016, Avg. loss: 0.018869\n",
      "Total training time: 25.65 seconds.\n",
      "-- Epoch 380\n",
      "Norm: 6.69, NNZs: 13804, Bias: 2.637664, T: 31351520, Avg. loss: 0.018830\n",
      "Total training time: 25.72 seconds.\n",
      "-- Epoch 381\n",
      "Norm: 6.69, NNZs: 13793, Bias: 2.639673, T: 31434024, Avg. loss: 0.018790\n",
      "Total training time: 25.79 seconds.\n",
      "-- Epoch 382\n",
      "Norm: 6.68, NNZs: 13783, Bias: 2.641656, T: 31516528, Avg. loss: 0.018756\n",
      "Total training time: 25.85 seconds.\n",
      "-- Epoch 383\n",
      "Norm: 6.68, NNZs: 13779, Bias: 2.643659, T: 31599032, Avg. loss: 0.018719\n",
      "Total training time: 25.91 seconds.\n",
      "-- Epoch 384\n",
      "Norm: 6.68, NNZs: 13773, Bias: 2.645607, T: 31681536, Avg. loss: 0.018680\n",
      "Total training time: 25.97 seconds.\n",
      "-- Epoch 385\n",
      "Norm: 6.68, NNZs: 13769, Bias: 2.647597, T: 31764040, Avg. loss: 0.018645\n",
      "Total training time: 26.03 seconds.\n",
      "-- Epoch 386\n",
      "Norm: 6.67, NNZs: 13762, Bias: 2.649587, T: 31846544, Avg. loss: 0.018609\n",
      "Total training time: 26.08 seconds.\n",
      "-- Epoch 387\n",
      "Norm: 6.67, NNZs: 13751, Bias: 2.651524, T: 31929048, Avg. loss: 0.018571\n",
      "Total training time: 26.14 seconds.\n",
      "-- Epoch 388\n",
      "Norm: 6.67, NNZs: 13744, Bias: 2.653499, T: 32011552, Avg. loss: 0.018536\n",
      "Total training time: 26.19 seconds.\n",
      "-- Epoch 389\n",
      "Norm: 6.67, NNZs: 13732, Bias: 2.655441, T: 32094056, Avg. loss: 0.018501\n",
      "Total training time: 26.26 seconds.\n",
      "-- Epoch 390\n",
      "Norm: 6.66, NNZs: 13723, Bias: 2.657366, T: 32176560, Avg. loss: 0.018465\n",
      "Total training time: 26.31 seconds.\n",
      "-- Epoch 391\n",
      "Norm: 6.66, NNZs: 13720, Bias: 2.659333, T: 32259064, Avg. loss: 0.018431\n",
      "Total training time: 26.37 seconds.\n",
      "-- Epoch 392\n",
      "Norm: 6.66, NNZs: 13709, Bias: 2.661246, T: 32341568, Avg. loss: 0.018395\n",
      "Total training time: 26.43 seconds.\n",
      "-- Epoch 393\n",
      "Norm: 6.66, NNZs: 13702, Bias: 2.663178, T: 32424072, Avg. loss: 0.018359\n",
      "Total training time: 26.48 seconds.\n",
      "-- Epoch 394\n",
      "Norm: 6.66, NNZs: 13698, Bias: 2.665088, T: 32506576, Avg. loss: 0.018326\n",
      "Total training time: 26.53 seconds.\n",
      "-- Epoch 395\n",
      "Norm: 6.65, NNZs: 13690, Bias: 2.667015, T: 32589080, Avg. loss: 0.018290\n",
      "Total training time: 26.59 seconds.\n",
      "-- Epoch 396\n",
      "Norm: 6.65, NNZs: 13681, Bias: 2.668884, T: 32671584, Avg. loss: 0.018257\n",
      "Total training time: 26.64 seconds.\n",
      "-- Epoch 397\n",
      "Norm: 6.65, NNZs: 13675, Bias: 2.670801, T: 32754088, Avg. loss: 0.018222\n",
      "Total training time: 26.71 seconds.\n",
      "-- Epoch 398\n",
      "Norm: 6.65, NNZs: 13658, Bias: 2.672672, T: 32836592, Avg. loss: 0.018189\n",
      "Total training time: 26.79 seconds.\n",
      "-- Epoch 399\n",
      "Norm: 6.64, NNZs: 13648, Bias: 2.674567, T: 32919096, Avg. loss: 0.018153\n",
      "Total training time: 26.87 seconds.\n",
      "-- Epoch 400\n",
      "Norm: 6.64, NNZs: 13636, Bias: 2.676438, T: 33001600, Avg. loss: 0.018119\n",
      "Total training time: 26.97 seconds.\n",
      "-- Epoch 401\n",
      "Norm: 6.64, NNZs: 13632, Bias: 2.678330, T: 33084104, Avg. loss: 0.018088\n",
      "Total training time: 27.03 seconds.\n",
      "-- Epoch 402\n",
      "Norm: 6.64, NNZs: 13625, Bias: 2.680201, T: 33166608, Avg. loss: 0.018056\n",
      "Total training time: 27.09 seconds.\n",
      "-- Epoch 403\n",
      "Norm: 6.64, NNZs: 13618, Bias: 2.682047, T: 33249112, Avg. loss: 0.018019\n",
      "Total training time: 27.16 seconds.\n",
      "-- Epoch 404\n",
      "Norm: 6.63, NNZs: 13612, Bias: 2.683879, T: 33331616, Avg. loss: 0.017987\n",
      "Total training time: 27.21 seconds.\n",
      "-- Epoch 405\n",
      "Norm: 6.63, NNZs: 13601, Bias: 2.685744, T: 33414120, Avg. loss: 0.017958\n",
      "Total training time: 27.26 seconds.\n",
      "-- Epoch 406\n",
      "Norm: 6.63, NNZs: 13593, Bias: 2.687577, T: 33496624, Avg. loss: 0.017924\n",
      "Total training time: 27.32 seconds.\n",
      "-- Epoch 407\n",
      "Norm: 6.63, NNZs: 13581, Bias: 2.689404, T: 33579128, Avg. loss: 0.017892\n",
      "Total training time: 27.38 seconds.\n",
      "-- Epoch 408\n",
      "Norm: 6.62, NNZs: 13573, Bias: 2.691226, T: 33661632, Avg. loss: 0.017859\n",
      "Total training time: 27.44 seconds.\n",
      "-- Epoch 409\n",
      "Norm: 6.62, NNZs: 13561, Bias: 2.693043, T: 33744136, Avg. loss: 0.017829\n",
      "Total training time: 27.49 seconds.\n",
      "-- Epoch 410\n",
      "Norm: 6.62, NNZs: 13553, Bias: 2.694862, T: 33826640, Avg. loss: 0.017796\n",
      "Total training time: 27.54 seconds.\n",
      "-- Epoch 411\n",
      "Norm: 6.62, NNZs: 13545, Bias: 2.696677, T: 33909144, Avg. loss: 0.017766\n",
      "Total training time: 27.60 seconds.\n",
      "-- Epoch 412\n",
      "Norm: 6.62, NNZs: 13540, Bias: 2.698498, T: 33991648, Avg. loss: 0.017736\n",
      "Total training time: 27.66 seconds.\n",
      "-- Epoch 413\n",
      "Norm: 6.61, NNZs: 13533, Bias: 2.700283, T: 34074152, Avg. loss: 0.017705\n",
      "Total training time: 27.71 seconds.\n",
      "-- Epoch 414\n",
      "Norm: 6.61, NNZs: 13523, Bias: 2.702082, T: 34156656, Avg. loss: 0.017674\n",
      "Total training time: 27.77 seconds.\n",
      "-- Epoch 415\n",
      "Norm: 6.61, NNZs: 13519, Bias: 2.703852, T: 34239160, Avg. loss: 0.017642\n",
      "Total training time: 27.83 seconds.\n",
      "-- Epoch 416\n",
      "Norm: 6.61, NNZs: 13514, Bias: 2.705642, T: 34321664, Avg. loss: 0.017611\n",
      "Total training time: 27.91 seconds.\n",
      "-- Epoch 417\n",
      "Norm: 6.60, NNZs: 13507, Bias: 2.707397, T: 34404168, Avg. loss: 0.017581\n",
      "Total training time: 27.96 seconds.\n",
      "-- Epoch 418\n",
      "Norm: 6.60, NNZs: 13503, Bias: 2.709178, T: 34486672, Avg. loss: 0.017554\n",
      "Total training time: 28.02 seconds.\n",
      "-- Epoch 419\n",
      "Norm: 6.60, NNZs: 13497, Bias: 2.710948, T: 34569176, Avg. loss: 0.017523\n",
      "Total training time: 28.08 seconds.\n",
      "-- Epoch 420\n",
      "Norm: 6.60, NNZs: 13495, Bias: 2.712733, T: 34651680, Avg. loss: 0.017492\n",
      "Total training time: 28.14 seconds.\n",
      "-- Epoch 421\n",
      "Norm: 6.59, NNZs: 13490, Bias: 2.714438, T: 34734184, Avg. loss: 0.017462\n",
      "Total training time: 28.19 seconds.\n",
      "-- Epoch 422\n",
      "Norm: 6.59, NNZs: 13481, Bias: 2.716218, T: 34816688, Avg. loss: 0.017434\n",
      "Total training time: 28.25 seconds.\n",
      "-- Epoch 423\n",
      "Norm: 6.59, NNZs: 13467, Bias: 2.717959, T: 34899192, Avg. loss: 0.017406\n",
      "Total training time: 28.31 seconds.\n",
      "-- Epoch 424\n",
      "Norm: 6.59, NNZs: 13463, Bias: 2.719680, T: 34981696, Avg. loss: 0.017375\n",
      "Total training time: 28.37 seconds.\n",
      "-- Epoch 425\n",
      "Norm: 6.59, NNZs: 13452, Bias: 2.721421, T: 35064200, Avg. loss: 0.017348\n",
      "Total training time: 28.43 seconds.\n",
      "-- Epoch 426\n",
      "Norm: 6.58, NNZs: 13446, Bias: 2.723128, T: 35146704, Avg. loss: 0.017319\n",
      "Total training time: 28.49 seconds.\n",
      "-- Epoch 427\n",
      "Norm: 6.58, NNZs: 13435, Bias: 2.724846, T: 35229208, Avg. loss: 0.017289\n",
      "Total training time: 28.55 seconds.\n",
      "-- Epoch 428\n",
      "Norm: 6.58, NNZs: 13428, Bias: 2.726587, T: 35311712, Avg. loss: 0.017262\n",
      "Total training time: 28.60 seconds.\n",
      "-- Epoch 429\n",
      "Norm: 6.58, NNZs: 13421, Bias: 2.728267, T: 35394216, Avg. loss: 0.017235\n",
      "Total training time: 28.65 seconds.\n",
      "-- Epoch 430\n",
      "Norm: 6.57, NNZs: 13414, Bias: 2.729988, T: 35476720, Avg. loss: 0.017205\n",
      "Total training time: 28.71 seconds.\n",
      "-- Epoch 431\n",
      "Norm: 6.57, NNZs: 13408, Bias: 2.731645, T: 35559224, Avg. loss: 0.017175\n",
      "Total training time: 28.78 seconds.\n",
      "-- Epoch 432\n",
      "Norm: 6.57, NNZs: 13401, Bias: 2.733393, T: 35641728, Avg. loss: 0.017149\n",
      "Total training time: 28.83 seconds.\n",
      "-- Epoch 433\n",
      "Norm: 6.57, NNZs: 13388, Bias: 2.735061, T: 35724232, Avg. loss: 0.017122\n",
      "Total training time: 28.88 seconds.\n",
      "-- Epoch 434\n",
      "Norm: 6.57, NNZs: 13381, Bias: 2.736724, T: 35806736, Avg. loss: 0.017096\n",
      "Total training time: 28.94 seconds.\n",
      "-- Epoch 435\n",
      "Norm: 6.56, NNZs: 13377, Bias: 2.738394, T: 35889240, Avg. loss: 0.017069\n",
      "Total training time: 29.00 seconds.\n",
      "-- Epoch 436\n",
      "Norm: 6.56, NNZs: 13373, Bias: 2.740062, T: 35971744, Avg. loss: 0.017041\n",
      "Total training time: 29.05 seconds.\n",
      "-- Epoch 437\n",
      "Norm: 6.56, NNZs: 13372, Bias: 2.741735, T: 36054248, Avg. loss: 0.017013\n",
      "Total training time: 29.10 seconds.\n",
      "-- Epoch 438\n",
      "Norm: 6.56, NNZs: 13368, Bias: 2.743385, T: 36136752, Avg. loss: 0.016988\n",
      "Total training time: 29.16 seconds.\n",
      "-- Epoch 439\n",
      "Norm: 6.55, NNZs: 13361, Bias: 2.745053, T: 36219256, Avg. loss: 0.016961\n",
      "Total training time: 29.22 seconds.\n",
      "-- Epoch 440\n",
      "Norm: 6.55, NNZs: 13349, Bias: 2.746709, T: 36301760, Avg. loss: 0.016936\n",
      "Total training time: 29.27 seconds.\n",
      "-- Epoch 441\n",
      "Norm: 6.55, NNZs: 13338, Bias: 2.748344, T: 36384264, Avg. loss: 0.016910\n",
      "Total training time: 29.34 seconds.\n",
      "-- Epoch 442\n",
      "Norm: 6.55, NNZs: 13334, Bias: 2.749983, T: 36466768, Avg. loss: 0.016883\n",
      "Total training time: 29.40 seconds.\n",
      "-- Epoch 443\n",
      "Norm: 6.55, NNZs: 13325, Bias: 2.751619, T: 36549272, Avg. loss: 0.016855\n",
      "Total training time: 29.47 seconds.\n",
      "-- Epoch 444\n",
      "Norm: 6.54, NNZs: 13321, Bias: 2.753237, T: 36631776, Avg. loss: 0.016833\n",
      "Total training time: 29.55 seconds.\n",
      "-- Epoch 445\n",
      "Norm: 6.54, NNZs: 13314, Bias: 2.754863, T: 36714280, Avg. loss: 0.016807\n",
      "Total training time: 29.61 seconds.\n",
      "-- Epoch 446\n",
      "Norm: 6.54, NNZs: 13307, Bias: 2.756462, T: 36796784, Avg. loss: 0.016780\n",
      "Total training time: 29.68 seconds.\n",
      "-- Epoch 447\n",
      "Norm: 6.54, NNZs: 13299, Bias: 2.758086, T: 36879288, Avg. loss: 0.016754\n",
      "Total training time: 29.73 seconds.\n",
      "-- Epoch 448\n",
      "Norm: 6.53, NNZs: 13290, Bias: 2.759688, T: 36961792, Avg. loss: 0.016730\n",
      "Total training time: 29.81 seconds.\n",
      "-- Epoch 449\n",
      "Norm: 6.53, NNZs: 13285, Bias: 2.761304, T: 37044296, Avg. loss: 0.016706\n",
      "Total training time: 29.86 seconds.\n",
      "-- Epoch 450\n",
      "Norm: 6.53, NNZs: 13279, Bias: 2.762889, T: 37126800, Avg. loss: 0.016681\n",
      "Total training time: 29.93 seconds.\n",
      "-- Epoch 451\n",
      "Norm: 6.53, NNZs: 13272, Bias: 2.764480, T: 37209304, Avg. loss: 0.016656\n",
      "Total training time: 29.98 seconds.\n",
      "-- Epoch 452\n",
      "Norm: 6.53, NNZs: 13256, Bias: 2.766039, T: 37291808, Avg. loss: 0.016628\n",
      "Total training time: 30.04 seconds.\n",
      "-- Epoch 453\n",
      "Norm: 6.52, NNZs: 13249, Bias: 2.767647, T: 37374312, Avg. loss: 0.016608\n",
      "Total training time: 30.12 seconds.\n",
      "-- Epoch 454\n",
      "Norm: 6.52, NNZs: 13242, Bias: 2.769224, T: 37456816, Avg. loss: 0.016579\n",
      "Total training time: 30.19 seconds.\n",
      "-- Epoch 455\n",
      "Norm: 6.52, NNZs: 13237, Bias: 2.770798, T: 37539320, Avg. loss: 0.016557\n",
      "Total training time: 30.24 seconds.\n",
      "-- Epoch 456\n",
      "Norm: 6.52, NNZs: 13228, Bias: 2.772366, T: 37621824, Avg. loss: 0.016533\n",
      "Total training time: 30.30 seconds.\n",
      "-- Epoch 457\n",
      "Norm: 6.52, NNZs: 13217, Bias: 2.773921, T: 37704328, Avg. loss: 0.016509\n",
      "Total training time: 30.37 seconds.\n",
      "-- Epoch 458\n",
      "Norm: 6.51, NNZs: 13213, Bias: 2.775470, T: 37786832, Avg. loss: 0.016487\n",
      "Total training time: 30.43 seconds.\n",
      "-- Epoch 459\n",
      "Norm: 6.51, NNZs: 13210, Bias: 2.777033, T: 37869336, Avg. loss: 0.016462\n",
      "Total training time: 30.49 seconds.\n",
      "-- Epoch 460\n",
      "Norm: 6.51, NNZs: 13199, Bias: 2.778576, T: 37951840, Avg. loss: 0.016440\n",
      "Total training time: 30.54 seconds.\n",
      "-- Epoch 461\n",
      "Norm: 6.51, NNZs: 13191, Bias: 2.780130, T: 38034344, Avg. loss: 0.016416\n",
      "Total training time: 30.60 seconds.\n",
      "-- Epoch 462\n",
      "Norm: 6.50, NNZs: 13182, Bias: 2.781638, T: 38116848, Avg. loss: 0.016393\n",
      "Total training time: 30.67 seconds.\n",
      "-- Epoch 463\n",
      "Norm: 6.50, NNZs: 13177, Bias: 2.783176, T: 38199352, Avg. loss: 0.016370\n",
      "Total training time: 30.72 seconds.\n",
      "-- Epoch 464\n",
      "Norm: 6.50, NNZs: 13172, Bias: 2.784694, T: 38281856, Avg. loss: 0.016346\n",
      "Total training time: 30.78 seconds.\n",
      "-- Epoch 465\n",
      "Norm: 6.50, NNZs: 13163, Bias: 2.786234, T: 38364360, Avg. loss: 0.016324\n",
      "Total training time: 30.83 seconds.\n",
      "-- Epoch 466\n",
      "Norm: 6.50, NNZs: 13162, Bias: 2.787755, T: 38446864, Avg. loss: 0.016300\n",
      "Total training time: 30.91 seconds.\n",
      "-- Epoch 467\n",
      "Norm: 6.49, NNZs: 13157, Bias: 2.789263, T: 38529368, Avg. loss: 0.016279\n",
      "Total training time: 30.96 seconds.\n",
      "-- Epoch 468\n",
      "Norm: 6.49, NNZs: 13149, Bias: 2.790765, T: 38611872, Avg. loss: 0.016257\n",
      "Total training time: 31.01 seconds.\n",
      "-- Epoch 469\n",
      "Norm: 6.49, NNZs: 13138, Bias: 2.792267, T: 38694376, Avg. loss: 0.016235\n",
      "Total training time: 31.07 seconds.\n",
      "-- Epoch 470\n",
      "Norm: 6.49, NNZs: 13130, Bias: 2.793771, T: 38776880, Avg. loss: 0.016211\n",
      "Total training time: 31.13 seconds.\n",
      "-- Epoch 471\n",
      "Norm: 6.49, NNZs: 13127, Bias: 2.795262, T: 38859384, Avg. loss: 0.016190\n",
      "Total training time: 31.19 seconds.\n",
      "-- Epoch 472\n",
      "Norm: 6.48, NNZs: 13116, Bias: 2.796744, T: 38941888, Avg. loss: 0.016168\n",
      "Total training time: 31.24 seconds.\n",
      "-- Epoch 473\n",
      "Norm: 6.48, NNZs: 13105, Bias: 2.798244, T: 39024392, Avg. loss: 0.016147\n",
      "Total training time: 31.30 seconds.\n",
      "-- Epoch 474\n",
      "Norm: 6.48, NNZs: 13095, Bias: 2.799704, T: 39106896, Avg. loss: 0.016126\n",
      "Total training time: 31.36 seconds.\n",
      "-- Epoch 475\n",
      "Norm: 6.48, NNZs: 13090, Bias: 2.801205, T: 39189400, Avg. loss: 0.016104\n",
      "Total training time: 31.41 seconds.\n",
      "-- Epoch 476\n",
      "Norm: 6.48, NNZs: 13084, Bias: 2.802697, T: 39271904, Avg. loss: 0.016081\n",
      "Total training time: 31.47 seconds.\n",
      "-- Epoch 477\n",
      "Norm: 6.47, NNZs: 13077, Bias: 2.804130, T: 39354408, Avg. loss: 0.016061\n",
      "Total training time: 31.52 seconds.\n",
      "-- Epoch 478\n",
      "Norm: 6.47, NNZs: 13065, Bias: 2.805617, T: 39436912, Avg. loss: 0.016039\n",
      "Total training time: 31.59 seconds.\n",
      "-- Epoch 479\n",
      "Norm: 6.47, NNZs: 13060, Bias: 2.807055, T: 39519416, Avg. loss: 0.016020\n",
      "Total training time: 31.65 seconds.\n",
      "-- Epoch 480\n",
      "Norm: 6.47, NNZs: 13049, Bias: 2.808503, T: 39601920, Avg. loss: 0.015997\n",
      "Total training time: 31.73 seconds.\n",
      "-- Epoch 481\n",
      "Norm: 6.46, NNZs: 13038, Bias: 2.809949, T: 39684424, Avg. loss: 0.015977\n",
      "Total training time: 31.80 seconds.\n",
      "-- Epoch 482\n",
      "Norm: 6.46, NNZs: 13028, Bias: 2.811401, T: 39766928, Avg. loss: 0.015955\n",
      "Total training time: 31.87 seconds.\n",
      "-- Epoch 483\n",
      "Norm: 6.46, NNZs: 13019, Bias: 2.812850, T: 39849432, Avg. loss: 0.015934\n",
      "Total training time: 31.93 seconds.\n",
      "-- Epoch 484\n",
      "Norm: 6.46, NNZs: 13019, Bias: 2.814261, T: 39931936, Avg. loss: 0.015914\n",
      "Total training time: 32.02 seconds.\n",
      "-- Epoch 485\n",
      "Norm: 6.46, NNZs: 13011, Bias: 2.815721, T: 40014440, Avg. loss: 0.015895\n",
      "Total training time: 32.10 seconds.\n",
      "-- Epoch 486\n",
      "Norm: 6.45, NNZs: 13006, Bias: 2.817137, T: 40096944, Avg. loss: 0.015876\n",
      "Total training time: 32.17 seconds.\n",
      "-- Epoch 487\n",
      "Norm: 6.45, NNZs: 13000, Bias: 2.818544, T: 40179448, Avg. loss: 0.015854\n",
      "Total training time: 32.25 seconds.\n",
      "-- Epoch 488\n",
      "Norm: 6.45, NNZs: 12998, Bias: 2.819954, T: 40261952, Avg. loss: 0.015835\n",
      "Total training time: 32.32 seconds.\n",
      "-- Epoch 489\n",
      "Norm: 6.45, NNZs: 12988, Bias: 2.821390, T: 40344456, Avg. loss: 0.015816\n",
      "Total training time: 32.38 seconds.\n",
      "-- Epoch 490\n",
      "Norm: 6.45, NNZs: 12978, Bias: 2.822795, T: 40426960, Avg. loss: 0.015795\n",
      "Total training time: 32.45 seconds.\n",
      "-- Epoch 491\n",
      "Norm: 6.44, NNZs: 12980, Bias: 2.824188, T: 40509464, Avg. loss: 0.015776\n",
      "Total training time: 32.52 seconds.\n",
      "-- Epoch 492\n",
      "Norm: 6.44, NNZs: 12980, Bias: 2.825607, T: 40591968, Avg. loss: 0.015757\n",
      "Total training time: 32.58 seconds.\n",
      "-- Epoch 493\n",
      "Norm: 6.44, NNZs: 12973, Bias: 2.826998, T: 40674472, Avg. loss: 0.015737\n",
      "Total training time: 32.64 seconds.\n",
      "-- Epoch 494\n",
      "Norm: 6.44, NNZs: 12959, Bias: 2.828395, T: 40756976, Avg. loss: 0.015717\n",
      "Total training time: 32.72 seconds.\n",
      "-- Epoch 495\n",
      "Norm: 6.43, NNZs: 12957, Bias: 2.829763, T: 40839480, Avg. loss: 0.015698\n",
      "Total training time: 32.90 seconds.\n",
      "-- Epoch 496\n",
      "Norm: 6.43, NNZs: 12949, Bias: 2.831186, T: 40921984, Avg. loss: 0.015679\n",
      "Total training time: 33.18 seconds.\n",
      "-- Epoch 497\n",
      "Norm: 6.43, NNZs: 12946, Bias: 2.832536, T: 41004488, Avg. loss: 0.015660\n",
      "Total training time: 33.26 seconds.\n",
      "-- Epoch 498\n",
      "Norm: 6.43, NNZs: 12935, Bias: 2.833910, T: 41086992, Avg. loss: 0.015642\n",
      "Total training time: 33.34 seconds.\n",
      "-- Epoch 499\n",
      "Norm: 6.43, NNZs: 12932, Bias: 2.835291, T: 41169496, Avg. loss: 0.015624\n",
      "Total training time: 33.41 seconds.\n",
      "-- Epoch 500\n",
      "Norm: 6.42, NNZs: 12931, Bias: 2.836647, T: 41252000, Avg. loss: 0.015604\n",
      "Total training time: 33.49 seconds.\n",
      "-- Epoch 501\n",
      "Norm: 6.42, NNZs: 12925, Bias: 2.838017, T: 41334504, Avg. loss: 0.015586\n",
      "Total training time: 33.56 seconds.\n",
      "-- Epoch 502\n",
      "Norm: 6.42, NNZs: 12924, Bias: 2.839383, T: 41417008, Avg. loss: 0.015568\n",
      "Total training time: 33.63 seconds.\n",
      "-- Epoch 503\n",
      "Norm: 6.42, NNZs: 12922, Bias: 2.840734, T: 41499512, Avg. loss: 0.015549\n",
      "Total training time: 33.71 seconds.\n",
      "-- Epoch 504\n",
      "Norm: 6.42, NNZs: 12913, Bias: 2.842100, T: 41582016, Avg. loss: 0.015530\n",
      "Total training time: 33.78 seconds.\n",
      "-- Epoch 505\n",
      "Norm: 6.41, NNZs: 12903, Bias: 2.843422, T: 41664520, Avg. loss: 0.015513\n",
      "Total training time: 33.83 seconds.\n",
      "-- Epoch 506\n",
      "Norm: 6.41, NNZs: 12895, Bias: 2.844765, T: 41747024, Avg. loss: 0.015493\n",
      "Total training time: 33.90 seconds.\n",
      "-- Epoch 507\n",
      "Norm: 6.41, NNZs: 12891, Bias: 2.846106, T: 41829528, Avg. loss: 0.015476\n",
      "Total training time: 33.96 seconds.\n",
      "-- Epoch 508\n",
      "Norm: 6.41, NNZs: 12882, Bias: 2.847453, T: 41912032, Avg. loss: 0.015460\n",
      "Total training time: 34.02 seconds.\n",
      "-- Epoch 509\n",
      "Norm: 6.41, NNZs: 12878, Bias: 2.848779, T: 41994536, Avg. loss: 0.015440\n",
      "Total training time: 34.09 seconds.\n",
      "-- Epoch 510\n",
      "Norm: 6.40, NNZs: 12874, Bias: 2.850110, T: 42077040, Avg. loss: 0.015419\n",
      "Total training time: 34.15 seconds.\n",
      "-- Epoch 511\n",
      "Norm: 6.40, NNZs: 12863, Bias: 2.851436, T: 42159544, Avg. loss: 0.015404\n",
      "Total training time: 34.22 seconds.\n",
      "-- Epoch 512\n",
      "Norm: 6.40, NNZs: 12852, Bias: 2.852743, T: 42242048, Avg. loss: 0.015387\n",
      "Total training time: 34.29 seconds.\n",
      "-- Epoch 513\n",
      "Norm: 6.40, NNZs: 12848, Bias: 2.854060, T: 42324552, Avg. loss: 0.015370\n",
      "Total training time: 34.38 seconds.\n",
      "-- Epoch 514\n",
      "Norm: 6.40, NNZs: 12841, Bias: 2.855387, T: 42407056, Avg. loss: 0.015353\n",
      "Total training time: 34.45 seconds.\n",
      "-- Epoch 515\n",
      "Norm: 6.39, NNZs: 12835, Bias: 2.856678, T: 42489560, Avg. loss: 0.015335\n",
      "Total training time: 34.53 seconds.\n",
      "-- Epoch 516\n",
      "Norm: 6.39, NNZs: 12823, Bias: 2.857994, T: 42572064, Avg. loss: 0.015320\n",
      "Total training time: 34.61 seconds.\n",
      "-- Epoch 517\n",
      "Norm: 6.39, NNZs: 12821, Bias: 2.859279, T: 42654568, Avg. loss: 0.015303\n",
      "Total training time: 34.70 seconds.\n",
      "-- Epoch 518\n",
      "Norm: 6.39, NNZs: 12813, Bias: 2.860593, T: 42737072, Avg. loss: 0.015284\n",
      "Total training time: 34.77 seconds.\n",
      "-- Epoch 519\n",
      "Norm: 6.39, NNZs: 12803, Bias: 2.861882, T: 42819576, Avg. loss: 0.015269\n",
      "Total training time: 34.85 seconds.\n",
      "-- Epoch 520\n",
      "Norm: 6.38, NNZs: 12798, Bias: 2.863157, T: 42902080, Avg. loss: 0.015251\n",
      "Total training time: 34.94 seconds.\n",
      "-- Epoch 521\n",
      "Norm: 6.38, NNZs: 12791, Bias: 2.864459, T: 42984584, Avg. loss: 0.015235\n",
      "Total training time: 35.00 seconds.\n",
      "-- Epoch 522\n",
      "Norm: 6.38, NNZs: 12783, Bias: 2.865720, T: 43067088, Avg. loss: 0.015219\n",
      "Total training time: 35.07 seconds.\n",
      "-- Epoch 523\n",
      "Norm: 6.38, NNZs: 12783, Bias: 2.867011, T: 43149592, Avg. loss: 0.015203\n",
      "Total training time: 35.14 seconds.\n",
      "-- Epoch 524\n",
      "Norm: 6.38, NNZs: 12779, Bias: 2.868271, T: 43232096, Avg. loss: 0.015186\n",
      "Total training time: 35.19 seconds.\n",
      "-- Epoch 525\n",
      "Norm: 6.37, NNZs: 12771, Bias: 2.869541, T: 43314600, Avg. loss: 0.015170\n",
      "Total training time: 35.24 seconds.\n",
      "-- Epoch 526\n",
      "Norm: 6.37, NNZs: 12767, Bias: 2.870802, T: 43397104, Avg. loss: 0.015154\n",
      "Total training time: 35.29 seconds.\n",
      "-- Epoch 527\n",
      "Norm: 6.37, NNZs: 12758, Bias: 2.872062, T: 43479608, Avg. loss: 0.015137\n",
      "Total training time: 35.35 seconds.\n",
      "-- Epoch 528\n",
      "Norm: 6.37, NNZs: 12752, Bias: 2.873317, T: 43562112, Avg. loss: 0.015121\n",
      "Total training time: 35.41 seconds.\n",
      "-- Epoch 529\n",
      "Norm: 6.37, NNZs: 12741, Bias: 2.874563, T: 43644616, Avg. loss: 0.015105\n",
      "Total training time: 35.46 seconds.\n",
      "-- Epoch 530\n",
      "Norm: 6.36, NNZs: 12737, Bias: 2.875832, T: 43727120, Avg. loss: 0.015090\n",
      "Total training time: 35.51 seconds.\n",
      "-- Epoch 531\n",
      "Norm: 6.36, NNZs: 12730, Bias: 2.877068, T: 43809624, Avg. loss: 0.015074\n",
      "Total training time: 35.57 seconds.\n",
      "-- Epoch 532\n",
      "Norm: 6.36, NNZs: 12725, Bias: 2.878310, T: 43892128, Avg. loss: 0.015057\n",
      "Total training time: 35.63 seconds.\n",
      "-- Epoch 533\n",
      "Norm: 6.36, NNZs: 12717, Bias: 2.879553, T: 43974632, Avg. loss: 0.015043\n",
      "Total training time: 35.68 seconds.\n",
      "-- Epoch 534\n",
      "Norm: 6.36, NNZs: 12706, Bias: 2.880816, T: 44057136, Avg. loss: 0.015025\n",
      "Total training time: 35.73 seconds.\n",
      "-- Epoch 535\n",
      "Norm: 6.35, NNZs: 12697, Bias: 2.882028, T: 44139640, Avg. loss: 0.015012\n",
      "Total training time: 35.79 seconds.\n",
      "-- Epoch 536\n",
      "Norm: 6.35, NNZs: 12688, Bias: 2.883254, T: 44222144, Avg. loss: 0.014995\n",
      "Total training time: 35.84 seconds.\n",
      "-- Epoch 537\n",
      "Norm: 6.35, NNZs: 12688, Bias: 2.884481, T: 44304648, Avg. loss: 0.014981\n",
      "Total training time: 35.89 seconds.\n",
      "-- Epoch 538\n",
      "Norm: 6.35, NNZs: 12685, Bias: 2.885682, T: 44387152, Avg. loss: 0.014964\n",
      "Total training time: 35.94 seconds.\n",
      "-- Epoch 539\n",
      "Norm: 6.35, NNZs: 12678, Bias: 2.886910, T: 44469656, Avg. loss: 0.014950\n",
      "Total training time: 36.00 seconds.\n",
      "-- Epoch 540\n",
      "Norm: 6.34, NNZs: 12675, Bias: 2.888139, T: 44552160, Avg. loss: 0.014935\n",
      "Total training time: 36.06 seconds.\n",
      "-- Epoch 541\n",
      "Norm: 6.34, NNZs: 12669, Bias: 2.889336, T: 44634664, Avg. loss: 0.014920\n",
      "Total training time: 36.13 seconds.\n",
      "-- Epoch 542\n",
      "Norm: 6.34, NNZs: 12660, Bias: 2.890539, T: 44717168, Avg. loss: 0.014906\n",
      "Total training time: 36.19 seconds.\n",
      "-- Epoch 543\n",
      "Norm: 6.34, NNZs: 12654, Bias: 2.891747, T: 44799672, Avg. loss: 0.014889\n",
      "Total training time: 36.25 seconds.\n",
      "-- Epoch 544\n",
      "Norm: 6.34, NNZs: 12648, Bias: 2.892946, T: 44882176, Avg. loss: 0.014874\n",
      "Total training time: 36.30 seconds.\n",
      "-- Epoch 545\n",
      "Norm: 6.33, NNZs: 12643, Bias: 2.894150, T: 44964680, Avg. loss: 0.014862\n",
      "Total training time: 36.35 seconds.\n",
      "-- Epoch 546\n",
      "Norm: 6.33, NNZs: 12635, Bias: 2.895322, T: 45047184, Avg. loss: 0.014847\n",
      "Total training time: 36.40 seconds.\n",
      "-- Epoch 547\n",
      "Norm: 6.33, NNZs: 12631, Bias: 2.896526, T: 45129688, Avg. loss: 0.014833\n",
      "Total training time: 36.46 seconds.\n",
      "-- Epoch 548\n",
      "Norm: 6.33, NNZs: 12625, Bias: 2.897716, T: 45212192, Avg. loss: 0.014818\n",
      "Total training time: 36.52 seconds.\n",
      "-- Epoch 549\n",
      "Norm: 6.33, NNZs: 12615, Bias: 2.898890, T: 45294696, Avg. loss: 0.014803\n",
      "Total training time: 36.57 seconds.\n",
      "-- Epoch 550\n",
      "Norm: 6.33, NNZs: 12604, Bias: 2.900080, T: 45377200, Avg. loss: 0.014789\n",
      "Total training time: 36.63 seconds.\n",
      "-- Epoch 551\n",
      "Norm: 6.32, NNZs: 12600, Bias: 2.901242, T: 45459704, Avg. loss: 0.014776\n",
      "Total training time: 36.70 seconds.\n",
      "-- Epoch 552\n",
      "Norm: 6.32, NNZs: 12590, Bias: 2.902427, T: 45542208, Avg. loss: 0.014762\n",
      "Total training time: 36.75 seconds.\n",
      "-- Epoch 553\n",
      "Norm: 6.32, NNZs: 12581, Bias: 2.903591, T: 45624712, Avg. loss: 0.014748\n",
      "Total training time: 36.80 seconds.\n",
      "-- Epoch 554\n",
      "Norm: 6.32, NNZs: 12578, Bias: 2.904771, T: 45707216, Avg. loss: 0.014734\n",
      "Total training time: 36.85 seconds.\n",
      "-- Epoch 555\n",
      "Norm: 6.32, NNZs: 12574, Bias: 2.905924, T: 45789720, Avg. loss: 0.014720\n",
      "Total training time: 36.92 seconds.\n",
      "-- Epoch 556\n",
      "Norm: 6.31, NNZs: 12567, Bias: 2.907078, T: 45872224, Avg. loss: 0.014706\n",
      "Total training time: 36.97 seconds.\n",
      "-- Epoch 557\n",
      "Norm: 6.31, NNZs: 12559, Bias: 2.908237, T: 45954728, Avg. loss: 0.014692\n",
      "Total training time: 37.02 seconds.\n",
      "-- Epoch 558\n",
      "Norm: 6.31, NNZs: 12553, Bias: 2.909386, T: 46037232, Avg. loss: 0.014677\n",
      "Total training time: 37.09 seconds.\n",
      "-- Epoch 559\n",
      "Norm: 6.31, NNZs: 12544, Bias: 2.910537, T: 46119736, Avg. loss: 0.014664\n",
      "Total training time: 37.16 seconds.\n",
      "-- Epoch 560\n",
      "Norm: 6.31, NNZs: 12537, Bias: 2.911663, T: 46202240, Avg. loss: 0.014651\n",
      "Total training time: 37.22 seconds.\n",
      "-- Epoch 561\n",
      "Norm: 6.30, NNZs: 12529, Bias: 2.912824, T: 46284744, Avg. loss: 0.014636\n",
      "Total training time: 37.28 seconds.\n",
      "-- Epoch 562\n",
      "Norm: 6.30, NNZs: 12523, Bias: 2.913963, T: 46367248, Avg. loss: 0.014623\n",
      "Total training time: 37.33 seconds.\n",
      "-- Epoch 563\n",
      "Norm: 6.30, NNZs: 12518, Bias: 2.915093, T: 46449752, Avg. loss: 0.014611\n",
      "Total training time: 37.39 seconds.\n",
      "-- Epoch 564\n",
      "Norm: 6.30, NNZs: 12506, Bias: 2.916242, T: 46532256, Avg. loss: 0.014597\n",
      "Total training time: 37.44 seconds.\n",
      "-- Epoch 565\n",
      "Norm: 6.30, NNZs: 12501, Bias: 2.917356, T: 46614760, Avg. loss: 0.014585\n",
      "Total training time: 37.50 seconds.\n",
      "-- Epoch 566\n",
      "Norm: 6.29, NNZs: 12495, Bias: 2.918481, T: 46697264, Avg. loss: 0.014571\n",
      "Total training time: 37.55 seconds.\n",
      "-- Epoch 567\n",
      "Norm: 6.29, NNZs: 12490, Bias: 2.919621, T: 46779768, Avg. loss: 0.014559\n",
      "Total training time: 37.61 seconds.\n",
      "-- Epoch 568\n",
      "Norm: 6.29, NNZs: 12478, Bias: 2.920718, T: 46862272, Avg. loss: 0.014544\n",
      "Total training time: 37.66 seconds.\n",
      "-- Epoch 569\n",
      "Norm: 6.29, NNZs: 12473, Bias: 2.921841, T: 46944776, Avg. loss: 0.014533\n",
      "Total training time: 37.72 seconds.\n",
      "-- Epoch 570\n",
      "Norm: 6.29, NNZs: 12466, Bias: 2.922944, T: 47027280, Avg. loss: 0.014520\n",
      "Total training time: 37.77 seconds.\n",
      "-- Epoch 571\n",
      "Norm: 6.29, NNZs: 12461, Bias: 2.924050, T: 47109784, Avg. loss: 0.014506\n",
      "Total training time: 37.84 seconds.\n",
      "-- Epoch 572\n",
      "Norm: 6.28, NNZs: 12455, Bias: 2.925161, T: 47192288, Avg. loss: 0.014494\n",
      "Total training time: 37.89 seconds.\n",
      "-- Epoch 573\n",
      "Norm: 6.28, NNZs: 12448, Bias: 2.926264, T: 47274792, Avg. loss: 0.014481\n",
      "Total training time: 37.96 seconds.\n",
      "-- Epoch 574\n",
      "Norm: 6.28, NNZs: 12441, Bias: 2.927375, T: 47357296, Avg. loss: 0.014469\n",
      "Total training time: 38.03 seconds.\n",
      "-- Epoch 575\n",
      "Norm: 6.28, NNZs: 12437, Bias: 2.928475, T: 47439800, Avg. loss: 0.014457\n",
      "Total training time: 38.09 seconds.\n",
      "-- Epoch 576\n",
      "Norm: 6.28, NNZs: 12429, Bias: 2.929561, T: 47522304, Avg. loss: 0.014444\n",
      "Total training time: 38.14 seconds.\n",
      "-- Epoch 577\n",
      "Norm: 6.27, NNZs: 12427, Bias: 2.930651, T: 47604808, Avg. loss: 0.014432\n",
      "Total training time: 38.19 seconds.\n",
      "-- Epoch 578\n",
      "Norm: 6.27, NNZs: 12422, Bias: 2.931745, T: 47687312, Avg. loss: 0.014420\n",
      "Total training time: 38.25 seconds.\n",
      "-- Epoch 579\n",
      "Norm: 6.27, NNZs: 12419, Bias: 2.932827, T: 47769816, Avg. loss: 0.014407\n",
      "Total training time: 38.33 seconds.\n",
      "-- Epoch 580\n",
      "Norm: 6.27, NNZs: 12416, Bias: 2.933915, T: 47852320, Avg. loss: 0.014396\n",
      "Total training time: 38.43 seconds.\n",
      "-- Epoch 581\n",
      "Norm: 6.27, NNZs: 12412, Bias: 2.934989, T: 47934824, Avg. loss: 0.014383\n",
      "Total training time: 38.56 seconds.\n",
      "-- Epoch 582\n",
      "Norm: 6.27, NNZs: 12400, Bias: 2.936068, T: 48017328, Avg. loss: 0.014372\n",
      "Total training time: 38.83 seconds.\n",
      "-- Epoch 583\n",
      "Norm: 6.26, NNZs: 12394, Bias: 2.937133, T: 48099832, Avg. loss: 0.014360\n",
      "Total training time: 38.90 seconds.\n",
      "-- Epoch 584\n",
      "Norm: 6.26, NNZs: 12382, Bias: 2.938195, T: 48182336, Avg. loss: 0.014347\n",
      "Total training time: 38.98 seconds.\n",
      "-- Epoch 585\n",
      "Norm: 6.26, NNZs: 12379, Bias: 2.939274, T: 48264840, Avg. loss: 0.014336\n",
      "Total training time: 39.06 seconds.\n",
      "-- Epoch 586\n",
      "Norm: 6.26, NNZs: 12373, Bias: 2.940339, T: 48347344, Avg. loss: 0.014325\n",
      "Total training time: 39.17 seconds.\n",
      "-- Epoch 587\n",
      "Norm: 6.26, NNZs: 12361, Bias: 2.941398, T: 48429848, Avg. loss: 0.014313\n",
      "Total training time: 39.26 seconds.\n",
      "-- Epoch 588\n",
      "Norm: 6.25, NNZs: 12355, Bias: 2.942442, T: 48512352, Avg. loss: 0.014300\n",
      "Total training time: 39.38 seconds.\n",
      "-- Epoch 589\n",
      "Norm: 6.25, NNZs: 12351, Bias: 2.943501, T: 48594856, Avg. loss: 0.014290\n",
      "Total training time: 39.51 seconds.\n",
      "-- Epoch 590\n",
      "Norm: 6.25, NNZs: 12347, Bias: 2.944546, T: 48677360, Avg. loss: 0.014279\n",
      "Total training time: 39.59 seconds.\n",
      "-- Epoch 591\n",
      "Norm: 6.25, NNZs: 12340, Bias: 2.945597, T: 48759864, Avg. loss: 0.014267\n",
      "Total training time: 39.67 seconds.\n",
      "-- Epoch 592\n",
      "Norm: 6.25, NNZs: 12332, Bias: 2.946629, T: 48842368, Avg. loss: 0.014253\n",
      "Total training time: 39.80 seconds.\n",
      "-- Epoch 593\n",
      "Norm: 6.25, NNZs: 12325, Bias: 2.947692, T: 48924872, Avg. loss: 0.014244\n",
      "Total training time: 39.90 seconds.\n",
      "-- Epoch 594\n",
      "Norm: 6.24, NNZs: 12317, Bias: 2.948718, T: 49007376, Avg. loss: 0.014233\n",
      "Total training time: 40.02 seconds.\n",
      "-- Epoch 595\n",
      "Norm: 6.24, NNZs: 12309, Bias: 2.949766, T: 49089880, Avg. loss: 0.014222\n",
      "Total training time: 40.14 seconds.\n",
      "-- Epoch 596\n",
      "Norm: 6.24, NNZs: 12304, Bias: 2.950792, T: 49172384, Avg. loss: 0.014211\n",
      "Total training time: 40.23 seconds.\n",
      "-- Epoch 597\n",
      "Norm: 6.24, NNZs: 12299, Bias: 2.951830, T: 49254888, Avg. loss: 0.014199\n",
      "Total training time: 40.43 seconds.\n",
      "-- Epoch 598\n",
      "Norm: 6.24, NNZs: 12291, Bias: 2.952844, T: 49337392, Avg. loss: 0.014187\n",
      "Total training time: 40.58 seconds.\n",
      "-- Epoch 599\n",
      "Norm: 6.23, NNZs: 12285, Bias: 2.953867, T: 49419896, Avg. loss: 0.014177\n",
      "Total training time: 40.70 seconds.\n",
      "-- Epoch 600\n",
      "Norm: 6.23, NNZs: 12281, Bias: 2.954885, T: 49502400, Avg. loss: 0.014166\n",
      "Total training time: 40.86 seconds.\n",
      "-- Epoch 601\n",
      "Norm: 6.23, NNZs: 12272, Bias: 2.955904, T: 49584904, Avg. loss: 0.014155\n",
      "Total training time: 41.01 seconds.\n",
      "-- Epoch 602\n",
      "Norm: 6.23, NNZs: 12263, Bias: 2.956917, T: 49667408, Avg. loss: 0.014145\n",
      "Total training time: 41.10 seconds.\n",
      "-- Epoch 603\n",
      "Norm: 6.23, NNZs: 12252, Bias: 2.957927, T: 49749912, Avg. loss: 0.014133\n",
      "Total training time: 41.31 seconds.\n",
      "-- Epoch 604\n",
      "Norm: 6.23, NNZs: 12247, Bias: 2.958935, T: 49832416, Avg. loss: 0.014124\n",
      "Total training time: 41.58 seconds.\n",
      "-- Epoch 605\n",
      "Norm: 6.22, NNZs: 12236, Bias: 2.959925, T: 49914920, Avg. loss: 0.014113\n",
      "Total training time: 41.91 seconds.\n",
      "-- Epoch 606\n",
      "Norm: 6.22, NNZs: 12228, Bias: 2.960948, T: 49997424, Avg. loss: 0.014103\n",
      "Total training time: 42.31 seconds.\n",
      "-- Epoch 607\n",
      "Norm: 6.22, NNZs: 12223, Bias: 2.961942, T: 50079928, Avg. loss: 0.014092\n",
      "Total training time: 42.58 seconds.\n",
      "-- Epoch 608\n",
      "Norm: 6.22, NNZs: 12218, Bias: 2.962933, T: 50162432, Avg. loss: 0.014081\n",
      "Total training time: 42.72 seconds.\n",
      "-- Epoch 609\n",
      "Norm: 6.22, NNZs: 12217, Bias: 2.963938, T: 50244936, Avg. loss: 0.014072\n",
      "Total training time: 42.82 seconds.\n",
      "-- Epoch 610\n",
      "Norm: 6.21, NNZs: 12209, Bias: 2.964925, T: 50327440, Avg. loss: 0.014061\n",
      "Total training time: 42.92 seconds.\n",
      "-- Epoch 611\n",
      "Norm: 6.21, NNZs: 12204, Bias: 2.965910, T: 50409944, Avg. loss: 0.014052\n",
      "Total training time: 43.01 seconds.\n",
      "-- Epoch 612\n",
      "Norm: 6.21, NNZs: 12196, Bias: 2.966900, T: 50492448, Avg. loss: 0.014040\n",
      "Total training time: 43.12 seconds.\n",
      "-- Epoch 613\n",
      "Norm: 6.21, NNZs: 12190, Bias: 2.967884, T: 50574952, Avg. loss: 0.014031\n",
      "Total training time: 43.35 seconds.\n",
      "-- Epoch 614\n",
      "Norm: 6.21, NNZs: 12185, Bias: 2.968863, T: 50657456, Avg. loss: 0.014020\n",
      "Total training time: 43.48 seconds.\n",
      "-- Epoch 615\n",
      "Norm: 6.21, NNZs: 12177, Bias: 2.969838, T: 50739960, Avg. loss: 0.014009\n",
      "Total training time: 43.63 seconds.\n",
      "-- Epoch 616\n",
      "Norm: 6.20, NNZs: 12171, Bias: 2.970820, T: 50822464, Avg. loss: 0.013999\n",
      "Total training time: 43.82 seconds.\n",
      "-- Epoch 617\n",
      "Norm: 6.20, NNZs: 12165, Bias: 2.971781, T: 50904968, Avg. loss: 0.013990\n",
      "Total training time: 44.11 seconds.\n",
      "-- Epoch 618\n",
      "Norm: 6.20, NNZs: 12160, Bias: 2.972762, T: 50987472, Avg. loss: 0.013980\n",
      "Total training time: 44.24 seconds.\n",
      "-- Epoch 619\n",
      "Norm: 6.20, NNZs: 12153, Bias: 2.973722, T: 51069976, Avg. loss: 0.013970\n",
      "Total training time: 44.37 seconds.\n",
      "-- Epoch 620\n",
      "Norm: 6.20, NNZs: 12147, Bias: 2.974681, T: 51152480, Avg. loss: 0.013960\n",
      "Total training time: 44.46 seconds.\n",
      "-- Epoch 621\n",
      "Norm: 6.20, NNZs: 12143, Bias: 2.975649, T: 51234984, Avg. loss: 0.013950\n",
      "Total training time: 44.53 seconds.\n",
      "-- Epoch 622\n",
      "Norm: 6.19, NNZs: 12139, Bias: 2.976599, T: 51317488, Avg. loss: 0.013942\n",
      "Total training time: 44.60 seconds.\n",
      "-- Epoch 623\n",
      "Norm: 6.19, NNZs: 12133, Bias: 2.977562, T: 51399992, Avg. loss: 0.013931\n",
      "Total training time: 44.68 seconds.\n",
      "-- Epoch 624\n",
      "Norm: 6.19, NNZs: 12127, Bias: 2.978505, T: 51482496, Avg. loss: 0.013921\n",
      "Total training time: 44.75 seconds.\n",
      "-- Epoch 625\n",
      "Norm: 6.19, NNZs: 12124, Bias: 2.979455, T: 51565000, Avg. loss: 0.013912\n",
      "Total training time: 44.81 seconds.\n",
      "-- Epoch 626\n",
      "Norm: 6.19, NNZs: 12115, Bias: 2.980420, T: 51647504, Avg. loss: 0.013902\n",
      "Total training time: 44.96 seconds.\n",
      "-- Epoch 627\n",
      "Norm: 6.19, NNZs: 12107, Bias: 2.981357, T: 51730008, Avg. loss: 0.013893\n",
      "Total training time: 45.25 seconds.\n",
      "-- Epoch 628\n",
      "Norm: 6.18, NNZs: 12105, Bias: 2.982285, T: 51812512, Avg. loss: 0.013883\n",
      "Total training time: 45.52 seconds.\n",
      "-- Epoch 629\n",
      "Norm: 6.18, NNZs: 12100, Bias: 2.983230, T: 51895016, Avg. loss: 0.013875\n",
      "Total training time: 45.66 seconds.\n",
      "-- Epoch 630\n",
      "Norm: 6.18, NNZs: 12092, Bias: 2.984181, T: 51977520, Avg. loss: 0.013865\n",
      "Total training time: 45.82 seconds.\n",
      "-- Epoch 631\n",
      "Norm: 6.18, NNZs: 12087, Bias: 2.985108, T: 52060024, Avg. loss: 0.013856\n",
      "Total training time: 45.95 seconds.\n",
      "Convergence after 631 epochs took 45.96 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18749775054311205"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDRegressor(penalty='elasticnet', random_state=0, max_iter=1000, tol=1e-5, l1_ratio=0.05, verbose=1)\n",
    "sgd.fit(csr_matrix(trainX), trainY)\n",
    "\n",
    "preds = sgd.predict(testX)\n",
    "diffs = preds - testY\n",
    "sumsq = np.dot(diffs, diffs)\n",
    "rmse = np.sqrt(sumsq / len(diffs))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That's a pretty good improvement from just guessing.  Let's see what words were important, and how much abv mattered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17228, 0.50686279220863983),\n",
       " (20133, 0.49121573087755716),\n",
       " (3168, 0.47855818997624389),\n",
       " (18903, -0.42229361962574269),\n",
       " (6780, 0.40464093614146163),\n",
       " (3311, 0.35504994322429345),\n",
       " (12915, -0.30869111345802763),\n",
       " (16374, 0.29445142113229972),\n",
       " (3402, 0.29318122609719283),\n",
       " (14158, 0.27980232261017818),\n",
       " (15341, 0.27888629371666618)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influencers = sorted(enumerate(sgd.coef_), key=lambda x: abs(x[1]), reverse=True)\n",
    "influencers[:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly positive weightings, and abv looks like the second on the list (20134 features after tacking on abv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_influencers(countvec, sorted_weights, start_idx, count):\n",
    "    plt.bar(np.arange(count), [(i[1]) for i in sorted_weights[start_idx:start_idx+count]],\n",
    "            color='darkgreen')\n",
    "    plt.xticks(np.arange(count), \n",
    "               [countvec.get_feature_names()[i[0]] if i[0]\n",
    "                != len(sorted_weights)-1 else 'ABV' \n",
    "                for i in sorted_weights[start_idx:start_idx+count]],\n",
    "                rotation='vertical')\n",
    "    plt.ylabel('coefficient')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAE6CAYAAAABX7UfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113b9f208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_influencers(cv, influencers, 0, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly brewery names and abv dominating the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just take it for a run through the \"menus\" and see how accurate it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random guesses first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for randomly choosing 3 beers off the menu: 0.5531046725022023\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for u in testers.index.unique():\n",
    "    udf = testers.loc[u, ['rating_user','rating_global']]\n",
    "    scores.append(untied_rank(udf.rating_user.values, \n",
    "                    udf.rating_user.values[np.random.permutation(range(len(udf)))[:3]]))\n",
    "print(f'Accuracy for randomly choosing 3 beers off the menu: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with slightly more educated guesses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "scores = []\n",
    "vecs = vecs.toarray()\n",
    "for u in tqdm(testers.index.unique()):\n",
    "    udf = testers.loc[u, ['rating_user', 'beer_id']]\n",
    "    vi_test = udf.beer_id.map(beer_id_to_vecs_index)\n",
    "    udf['preds'] = sgd.predict(vecs[vi_test, :])\n",
    "    scores.append(untied_rank(udf.rating_user.values, \n",
    "                              udf.rating_user.values[np.argsort(udf.preds.values)[:-4:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score picking the top 3 globally rated for 652 \"menus\":  0.6688086805312844\n"
     ]
    }
   ],
   "source": [
    "print(f'The average score picking the top 3 globally rated for {len(scores)} \"menus\":  {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, halfway between guessing and using the global mean ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's move on to a similar scenario, but this time we have some of the user's ratings under our belt, and can make better recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "One way of looking at the problem is to try to predict how the user would rate all of the possible choices and then recommend the top few in order.  Any such predictive model must consider two crucial factors:  1) The mean rating of the beers by the rest of the world, and 2) The current user's generosity or stinginess in rating.  \n",
    "Those 2 factors go a long way toward predicting how the user will rate any new beer.  And yet they really leave us no further than where we were earlier, when the user was looking at a menu of 10 beer choices.  We already saw that the global mean gives us a pretty good guide for recommendations, but can't we do better, now that we're armed with some knowledge of how generous the current user is with her ratings?  We can adjust the global means of the beers she considers by adding her historical bias, and thus get a better prediction for how she'll rate them.  But that does nothing to differentiate them from her other choices.  She'll rate them all higher or lower, on average, depending on her mental rating scale.  What we're looking for is something that will use patterns in her ratings that suggest when she'll rate beers above the combination of the beer's baseline (global mean rating) and her baseline (generosity/stinginess).  The job of the recommender, beyond indicating to the user which beers get highest ratings, is to tell the user, \"Based on your rating of beers A and B, it is more likely that you'll appreciate beer C than beers D and E.  Not because beer C has higher average ratings than D and E, but because the way your ratings for A and B deviated from the expected ratings suggests that your rating for C will deviate more positively than your ratings for D and E would.\"  \n",
    "This makes clear the choice we'll have to make when we score each recommendation, and there's really no other option than to make the scorer depend on the situation at hand. Our decisions depend on what choices the user has at the moment of recommendation, whether the user is looking for something that fits her tastes closely (no matter if it's highly or poorly rated), or whether she's looking for the top-rated choice, regardless of whether it fits her taste style.  It could be quite useful to have the recommender show \"These are the 3 most popular beers out of the ones you're considering\", alongside \"These are the 3 that seem to fit your rating history best\".  Since we already looked at the approach to the 3 most popular, let's take a look now at the 3 best fits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by making a feature that shows for each checkin how the rating differed from the expected rating, given the user's inherent bias and the beer's global rating.  A key point here is that we must separate a training set from a testing set before calculating means and deviations from the mean.  When making recommendations, we can't have any more clue as to the user's overall tendencies than we already know at that point in time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3814"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's all the users who have 20-something checkins.  Looks like about 150 of them (3814 / ~25)\n",
    "twenties = checkins[(checkins.user_id.map(usercounts) > 19) &\n",
    "                    (checkins.user_id.map(usercounts) < 30)]\n",
    "len(twenties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkin_id</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>802510823</td>\n",
       "      <td>2095023</td>\n",
       "      <td>1496514</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Stone Brewing Stone Scorpion Bowl IPA To creat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>790728295</td>\n",
       "      <td>1044097</td>\n",
       "      <td>1887470</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Ruination Double IPA 2.0</td>\n",
       "      <td>IPA - Imperial / Double</td>\n",
       "      <td>4.01290</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Stone Brewing Stone Ruination Double IPA 2.0 S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>795640121</td>\n",
       "      <td>1070</td>\n",
       "      <td>1887470</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Lagunitas Brewing Company</td>\n",
       "      <td>Imperial Stout</td>\n",
       "      <td>Stout - Russian Imperial</td>\n",
       "      <td>3.91420</td>\n",
       "      <td>9.9</td>\n",
       "      <td>Lagunitas Brewing Company Imperial Stout Made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>734019632</td>\n",
       "      <td>490277</td>\n",
       "      <td>2930139</td>\n",
       "      <td>5.00</td>\n",
       "      <td>Pizza Port Brewing Company</td>\n",
       "      <td>Swami's IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.84851</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Pizza Port Brewing Company Swami's IPA Note: S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>717409906</td>\n",
       "      <td>1390262</td>\n",
       "      <td>6419897</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Coronado Brewing Company</td>\n",
       "      <td>Guava Islander</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.67951</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Coronado Brewing Company Guava Islander Tropic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      checkin_id  beer_id  user_id  rating_user                brewery_name  \\\n",
       "29     802510823  2095023  1496514         3.75               Stone Brewing   \n",
       "794    790728295  1044097  1887470         4.00               Stone Brewing   \n",
       "899    795640121     1070  1887470         4.00   Lagunitas Brewing Company   \n",
       "954    734019632   490277  2930139         5.00  Pizza Port Brewing Company   \n",
       "2274   717409906  1390262  6419897         4.00    Coronado Brewing Company   \n",
       "\n",
       "                           beer_name                beer_style  rating_global  \\\n",
       "29           Stone Scorpion Bowl IPA            IPA - American        3.73789   \n",
       "794   Stone Ruination Double IPA 2.0   IPA - Imperial / Double        4.01290   \n",
       "899                   Imperial Stout  Stout - Russian Imperial        3.91420   \n",
       "954                      Swami's IPA            IPA - American        3.84851   \n",
       "2274                  Guava Islander            IPA - American        3.67951   \n",
       "\n",
       "      abv                                   beer_description  \n",
       "29    7.5  Stone Brewing Stone Scorpion Bowl IPA To creat...  \n",
       "794   8.5  Stone Brewing Stone Ruination Double IPA 2.0 S...  \n",
       "899   9.9  Lagunitas Brewing Company Imperial Stout Made ...  \n",
       "954   6.8  Pizza Port Brewing Company Swami's IPA Note: S...  \n",
       "2274  7.0  Coronado Brewing Company Guava Islander Tropic...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkin_id</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15451</th>\n",
       "      <td>565488682</td>\n",
       "      <td>337182</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Prohibition Brewing Co.</td>\n",
       "      <td>Lawless IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.36052</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Prohibition Brewing Co. Lawless IPA Prohibitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15451</th>\n",
       "      <td>643941101</td>\n",
       "      <td>1991090</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Fuggles &amp; Warlock Craftworks</td>\n",
       "      <td>Valis Imperial IPA</td>\n",
       "      <td>IPA - Imperial / Double</td>\n",
       "      <td>3.83498</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Fuggles &amp; Warlock Craftworks  Valis Imperial I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15451</th>\n",
       "      <td>673136169</td>\n",
       "      <td>2890172</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Callister Brewing Co.</td>\n",
       "      <td>Brut Force</td>\n",
       "      <td>IPA - Brut</td>\n",
       "      <td>3.58824</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Callister Brewing Co. Brut Force Fresh-hopped ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15451</th>\n",
       "      <td>701437622</td>\n",
       "      <td>2320558</td>\n",
       "      <td>4.25</td>\n",
       "      <td>Moody Ales</td>\n",
       "      <td>Black IPA</td>\n",
       "      <td>IPA - Black / Cascadian Dark Ale</td>\n",
       "      <td>3.61538</td>\n",
       "      <td>5.6</td>\n",
       "      <td>Moody Ales Black IPA Black IPA brewed with 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15451</th>\n",
       "      <td>719884360</td>\n",
       "      <td>3011095</td>\n",
       "      <td>4.50</td>\n",
       "      <td>Steel &amp; Oak Brewing Co.</td>\n",
       "      <td>A-Side</td>\n",
       "      <td>IPA - New England</td>\n",
       "      <td>3.91641</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Steel &amp; Oak Brewing Co. A-Side We got together...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         checkin_id  beer_id  rating_user                   brewery_name  \\\n",
       "user_id                                                                    \n",
       "15451     565488682   337182         3.00        Prohibition Brewing Co.   \n",
       "15451     643941101  1991090         3.50  Fuggles & Warlock Craftworks    \n",
       "15451     673136169  2890172         3.75          Callister Brewing Co.   \n",
       "15451     701437622  2320558         4.25                     Moody Ales   \n",
       "15451     719884360  3011095         4.50        Steel & Oak Brewing Co.   \n",
       "\n",
       "                  beer_name                        beer_style  rating_global  \\\n",
       "user_id                                                                        \n",
       "15451           Lawless IPA                    IPA - American        3.36052   \n",
       "15451    Valis Imperial IPA           IPA - Imperial / Double        3.83498   \n",
       "15451            Brut Force                        IPA - Brut        3.58824   \n",
       "15451             Black IPA  IPA - Black / Cascadian Dark Ale        3.61538   \n",
       "15451                A-Side                 IPA - New England        3.91641   \n",
       "\n",
       "         abv                                   beer_description  \n",
       "user_id                                                          \n",
       "15451    6.5  Prohibition Brewing Co. Lawless IPA Prohibitio...  \n",
       "15451    9.0  Fuggles & Warlock Craftworks  Valis Imperial I...  \n",
       "15451    6.4  Callister Brewing Co. Brut Force Fresh-hopped ...  \n",
       "15451    5.6  Moody Ales Black IPA Black IPA brewed with 100...  \n",
       "15451    6.5  Steel & Oak Brewing Co. A-Side We got together...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with sorted checkins for each user, we can simulate having a user's rating history when recommending\n",
    "twenties.sort_values(by=['user_id', 'checkin_id'], inplace=True)\n",
    "twenties.set_index('user_id', inplace=True)\n",
    "twenties.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_last_X(frame, countDict, X):\n",
    "    '''\n",
    "    Split the input frame into training and testing,\n",
    "    using the last X for each user as testers.\n",
    "    CountDict input has the rows per user,\n",
    "    and the frame is indexed by user.\n",
    "    Returns the train split and test split\n",
    "    '''\n",
    "    boollist = [[True] * (countDict[u] - X) + [False] * X for u in frame.index.unique()]\n",
    "    boollist = np.array([boo for lis in boollist for boo in lis])  # numpy to help with the logic\n",
    "    \n",
    "    return frame[boollist], frame[~boollist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenties.index.nunique()  # to make sure split function works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1630"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainers, testers = split_last_X(twenties, usercounts, 10)\n",
    "len(testers)  # s/b 1630"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what custom score we get just using the most popular 3 as before, then see if we can improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score picking the top 3 globally rated for 163 \"menus\":  0.76472085523876\n"
     ]
    }
   ],
   "source": [
    "top_rank_scores = []\n",
    "for u in testers.index.unique():\n",
    "    utest = testers.loc[u, ['rating_user','rating_global']]\n",
    "    top_rank_scores.append(untied_rank(utest.rating_user.values, \n",
    "                              utest.rating_user.values[np.argsort(utest.rating_global.values)[:-4:-1]]))\n",
    "print(f'The average score picking the top 3 globally rated for 163 \"menus\":  {np.mean(top_rank_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_rank_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.765 is our target to beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Now for that training column that shows unexpected deviation from mean ratings\n",
    "trainers['udiff'] = trainers.rating_user - trainers.rating_global\n",
    "trainers['udev'] = trainers.udiff - trainers.index.map(trainers.groupby(trainers.index)['udiff'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkin_id</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "      <th>udiff</th>\n",
       "      <th>udev</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15451</th>\n",
       "      <td>565488682</td>\n",
       "      <td>337182</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Prohibition Brewing Co.</td>\n",
       "      <td>Lawless IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.36052</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Prohibition Brewing Co. Lawless IPA Prohibitio...</td>\n",
       "      <td>-0.36052</td>\n",
       "      <td>-0.501174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         checkin_id  beer_id  rating_user             brewery_name  \\\n",
       "user_id                                                              \n",
       "15451     565488682   337182          3.0  Prohibition Brewing Co.   \n",
       "\n",
       "           beer_name      beer_style  rating_global  abv  \\\n",
       "user_id                                                    \n",
       "15451    Lawless IPA  IPA - American        3.36052  6.5   \n",
       "\n",
       "                                          beer_description    udiff      udev  \n",
       "user_id                                                                        \n",
       "15451    Prohibition Brewing Co. Lawless IPA Prohibitio... -0.36052 -0.501174  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainers.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we'll isolate that last column, \"udev\", when training for each user, and although we probably won't learn much training on 10-20 checkins for these users, we should see a slight improvement from 0.765"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same bag of words from before.  The words may not show much, but at least likes/dislikes of specific breweries and preferences for abv should tick the score up a tiny bit.  Let's see...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGDRegressor(penalty='elasticnet', random_state=0, max_iter=1000, tol=1e-5, l1_ratio=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 163/163 [02:06<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "scores = []\n",
    "for u in tqdm(trainers.index.unique()):\n",
    "    udf = trainers.loc[u]\n",
    "    vi_train = udf.beer_id.map(beer_id_to_vecs_index)\n",
    "    trainX = vecs[vi_train, :]\n",
    "    vi_test = testers.loc[u].beer_id.map(beer_id_to_vecs_index)\n",
    "    testX = vecs[vi_test, :]\n",
    "    gbr.fit(trainX, udf.udev.values)\n",
    "    dev_preds = gbr.predict(testX)\n",
    "    preds = testers.loc[u].rating_global + dev_preds   # no need to add the (constant) user_bias here, since we want rankings\n",
    "    #preds = np.clip(preds, 0.25, 5.0)  # no need to clip since using relative rankings\n",
    "    scores.append(untied_rank(testers.loc[u].rating_user.values, \n",
    "                              testers.loc[u].rating_user.values[np.argsort(preds)[:-4:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for choosing 3 beers off the menu, based on the user's first 10-20 ratings: 0.7458876571211996\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for choosing 3 beers off the menu, based on the user\\'s first 10-20 ratings: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's worse than just using global ratings to rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 163/163 [02:07<00:00,  1.33it/s]\n",
      "100%|| 163/163 [02:04<00:00,  1.31it/s]\n",
      "100%|| 163/163 [02:05<00:00,  1.34it/s]\n",
      "100%|| 163/163 [02:04<00:00,  1.36it/s]\n",
      "100%|| 163/163 [02:04<00:00,  1.35it/s]\n",
      "100%|| 163/163 [02:05<00:00,  1.31it/s]\n",
      "100%|| 163/163 [02:04<00:00,  1.32it/s]\n",
      "100%|| 163/163 [02:05<00:00,  1.35it/s]\n",
      "100%|| 163/163 [02:04<00:00,  1.32it/s]\n",
      "100%|| 163/163 [02:04<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "scoreboard = []\n",
    "for x in range(2,12):\n",
    "    scores = []\n",
    "    for u in tqdm(trainers.index.unique()):\n",
    "        udf = trainers.loc[u]\n",
    "        vi_train = udf.beer_id.map(beer_id_to_vecs_index)\n",
    "        trainX = vecs[vi_train, :]\n",
    "        vi_test = testers.loc[u].beer_id.map(beer_id_to_vecs_index)\n",
    "        testX = vecs[vi_test, :]\n",
    "        gbr.fit(trainX, udf.udev.values)\n",
    "        dev_preds = gbr.predict(testX)\n",
    "        preds = testers.loc[u].rating_global + dev_preds   # no need to add the (constant) user_bias here, since we want rankings\n",
    "\n",
    "        scores.append(untied_rank(testers.loc[u].rating_user.values, \n",
    "                              testers.loc[u].rating_user.values[np.argsort(preds)[:-x:-1]]))\n",
    "    scoreboard.append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSxjGGGNC8l/t+Co5FLlF8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111ab6dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,11), scoreboard, color='darkgreen', label='Adding GBR predictions')\n",
    "plt.plot(range(1,11), allscores, '--', label='Using top-rated for picks')\n",
    "plt.title('Recommender accuracy with and without GBR picks')\n",
    "plt.xlabel('Number of items recommended out of ten')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Switch to user-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkins.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with sorted checkins for each user, we can simulate having a user's rating history when recommending\n",
    "checkins.sort_values(by=['user_id', 'checkin_id'], inplace=True)\n",
    "checkins.set_index('user_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1027674 training rows, 72370 testing rows\n"
     ]
    }
   ],
   "source": [
    "# gather the users who have more than 50 ratings and save their last 10 for testing\n",
    "bigs = checkins.index.map(usercounts) > 49\n",
    "smalls = checkins[~bigs]\n",
    "tr, test = split_last_X(checkins[bigs], usercounts, 10)\n",
    "train = pd.concat([smalls, tr])\n",
    "print(f'{train.shape[0]} training rows, {test.shape[0]} testing rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score picking the top 3 globally rated for 7237 \"menus\":  0.7727329901323322\n"
     ]
    }
   ],
   "source": [
    "# baseline (top picks) results/target\n",
    "top_rank_scores = []\n",
    "for u in test.index.unique():\n",
    "    utest = test.loc[u, ['rating_user','rating_global']]\n",
    "    top_rank_scores.append(untied_rank(utest.rating_user.values, \n",
    "                              utest.rating_user.values[np.argsort(utest.rating_global.values)[:-4:-1]]))\n",
    "print(f'The average score picking the top 3 globally rated for {len(top_rank_scores)} \"menus\":  {np.mean(top_rank_scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure why that's higher than for the users with fewer ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['udiff'] = train.rating_user - train.rating_global\n",
    "train['udev'] = train.udiff - train.index.map(train.groupby(train.index)['udiff'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "udict = {uid:dict() for uid in train.user_id.unique()}\n",
    "bdict = {bid:dict() for bid in train.beer_id.unique()}\n",
    "for checkin in zip(train.user_id, train.beer_id, train.udev):\n",
    "    udict[checkin[0]][checkin[1]] = checkin[2]\n",
    "    bdict[checkin[1]][checkin[0]] = checkin[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 46894/46894 [1:43:11<00:00,  7.57it/s]     \n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# calculate user/user correlation/similarity \n",
    "shared = {u: defaultdict(lambda: defaultdict(float)) for u in udict}\n",
    "# this may take a minute or maybe an hour, depending on memory, with the nested loops, but seems messy otherwise\n",
    "for u in tqdm(udict):\n",
    "    # loop thru all checkins by u\n",
    "    for b in udict[u]:\n",
    "        # update the similarity factors for u-v for every checkin, as would happen with new checkins\n",
    "        for v in bdict[b]:\n",
    "            suv = shared[u][v]\n",
    "            suv['count'] += 1  # increment the common u-v ratings\n",
    "            #### stats.stackexchange has these going last, but then each new sample\n",
    "            ##### updates to a diff from mean that it contributes to, which seems wrong\n",
    "            ###### (and messes up the first one, where u_bar == u[b])  ####\n",
    "            u_dev = udict[u][b] - suv['u_bar']\n",
    "            v_dev = udict[v][b] - suv['v_bar']\n",
    "            suv['numer'] += u_dev * v_dev\n",
    "            suv['denom_1'] += u_dev ** 2\n",
    "            suv['denom_2'] += v_dev ** 2\n",
    "            #####\n",
    "            suv['u_bar'] = ((suv['count']-1) * suv['u_bar'] + udict[u][b]) / suv['count']\n",
    "            suv['v_bar'] = ((suv['count']-1) * suv['v_bar'] + udict[v][b]) / suv['count']\n",
    "            \n",
    "    # remove self-edges\n",
    "    del shared[u][u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the global rating for each beer differs slightly from checkin to checkin,\n",
    "## due to accumulating stats over time.  Also I'm using each beer's listed\n",
    "## global rating mean, instead of the mean of all global ratings...\n",
    "beer_mu = dict(train.groupby('beer_id').rating_global.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
