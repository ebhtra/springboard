{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn pickled Untappd User Feed data into Pandas DF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userFeedDicts.pkl         userFeedDicts_part_2.pkl  userFeedDicts_part_6.pkl\r\n",
      "userFeedDicts_part_10.pkl userFeedDicts_part_3.pkl  userFeedDicts_part_7.pkl\r\n",
      "userFeedDicts_part_11.pkl userFeedDicts_part_4.pkl  userFeedDicts_part_8.pkl\r\n",
      "userFeedDicts_part_12.pkl userFeedDicts_part_5.pkl  userFeedDicts_part_9.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls capstone_1/userFeeds/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# running this manually and iterating this variable every time\n",
    "part = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 87167\n"
     ]
    }
   ],
   "source": [
    "with open(f'capstone_1/userFeeds/userFeedDicts_part_{part}.pkl', 'rb') as f:\n",
    "    feed = pickle.load(f)\n",
    "\n",
    "print(type(feed), len(feed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of those 87K dict items have no data, so filter down to the data ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "694"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed = {user:feed[user] for user in feed if feed[user]['datalist']}  # empty datalists will eval to False\n",
    "len(feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just drilling down to the level where all the data are\n",
    "feed = [data['response']['checkins']['items'] for val in feed.values() for data in val['datalist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There are a lot of data here, so let's use a generator to control the flow\n",
    "checkins = (pd.io.json.json_normalize(checkin) for checkin in feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inspect structure\n",
    "#checkin_df = next(checkins)\n",
    "#checkin_df.shape  # So 50 checkins per batch,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Going to keep about a third of those 76 columns and reorder them for easier viewing\n",
    "keepcols=['checkin_id', 'beer.bid', 'user.uid', 'rating_score', 'beer.beer_abv', \n",
    "          'brewery.brewery_name','beer.beer_name', 'beer.beer_style',  \n",
    "           'brewery.brewery_id', 'brewery.brewery_type', 'brewery.country_name',\n",
    "          'brewery.location.brewery_city', 'brewery.location.brewery_state',\n",
    "          'brewery.location.lat', 'brewery.location.lng', 'user.user_name',\n",
    "          'venue.categories.items', 'venue.location.lat', 'venue.location.lng',\n",
    "         'venue.location.venue_city', 'venue.location.venue_country', \n",
    "          'venue.location.venue_state', 'venue.primary_category',\n",
    "          'venue.venue_id', 'checkin_comment','created_at', \n",
    "       ]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 segments built\n",
      "800 segments built\n",
      "1200 segments built\n",
      "1600 segments built\n",
      "2000 segments built\n",
      "2400 segments built\n",
      "appending 12 final batches\n"
     ]
    }
   ],
   "source": [
    "built = 0 # counter to monitor progress\n",
    "batch_concat = []\n",
    "batch_size = 40\n",
    "while True:\n",
    "    # concat vertically until generator runs out\n",
    "    batch = []\n",
    "    try:\n",
    "        for _ in range(batch_size):\n",
    "            batch.append(next(checkins))\n",
    "        batch = pd.concat(batch, axis=0, ignore_index=True)\n",
    "        # save some size by trimming 2/3 of the frame\n",
    "        batch_concat.append(batch[keepcols])\n",
    "        built += 1\n",
    "        if built % 10 == 0:\n",
    "            print(f'{built * batch_size} segments built')\n",
    "    except StopIteration:\n",
    "        print(f'appending {len(batch)} final batches')\n",
    "        batch = pd.concat(batch, axis=0, ignore_index=True)\n",
    "        batch_concat.append(batch[keepcols])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat(batch_concat, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136019, 26)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(f'capstone_1/checkins/df_{part}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 177458 entries, 0 to 177457\n",
      "Data columns (total 26 columns):\n",
      "checkin_id                        177458 non-null int64\n",
      "beer.bid                          177458 non-null int64\n",
      "user.uid                          177458 non-null int64\n",
      "rating_score                      177458 non-null float64\n",
      "beer.beer_abv                     177458 non-null float64\n",
      "brewery.brewery_name              177458 non-null object\n",
      "beer.beer_name                    177458 non-null object\n",
      "beer.beer_style                   177458 non-null object\n",
      "brewery.brewery_id                177458 non-null int64\n",
      "brewery.brewery_type              177458 non-null object\n",
      "brewery.country_name              177458 non-null object\n",
      "brewery.location.brewery_city     177458 non-null object\n",
      "brewery.location.brewery_state    177458 non-null object\n",
      "brewery.location.lat              177458 non-null float64\n",
      "brewery.location.lng              177458 non-null float64\n",
      "user.user_name                    177458 non-null object\n",
      "venue.categories.items            127368 non-null object\n",
      "venue.location.lat                127368 non-null float64\n",
      "venue.location.lng                127368 non-null float64\n",
      "venue.location.venue_city         127368 non-null object\n",
      "venue.location.venue_country      127345 non-null object\n",
      "venue.location.venue_state        127368 non-null object\n",
      "venue.primary_category            126541 non-null object\n",
      "venue.venue_id                    127368 non-null float64\n",
      "checkin_comment                   177458 non-null object\n",
      "created_at                        177458 non-null object\n",
      "dtypes: float64(7), int64(4), object(15)\n",
      "memory usage: 35.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just patch the routine together below to automate.  Will take awhile to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 segments built\n",
      "800 segments built\n",
      "1200 segments built\n",
      "1600 segments built\n",
      "2000 segments built\n",
      "2400 segments built\n",
      "appending 38 final batches\n",
      "400 segments built\n",
      "800 segments built\n",
      "1200 segments built\n",
      "1600 segments built\n",
      "2000 segments built\n",
      "2400 segments built\n",
      "appending 38 final batches\n",
      "400 segments built\n",
      "800 segments built\n",
      "1200 segments built\n",
      "1600 segments built\n",
      "2000 segments built\n",
      "2400 segments built\n",
      "appending 27 final batches\n",
      "400 segments built\n",
      "800 segments built\n",
      "appending 4 final batches\n",
      "400 segments built\n",
      "800 segments built\n",
      "1200 segments built\n",
      "1600 segments built\n",
      "2000 segments built\n",
      "2400 segments built\n",
      "appending 27 final batches\n",
      "400 segments built\n",
      "800 segments built\n",
      "1200 segments built\n",
      "1600 segments built\n",
      "2000 segments built\n",
      "2400 segments built\n",
      "appending 2 final batches\n",
      "400 segments built\n",
      "800 segments built\n",
      "1200 segments built\n",
      "1600 segments built\n",
      "2000 segments built\n",
      "2400 segments built\n",
      "appending 25 final batches\n"
     ]
    }
   ],
   "source": [
    "for part in range(6,13):  # already did parts 1-5 of 12\n",
    "    with open(f'capstone_1/userFeeds/userFeedDicts_part_{part}.pkl', 'rb') as f:\n",
    "        feed = pickle.load(f)\n",
    "    feed = {user:feed[user] for user in feed if feed[user]['datalist']}  # empty datalists will eval to False\n",
    "    feed = [data['response']['checkins']['items'] for val in feed.values() for data in val['datalist']]\n",
    "    checkins = (pd.io.json.json_normalize(checkin) for checkin in feed)\n",
    "    built = 0 # counter to monitor progress\n",
    "    batch_concat = []\n",
    "    batch_size = 40\n",
    "    while True:\n",
    "        # concat vertically until generator runs out\n",
    "        batch = []\n",
    "        try:\n",
    "            for _ in range(batch_size):\n",
    "                batch.append(next(checkins))\n",
    "            batch = pd.concat(batch, axis=0, ignore_index=True)\n",
    "            # save some size by trimming 2/3 of the frame\n",
    "            batch_concat.append(batch[keepcols])\n",
    "            built += 1\n",
    "            if built % 10 == 0:\n",
    "                print(f'{built * batch_size} segments built')\n",
    "        except StopIteration:\n",
    "            print(f'appending {len(batch)} final batches')\n",
    "            batch = pd.concat(batch, axis=0, ignore_index=True)\n",
    "            batch_concat.append(batch[keepcols])\n",
    "            break\n",
    "    df = pd.concat(batch_concat, axis=0, ignore_index=True)\n",
    "    df.to_csv(f'capstone_1/checkins/df_{part}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
