{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from surprise import SVD, Reader, Dataset, accuracy\n",
    "from surprise.model_selection import cross_validate, train_test_split, KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('bigframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove all but the most recent one User/Beer combo for multiple such checkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['user_id', 'beer_id'], inplace=True)  # keep_first (default) means keep most recent checkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1296064, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape  # remaining from 1.42M prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0.25, 5.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put this into surprise's format (user, beer, rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The columns must correspond to user_id, beer_id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df[['user_id', 'beer_id', 'rating_user']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a cross-validation iterator\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "algo = SVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47365809752496973"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample random trainset and testset\n",
    "# test set is made of 25% of the ratings.\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=171496, iid=3034980, r_ui=4.25, est=4.4778698277391804, details={'was_impossible': False}),\n",
       " Prediction(uid=1803223, iid=1828774, r_ui=3.25, est=3.5844314206255463, details={'was_impossible': False}),\n",
       " Prediction(uid=267320, iid=399609, r_ui=4.0, est=3.981760322915016, details={'was_impossible': False}),\n",
       " Prediction(uid=2924460, iid=1187911, r_ui=4.0, est=3.6026735719768013, details={'was_impossible': False}),\n",
       " Prediction(uid=1749282, iid=2686615, r_ui=3.5, est=3.6181331817534472, details={'was_impossible': False}),\n",
       " Prediction(uid=3292172, iid=3970, r_ui=3.25, est=3.9172385217788266, details={'was_impossible': False}),\n",
       " Prediction(uid=4396115, iid=4057, r_ui=4.0, est=3.2826608617101911, details={'was_impossible': False}),\n",
       " Prediction(uid=959498, iid=1473393, r_ui=3.5, est=3.6003136089757715, details={'was_impossible': False}),\n",
       " Prediction(uid=267320, iid=9681, r_ui=4.0, est=4.3961044757993522, details={'was_impossible': False}),\n",
       " Prediction(uid=1279351, iid=647032, r_ui=3.75, est=3.5760318107450173, details={'was_impossible': False}),\n",
       " Prediction(uid=1051191, iid=2679592, r_ui=4.5, est=4.2000853709982335, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does that compare to just guessing the global mean rating for every beer?  \n",
    "First we have to remove the beers that don't have global ratings.  We could  \n",
    "theoretically use the mean of all user ratings in place of the missing global  \n",
    "ratings, but for beers with few checkins, that would cheat  \n",
    "by skewing toward the rating of the user being predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_rated = df[['rating_user', 'rating_global']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1296064, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_rated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_user      5.00000\n",
       "rating_global    4.90672\n",
       "dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_rated.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_user      0.25\n",
       "rating_global    0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_rated.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops, went to the trouble of setting NaN global ratings to 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_rated = global_rated[global_rated.rating_global > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1089604, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_rated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_user      0.25000\n",
       "rating_global    1.00423\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_rated.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51243794703341272"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the rmse using global rating as prediction\n",
    "gr = global_rated\n",
    "diffs = gr.rating_global.values - gr.rating_user.values\n",
    "sum_errs_sq = np.dot(diffs, diffs)\n",
    "rmse = np.sqrt(sum_errs_sq / len(diffs))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So at least the Surprise rmse was lower than that of (the `global_rated` subset of) the whole population.\n",
    "  \n",
    "Quick check of what pct of ratings had globals: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.07 pct of checkins had global ratings.\n"
     ]
    }
   ],
   "source": [
    "print(f'{round(len(global_rated) * 100 / len(df), 3)} pct of checkins had global ratings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naively predict global_mean_rating</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Surprise SVD with default params</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               method   rmse\n",
       "0  naively predict global_mean_rating  0.512\n",
       "1    Surprise SVD with default params  0.474"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# might as well keep track of evaluation results\n",
    "methods = ['naively predict global_mean_rating']\n",
    "rmse = [0.512]\n",
    "results = pd.DataFrame({'method': methods,\n",
    "                        'rmse': rmse})\n",
    "\n",
    "def add_results_row(meth_name, rmse_result):\n",
    "    methods.append(meth_name)\n",
    "    rmse.append(rmse_result)\n",
    "    results = pd.DataFrame({'method': methods,\n",
    "                            'rmse': rmse})\n",
    "    return results\n",
    "\n",
    "# make sure function works\n",
    "results = add_results_row('Surprise SVD with default params', 0.474)\n",
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# append result rows here and check tail to make sure all good\n",
    "results = add_results_row(___)\n",
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>city</th>\n",
       "      <th>booked_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-london</td>\n",
       "      <td>london</td>\n",
       "      <td>0.393636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-berlin</td>\n",
       "      <td>berlin</td>\n",
       "      <td>0.473436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-paris</td>\n",
       "      <td>paris</td>\n",
       "      <td>0.854547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-london</td>\n",
       "      <td>london</td>\n",
       "      <td>0.340004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4-london</td>\n",
       "      <td>london</td>\n",
       "      <td>0.869650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id    city  booked_perc\n",
       "0  0-london  london     0.393636\n",
       "1  1-berlin  berlin     0.473436\n",
       "2   2-paris   paris     0.854547\n",
       "3  3-london  london     0.340004\n",
       "4  4-london  london     0.869650"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "size=10000\n",
    "cities=['paris','barca','london','berlin']\n",
    "deef = pd.DataFrame({'city': np.random.choice(cities, size=size), 'booked_perc':np.random.rand(size)})\n",
    "deef['id'] = deef.index.map(str) + '-' + deef.city\n",
    "deef = deef[['id','city','booked_perc']]\n",
    "deef.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastest way to sum a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 6.70 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000 loops, best of 3: 198 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "deef.booked_perc.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastest way to sum a column and filter it first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 2.6 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.dot(deef.booked_perc.values, np.logical_and((deef.booked_perc < 0.5), deef.city=='berlin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or with one filter only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 2 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "deef[deef.booked_perc < 0.5].booked_perc.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or with 2 filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 3.39 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "deef[(deef.booked_perc < 0.5) & (deef.city == 'berlin')].booked_perc.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a column of differences from same column, one row to next, for rows 1 to N-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delters = deef.booked_perc.values - deef.booked_perc.values[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 6.01 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 52 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "delters = deef.booked_perc.values - np.append(np.array([0]), deef.booked_perc.values[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 1.34 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "delters = deef.booked_perc.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
