{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many of the checkins have descriptions for the beer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_id</th>\n",
       "      <th>beer_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2095023</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beer_id                                   beer_description\n",
       "0  2095023  To create a recipe so tropical and fruity with..."
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descrips = pd.read_csv('descriptions.csv', nrows=1)\n",
    "descrips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114347 114347\n"
     ]
    }
   ],
   "source": [
    "descrips = pd.read_csv('descriptions.csv')\n",
    "print(len(descrips), descrips.beer_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how many of all the checkins have descriptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkins = pd.read_csv('comboframe.csv', usecols=['beer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1531277"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.merge(checkins, descrips, how='inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkins = pd.read_csv('comboframe.csv', usecols=['beer_id', 'rating_user',\n",
    "                                                  'rating_global', 'user_id',\n",
    "                                                  'abv', 'brewery_name',\n",
    "                                                  'beer_style', 'beer_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2061965, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkins.drop_duplicates(subset=['beer_id', 'user_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1894852, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1394388, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins = checkins.merge(descrips, how='inner')\n",
    "checkins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2095023</td>\n",
       "      <td>3340203</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2095023</td>\n",
       "      <td>2166716</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2095023</td>\n",
       "      <td>2607740</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2095023</td>\n",
       "      <td>1040951</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2095023</td>\n",
       "      <td>1338056</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beer_id  user_id  rating_user   brewery_name                beer_name  \\\n",
       "0  2095023  3340203         3.75  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "1  2095023  2166716         3.50  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "2  2095023  2607740         3.50  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "3  2095023  1040951         3.50  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "4  2095023  1338056         3.25  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "\n",
       "       beer_style  rating_global  abv  \\\n",
       "0  IPA - American        3.73789  7.5   \n",
       "1  IPA - American        3.73789  7.5   \n",
       "2  IPA - American        3.73789  7.5   \n",
       "3  IPA - American        3.73789  7.5   \n",
       "4  IPA - American        3.73789  7.5   \n",
       "\n",
       "                                    beer_description  \n",
       "0  To create a recipe so tropical and fruity with...  \n",
       "1  To create a recipe so tropical and fruity with...  \n",
       "2  To create a recipe so tropical and fruity with...  \n",
       "3  To create a recipe so tropical and fruity with...  \n",
       "4  To create a recipe so tropical and fruity with...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1394388 entries, 0 to 1394387\n",
      "Data columns (total 9 columns):\n",
      "beer_id             1394388 non-null int64\n",
      "user_id             1394388 non-null int64\n",
      "rating_user         1394388 non-null float64\n",
      "brewery_name        1394388 non-null object\n",
      "beer_name           1394388 non-null object\n",
      "beer_style          1394388 non-null object\n",
      "rating_global       1369092 non-null float64\n",
      "abv                 1394388 non-null float64\n",
      "beer_description    1394388 non-null object\n",
      "dtypes: float64(3), int64(2), object(4)\n",
      "memory usage: 106.4+ MB\n"
     ]
    }
   ],
   "source": [
    "checkins.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cut the non-globally rated, which are only 2% of the data\n",
    "checkins.dropna(subset=['rating_global'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1369092, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2488"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(checkins.rating_global == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1366604, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of those, too\n",
    "checkins = checkins[checkins.rating_global > 0]\n",
    "checkins.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to find which particular words tend to align with each rater's tastes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english', min_df=20, max_df=0.57, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had slightly better results with a wider min-max_df spread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english', min_df=10, max_df=0.71, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, without regards to specific users, how well do the words predict the global rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "by_beer = checkins.groupby('beer_id')\n",
    "\n",
    "descrips['abv'] = descrips.beer_id.map(dict(by_beer['abv'].mean()))\n",
    "descrips['rating_global'] = descrips.beer_id.map(dict(by_beer['rating_global'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkins.set_index('beer_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1377"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droppers = descrips.rating_global.isna()\n",
    "sum(droppers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112970, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descrips = descrips[~droppers]\n",
    "descrips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2095023</th>\n",
       "      <td>3340203</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095023</th>\n",
       "      <td>2166716</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095023</th>\n",
       "      <td>2607740</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095023</th>\n",
       "      <td>1040951</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095023</th>\n",
       "      <td>1338056</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  rating_user   brewery_name                beer_name  \\\n",
       "beer_id                                                                 \n",
       "2095023  3340203         3.75  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "2095023  2166716         3.50  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "2095023  2607740         3.50  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "2095023  1040951         3.50  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "2095023  1338056         3.25  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "\n",
       "             beer_style  rating_global  abv  \\\n",
       "beer_id                                       \n",
       "2095023  IPA - American        3.73789  7.5   \n",
       "2095023  IPA - American        3.73789  7.5   \n",
       "2095023  IPA - American        3.73789  7.5   \n",
       "2095023  IPA - American        3.73789  7.5   \n",
       "2095023  IPA - American        3.73789  7.5   \n",
       "\n",
       "                                          beer_description  \n",
       "beer_id                                                     \n",
       "2095023  To create a recipe so tropical and fruity with...  \n",
       "2095023  To create a recipe so tropical and fruity with...  \n",
       "2095023  To create a recipe so tropical and fruity with...  \n",
       "2095023  To create a recipe so tropical and fruity with...  \n",
       "2095023  To create a recipe so tropical and fruity with...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_id</th>\n",
       "      <th>beer_description</th>\n",
       "      <th>abv</th>\n",
       "      <th>rating_global</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2095023</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.73789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2734572</td>\n",
       "      <td>NEW TRADITIONS CALL FOR NEW HOLIDAYS AND NEW H...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.87873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1044097</td>\n",
       "      <td>Stone Ruination IPA was the first full-time br...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.01290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1070</td>\n",
       "      <td>Made with Highly roasted malted barley, and pl...</td>\n",
       "      <td>9.9</td>\n",
       "      <td>3.91420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>490277</td>\n",
       "      <td>Note: Swami's IPA is brewed and distributed fr...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.84851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beer_id                                   beer_description  abv  \\\n",
       "0  2095023  To create a recipe so tropical and fruity with...  7.5   \n",
       "1  2734572  NEW TRADITIONS CALL FOR NEW HOLIDAYS AND NEW H...  9.0   \n",
       "2  1044097  Stone Ruination IPA was the first full-time br...  8.5   \n",
       "3     1070  Made with Highly roasted malted barley, and pl...  9.9   \n",
       "4   490277  Note: Swami's IPA is brewed and distributed fr...  6.8   \n",
       "\n",
       "   rating_global  \n",
       "0        3.73789  \n",
       "1        3.87873  \n",
       "2        4.01290  \n",
       "3        3.91420  \n",
       "4        3.84851  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descrips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "descrips['brewery_name'] = descrips.beer_id.map(dict(checkins.groupby('beer_id')['brewery_name'].max(key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "descrips['beer_name'] = descrips.beer_id.map(dict(checkins.groupby('beer_id')['beer_name'].max(key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descrips['beer_style'] = descrips.beer_id.map(dict(checkins.groupby('beer_id')['beer_style'].max(key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_id</th>\n",
       "      <th>beer_description</th>\n",
       "      <th>abv</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2095023</td>\n",
       "      <td>Stone Brewing Stone Scorpion Bowl IPA To creat...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2734572</td>\n",
       "      <td>Ritual Brewing Company Oil Rig NEW TRADITIONS ...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.87873</td>\n",
       "      <td>Ritual Brewing Company</td>\n",
       "      <td>Oil Rig</td>\n",
       "      <td>IPA - Imperial / Double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1044097</td>\n",
       "      <td>Stone Brewing Stone Ruination Double IPA 2.0 S...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.01290</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Ruination Double IPA 2.0</td>\n",
       "      <td>IPA - Imperial / Double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1070</td>\n",
       "      <td>Lagunitas Brewing Company Imperial Stout Made ...</td>\n",
       "      <td>9.9</td>\n",
       "      <td>3.91420</td>\n",
       "      <td>Lagunitas Brewing Company</td>\n",
       "      <td>Imperial Stout</td>\n",
       "      <td>Stout - Russian Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>490277</td>\n",
       "      <td>Pizza Port Brewing Company Swami's IPA Note: S...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.84851</td>\n",
       "      <td>Pizza Port Brewing Company</td>\n",
       "      <td>Swami's IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beer_id                                   beer_description  abv  \\\n",
       "0  2095023  Stone Brewing Stone Scorpion Bowl IPA To creat...  7.5   \n",
       "1  2734572  Ritual Brewing Company Oil Rig NEW TRADITIONS ...  9.0   \n",
       "2  1044097  Stone Brewing Stone Ruination Double IPA 2.0 S...  8.5   \n",
       "3     1070  Lagunitas Brewing Company Imperial Stout Made ...  9.9   \n",
       "4   490277  Pizza Port Brewing Company Swami's IPA Note: S...  6.8   \n",
       "\n",
       "   rating_global                brewery_name                       beer_name  \\\n",
       "0        3.73789               Stone Brewing         Stone Scorpion Bowl IPA   \n",
       "1        3.87873      Ritual Brewing Company                         Oil Rig   \n",
       "2        4.01290               Stone Brewing  Stone Ruination Double IPA 2.0   \n",
       "3        3.91420   Lagunitas Brewing Company                  Imperial Stout   \n",
       "4        3.84851  Pizza Port Brewing Company                     Swami's IPA   \n",
       "\n",
       "                 beer_style  \n",
       "0            IPA - American  \n",
       "1   IPA - Imperial / Double  \n",
       "2   IPA - Imperial / Double  \n",
       "3  Stout - Russian Imperial  \n",
       "4            IPA - American  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descrips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "descrips['beer_description'] = descrips.brewery_name + ' ' + descrips.beer_name + ' ' + descrips.beer_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_id</th>\n",
       "      <th>beer_description</th>\n",
       "      <th>abv</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2095023</td>\n",
       "      <td>Stone Brewing Stone Scorpion Bowl IPA To creat...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2734572</td>\n",
       "      <td>Ritual Brewing Company Oil Rig NEW TRADITIONS ...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.87873</td>\n",
       "      <td>Ritual Brewing Company</td>\n",
       "      <td>Oil Rig</td>\n",
       "      <td>IPA - Imperial / Double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1044097</td>\n",
       "      <td>Stone Brewing Stone Ruination Double IPA 2.0 S...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.01290</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Ruination Double IPA 2.0</td>\n",
       "      <td>IPA - Imperial / Double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1070</td>\n",
       "      <td>Lagunitas Brewing Company Imperial Stout Made ...</td>\n",
       "      <td>9.9</td>\n",
       "      <td>3.91420</td>\n",
       "      <td>Lagunitas Brewing Company</td>\n",
       "      <td>Imperial Stout</td>\n",
       "      <td>Stout - Russian Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>490277</td>\n",
       "      <td>Pizza Port Brewing Company Swami's IPA Note: S...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.84851</td>\n",
       "      <td>Pizza Port Brewing Company</td>\n",
       "      <td>Swami's IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beer_id                                   beer_description  abv  \\\n",
       "0  2095023  Stone Brewing Stone Scorpion Bowl IPA To creat...  7.5   \n",
       "1  2734572  Ritual Brewing Company Oil Rig NEW TRADITIONS ...  9.0   \n",
       "2  1044097  Stone Brewing Stone Ruination Double IPA 2.0 S...  8.5   \n",
       "3     1070  Lagunitas Brewing Company Imperial Stout Made ...  9.9   \n",
       "4   490277  Pizza Port Brewing Company Swami's IPA Note: S...  6.8   \n",
       "\n",
       "   rating_global                brewery_name                       beer_name  \\\n",
       "0        3.73789               Stone Brewing         Stone Scorpion Bowl IPA   \n",
       "1        3.87873      Ritual Brewing Company                         Oil Rig   \n",
       "2        4.01290               Stone Brewing  Stone Ruination Double IPA 2.0   \n",
       "3        3.91420   Lagunitas Brewing Company                  Imperial Stout   \n",
       "4        3.84851  Pizza Port Brewing Company                     Swami's IPA   \n",
       "\n",
       "                 beer_style  \n",
       "0            IPA - American  \n",
       "1   IPA - Imperial / Double  \n",
       "2   IPA - Imperial / Double  \n",
       "3  Stout - Russian Imperial  \n",
       "4            IPA - American  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descrips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112970, 14944)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs = cv.fit_transform(descrips.beer_description)\n",
    "vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the vecs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row1 = vecs.toarray()[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  486,  1376,  1907,  2009,  2016,  2847,  3478,  4123,  5144,\n",
       "        5402,  5660,  5673,  5969,  6693,  7145,  7172,  7741,  7852,\n",
       "        8006,  8239,  8827,  8861,  9048,  9213,  9647, 10558, 10837,\n",
       "       11649, 11861, 12691, 12942, 13195, 13333, 13507, 13723, 14944, 14945])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(row1)[0]  # this is after adding brewer and beer names to descrips, plus abv/5.0 and style category features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['addition', 'bavaria', 'bowl', 'brewers', 'brewing', 'citrus', 'create', 'dish', 'feat', 'floral', 'fruit', 'fruity', 'gods', 'hops', 'ipa', 'island', 'leave', 'light', 'loral', 'mandarina', 'mosaic', 'mouthwatering', 'need', 'notes', 'palate', 'punch', 'recipe', 'scorpion', 'share', 'stone', 'sure', 'team', 'thing', 'took', 'tropical']\n"
     ]
    }
   ],
   "source": [
    "print([cv.get_feature_names()[word] for word in np.nonzero(row1)[0][:-2]]) # the last two are abv/5 and style category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stone Brewing Stone Scorpion Bowl IPA To create a recipe so tropical and fruity without the addition of fruit was no feat our team of brewers would leave up to the gods. They took floral and citrus notes from Mosaic, Loral and Mandarina Bavaria hops to dish up a mouthwatering fruit punch to the palate. Get deserted on your own island or share with others. One thing is for sure: there is no need to light this one. It is already on fire.'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descrips.loc[descrips.index[0], 'beer_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "vecs = hstack([vecs, descrips.abv.values[:, np.newaxis] / 5.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(previously-used slower and less efficient technique, converting whole sparse matrix to np.array, below)  \n",
    "and also dividing abv feature by 10, before finding that dividing by 5 worked better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  vecs = np.concatenate((vecs.toarray(), np.expand_dims((descrips.abv.values / 10.0), -1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.coo.coo_matrix"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vecs = csr_matrix(vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-hot the beer style and hstack to vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=True)\n",
    "\n",
    "styles = ohe.fit_transform([descrips['beer_style']])\n",
    "\n",
    "vecs = hstack([vecs, styles.transpose()])\n",
    "\n",
    "vecs = csr_matrix(vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(skip down to training)\n",
    "\n",
    "====================================================================================================  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = SGDRegressor(penalty='elasticnet', early_stopping=True, validation_fraction=0.1, \n",
    "                     random_state=0, max_iter=500, tol=1e-5, l1_ratio=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(vecs, descrips.rating_global, test_size=0.05, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107321, 14946)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=500,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='elasticnet', power_t=0.25,\n",
       "       random_state=0, shuffle=True, tol=1e-05, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.8934725332 3.09504643107\n"
     ]
    }
   ],
   "source": [
    "print(max(preds), min(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19437515935148203"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.clip(preds, 0.25, 5) # possible ratings are 0.25 to 5\n",
    "diffs = preds - testY\n",
    "sumsq = np.dot(diffs, diffs)\n",
    "rmse = np.sqrt(sumsq / len(diffs))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does a simple global mean of all training beers perform as a guess?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28527865119061402"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the mean of the training set\n",
    "errors = testY - trainY.mean()\n",
    "sumsqerr = np.dot(errors, errors)\n",
    "rmse = np.sqrt(sumsqerr / len(errors))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# checking what the max doc freq is (max_df was .71 for the CountVectorizer parameter)\n",
    "docfreqs = vecs.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61982827299282994"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(docfreqs[:-2]) / vecs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = np.argsort(docfreqs[:-2])\n",
    "\n",
    "topidx = counts[:-11:-1]\n",
    "\n",
    "topwords = [cv.get_feature_names()[i] for i in counts[:-11:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('brewing', 0.61982827299282994), ('company', 0.34727803841727894), ('ipa', 0.2991148092413915), ('beer', 0.29614942020005314), ('hops', 0.29338762503319465), ('ale', 0.23142427193060106), ('brewed', 0.20581570328405771), ('hop', 0.16780561210940959), ('dry', 0.16090112419226343), ('brewery', 0.15913959458263255)]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(topwords, [docfreqs[i] / vecs.shape[0] for i in topidx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112970, 14937)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lower the max_df to 0.17 to keep 'hop' and 'dry' but not 'brewed' and 'ale'.\n",
    "cv = CountVectorizer(stop_words='english', min_df=10, max_df=0.17, binary=True)\n",
    "vecs = cv.fit_transform(descrips.beer_description)\n",
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the abvs and style categories\n",
    "vecs = hstack([vecs, descrips.abv.values[:, np.newaxis] / 5.0])\n",
    "vecs = hstack([vecs, styles.transpose()])  # these are the OneHotEncoded styles\n",
    "vecs = csr_matrix(vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now skip to the bottom and train the model on the sample1K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28527538451367385"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vs. peeking by using the mean of all global ratings in the train and test sets combined\n",
    "errors = testY - descrips.rating_global.mean()\n",
    "sumsqerr = np.dot(errors, errors)\n",
    "rmse = np.sqrt(sumsqerr / len(errors))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3.4825868640193778, 3.56213), (3.9518020145291661, 4.21571), (3.8870596211520216, 4.077039999999999), (3.7722770464012245, 3.47297), (3.8549491909438274, 4.3338199999999985), (3.9474416850096095, 4.235150000000001), (4.0204725448669141, 3.8882199999999996), (4.0774886871238785, 4.0481300000000005), (3.9148055414477065, 4.00488), (3.7643488802080189, 3.96849), (3.6751454780801565, 3.536460000000002), (4.5156955416427174, 4.46966), (3.945871716567261, 4.101560000000003), (4.1505545119720519, 3.8046899999999995), (3.808455490322185, 3.67222), (3.6799362349346438, 3.27376), (3.5870880684370912, 3.5608800000000005), (3.8308689661251378, 3.786669999999994), (3.6431751340834899, 3.8661300000000014), (3.678309617954771, 3.50909), (4.1305744345066095, 3.95489), (3.7683018424151791, 3.64267)]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(preds[:22], testY[:22])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118aba8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make everything share same bins (StackO. 23617129)\n",
    "bins = np.histogram(np.hstack((preds, testY.values)), bins=30)[1]\n",
    "plt.hist(preds, bins, label='predicted means')\n",
    "plt.hist(testY, bins, histtype='step', lw=2, label='actual means')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1DFDQJI6ZghIUsf+F8kLAnoApziUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118aae550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model.coef_, bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7425"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "influencers = sorted(enumerate(model.coef_), key=lambda x: abs(x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4301, 0.29095082627849705),\n",
       " (2597, 0.24961489009358373),\n",
       " (7184, 0.23332196409831532),\n",
       " (1101, -0.22040684215971354),\n",
       " (5083, -0.22012820165455399),\n",
       " (4257, 0.21690056616767114),\n",
       " (3653, -0.21388289465033022),\n",
       " (5153, 0.2082593484907424),\n",
       " (1635, -0.2060263270513582),\n",
       " (3844, 0.20600328767429829),\n",
       " (2, 0.20533489016441253),\n",
       " (2932, -0.18002955590721237),\n",
       " (1461, -0.17619005213785369),\n",
       " (6941, -0.16994482286906312),\n",
       " (803, -0.16366888862820955),\n",
       " (7413, -0.15018919898213579),\n",
       " (6745, 0.14700742201371553),\n",
       " (6474, 0.14008345744322809),\n",
       " (6886, 0.13869011518502336),\n",
       " (7214, 0.13816254524827523),\n",
       " (4272, -0.13619947186086548),\n",
       " (1810, 0.13570757667929384)]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influencers[:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAElCAYAAADtFjXiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f4f5c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topX = 20\n",
    "plt.bar(np.arange(topX), [(i[1]) for i in influencers[:topX]])\n",
    "plt.xticks(np.arange(topX), [cv.get_feature_names()[i[0]] for i in influencers[:topX]], rotation='vertical');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "beer_description\n",
       "False    3.802049\n",
       "True     4.395147\n",
       "Name: rating_global, dtype: float64"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descrips.groupby(descrips.beer_description.str.lower().str.contains('melomel'))['rating_global'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "beer_description\n",
       "False    3.802783\n",
       "True     3.299480\n",
       "Name: rating_global, dtype: float64"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descrips.groupby(descrips.beer_description.str.lower().str.contains('calories'))['rating_global'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for each checkin, how much did the user rate the beer better or worse than rest of world?\n",
    "checkins['beer_bias'] = checkins.rating_user - checkins.rating_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use that new column to also make a column that shows the user's overall \"generosity\" or lack thereof\n",
    "userbiasdict = dict(checkins.groupby('user_id')['beer_bias'].mean())\n",
    "checkins['user_bias'] = checkins.user_id.map(userbiasdict)\n",
    "# and then see how much each rating deviates from that user's baseline bias/generosity\n",
    "checkins['user_pref'] = checkins.beer_bias - checkins.user_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "      <th>beer_bias</th>\n",
       "      <th>user_bias</th>\n",
       "      <th>user_pref</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2095023</th>\n",
       "      <td>3340203</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "      <td>0.01211</td>\n",
       "      <td>0.167938</td>\n",
       "      <td>-0.155828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095023</th>\n",
       "      <td>2166716</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "      <td>-0.23789</td>\n",
       "      <td>-0.663801</td>\n",
       "      <td>0.425911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095023</th>\n",
       "      <td>2607740</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "      <td>-0.23789</td>\n",
       "      <td>-0.207602</td>\n",
       "      <td>-0.030288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095023</th>\n",
       "      <td>1040951</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "      <td>-0.23789</td>\n",
       "      <td>-0.078888</td>\n",
       "      <td>-0.159002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095023</th>\n",
       "      <td>1338056</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "      <td>-0.48789</td>\n",
       "      <td>-0.027114</td>\n",
       "      <td>-0.460776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  rating_user   brewery_name                beer_name  \\\n",
       "beer_id                                                                 \n",
       "2095023  3340203         3.75  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "2095023  2166716         3.50  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "2095023  2607740         3.50  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "2095023  1040951         3.50  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "2095023  1338056         3.25  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "\n",
       "             beer_style  rating_global  abv  \\\n",
       "beer_id                                       \n",
       "2095023  IPA - American        3.73789  7.5   \n",
       "2095023  IPA - American        3.73789  7.5   \n",
       "2095023  IPA - American        3.73789  7.5   \n",
       "2095023  IPA - American        3.73789  7.5   \n",
       "2095023  IPA - American        3.73789  7.5   \n",
       "\n",
       "                                          beer_description  beer_bias  \\\n",
       "beer_id                                                                 \n",
       "2095023  To create a recipe so tropical and fruity with...    0.01211   \n",
       "2095023  To create a recipe so tropical and fruity with...   -0.23789   \n",
       "2095023  To create a recipe so tropical and fruity with...   -0.23789   \n",
       "2095023  To create a recipe so tropical and fruity with...   -0.23789   \n",
       "2095023  To create a recipe so tropical and fruity with...   -0.48789   \n",
       "\n",
       "         user_bias  user_pref  \n",
       "beer_id                        \n",
       "2095023   0.167938  -0.155828  \n",
       "2095023  -0.663801   0.425911  \n",
       "2095023  -0.207602  -0.030288  \n",
       "2095023  -0.078888  -0.159002  \n",
       "2095023  -0.027114  -0.460776  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try training a regressor on each user with over a certain threshold of ratings in the descriptions Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigs = checkins.groupby('user_id').size() > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6277"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "868621"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = checkins[checkins.user_id.map(bigs)]\n",
    "len(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6277"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=112970, step=1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descrips.reset_index(inplace=True)\n",
    "descrips.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now the descrips/vecs index can be looked up for each beer_id\n",
    "beer_id_to_vecs_index = dict(zip(descrips.beer_id, descrips.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_gen = (user for user in freqs.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SGDRegressor(penalty='elasticnet', early_stopping=True, validation_fraction=0.1, \n",
    "                     random_state=0, max_iter=500, tol=1e-4, l1_ratio=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "      <th>beer_bias</th>\n",
       "      <th>user_bias</th>\n",
       "      <th>user_pref</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2095023</th>\n",
       "      <td>3340203</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>To create a recipe so tropical and fruity with...</td>\n",
       "      <td>0.01211</td>\n",
       "      <td>0.167938</td>\n",
       "      <td>-0.155828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  rating_user   brewery_name                beer_name  \\\n",
       "beer_id                                                                 \n",
       "2095023  3340203         3.75  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "\n",
       "             beer_style  rating_global  abv  \\\n",
       "beer_id                                       \n",
       "2095023  IPA - American        3.73789  7.5   \n",
       "\n",
       "                                          beer_description  beer_bias  \\\n",
       "beer_id                                                                 \n",
       "2095023  To create a recipe so tropical and fruity with...    0.01211   \n",
       "\n",
       "         user_bias  user_pref  \n",
       "beer_id                        \n",
       "2095023   0.167938  -0.155828  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freqs.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [00:04<12:27,  1.33it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  1%|          | 10/1000 [00:06<10:02,  1.64it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  2%|▏         | 16/1000 [00:10<09:24,  1.74it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  2%|▏         | 19/1000 [00:12<09:45,  1.68it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  2%|▏         | 20/1000 [00:13<11:12,  1.46it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  3%|▎         | 31/1000 [00:20<09:03,  1.78it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  4%|▎         | 37/1000 [00:23<08:53,  1.81it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  4%|▍         | 42/1000 [00:26<08:25,  1.90it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  4%|▍         | 45/1000 [00:28<09:28,  1.68it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  5%|▍         | 46/1000 [00:29<09:55,  1.60it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  5%|▍         | 48/1000 [00:30<11:18,  1.40it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  6%|▌         | 59/1000 [00:37<08:42,  1.80it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  6%|▌         | 62/1000 [00:39<11:15,  1.39it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  7%|▋         | 66/1000 [00:42<10:25,  1.49it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 77/1000 [00:48<07:18,  2.11it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 78/1000 [00:49<08:57,  1.71it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 81/1000 [00:51<08:27,  1.81it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 10%|▉         | 98/1000 [01:00<07:45,  1.94it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 12%|█▏        | 121/1000 [01:15<09:16,  1.58it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 13%|█▎        | 129/1000 [01:19<07:25,  1.96it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 13%|█▎        | 131/1000 [01:20<08:30,  1.70it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 15%|█▍        | 147/1000 [01:29<07:49,  1.82it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 15%|█▍        | 148/1000 [01:30<08:47,  1.61it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 15%|█▍        | 149/1000 [01:31<09:12,  1.54it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 17%|█▋        | 173/1000 [01:43<06:57,  1.98it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 21%|██        | 206/1000 [02:01<06:54,  1.91it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 21%|██        | 208/1000 [02:02<07:29,  1.76it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 27%|██▋       | 272/1000 [02:37<05:52,  2.06it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 27%|██▋       | 274/1000 [02:38<07:05,  1.71it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 28%|██▊       | 275/1000 [02:39<07:41,  1.57it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 28%|██▊       | 277/1000 [02:40<07:27,  1.61it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 31%|███▏      | 314/1000 [03:00<06:18,  1.81it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 32%|███▏      | 322/1000 [03:04<05:30,  2.05it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 35%|███▌      | 351/1000 [03:19<05:09,  2.10it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 36%|███▌      | 362/1000 [03:25<05:17,  2.01it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 36%|███▋      | 363/1000 [03:25<06:06,  1.74it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 39%|███▉      | 393/1000 [03:42<05:34,  1.81it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 40%|███▉      | 397/1000 [03:44<05:00,  2.01it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 40%|███▉      | 399/1000 [03:45<05:44,  1.74it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 42%|████▏     | 423/1000 [03:59<05:45,  1.67it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 43%|████▎     | 432/1000 [04:05<05:26,  1.74it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 44%|████▍     | 440/1000 [04:09<05:28,  1.70it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 47%|████▋     | 471/1000 [04:25<05:22,  1.64it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 49%|████▉     | 489/1000 [04:34<04:11,  2.03it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 49%|████▉     | 494/1000 [04:37<04:28,  1.88it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 50%|████▉     | 496/1000 [04:38<05:00,  1.68it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 51%|█████     | 512/1000 [04:47<04:21,  1.87it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 51%|█████▏    | 513/1000 [04:48<05:01,  1.62it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 52%|█████▏    | 517/1000 [04:51<05:00,  1.61it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 52%|█████▏    | 520/1000 [04:53<05:03,  1.58it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 52%|█████▏    | 524/1000 [04:55<04:13,  1.87it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 53%|█████▎    | 531/1000 [04:59<04:07,  1.90it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 54%|█████▎    | 535/1000 [05:01<04:08,  1.87it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 57%|█████▋    | 574/1000 [05:21<03:41,  1.92it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 58%|█████▊    | 576/1000 [05:23<04:21,  1.62it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 59%|█████▊    | 587/1000 [05:28<03:32,  1.94it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 60%|██████    | 605/1000 [05:38<03:19,  1.98it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 62%|██████▏   | 620/1000 [05:46<03:11,  1.99it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 63%|██████▎   | 632/1000 [05:53<03:24,  1.80it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 64%|██████▍   | 639/1000 [05:56<02:52,  2.09it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 64%|██████▍   | 642/1000 [05:58<03:22,  1.76it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 64%|██████▍   | 643/1000 [05:59<03:47,  1.57it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 64%|██████▍   | 645/1000 [06:00<03:29,  1.70it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 65%|██████▌   | 650/1000 [06:03<03:01,  1.93it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 66%|██████▌   | 660/1000 [06:08<02:51,  1.98it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 67%|██████▋   | 666/1000 [06:11<02:57,  1.88it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 69%|██████▉   | 689/1000 [06:26<03:52,  1.34it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 69%|██████▉   | 693/1000 [06:29<03:36,  1.42it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 71%|███████   | 706/1000 [06:37<03:04,  1.60it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 71%|███████   | 709/1000 [06:39<03:03,  1.59it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 71%|███████   | 710/1000 [06:40<03:21,  1.44it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 72%|███████▏  | 716/1000 [06:43<02:27,  1.93it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 72%|███████▏  | 724/1000 [06:48<02:33,  1.80it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 72%|███████▎  | 725/1000 [06:49<03:33,  1.29it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 73%|███████▎  | 730/1000 [06:52<03:12,  1.40it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 76%|███████▋  | 765/1000 [07:16<02:11,  1.79it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 77%|███████▋  | 769/1000 [07:20<02:56,  1.31it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 78%|███████▊  | 780/1000 [07:27<01:57,  1.87it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 78%|███████▊  | 783/1000 [07:29<01:53,  1.91it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 78%|███████▊  | 785/1000 [07:30<02:01,  1.77it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 80%|███████▉  | 795/1000 [07:36<01:50,  1.86it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 80%|███████▉  | 796/1000 [07:36<02:04,  1.63it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 80%|████████  | 800/1000 [07:39<01:48,  1.85it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 80%|████████  | 804/1000 [07:41<01:40,  1.95it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 81%|████████  | 810/1000 [07:44<01:31,  2.07it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 82%|████████▏ | 816/1000 [07:48<01:45,  1.74it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 84%|████████▍ | 838/1000 [08:02<01:35,  1.70it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 85%|████████▌ | 852/1000 [08:12<01:16,  1.94it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 86%|████████▌ | 860/1000 [08:17<01:07,  2.08it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 87%|████████▋ | 868/1000 [08:21<01:06,  1.98it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 87%|████████▋ | 870/1000 [08:22<01:25,  1.53it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 88%|████████▊ | 884/1000 [08:32<01:11,  1.61it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 90%|█████████ | 902/1000 [08:43<00:49,  1.97it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 94%|█████████▎| 937/1000 [09:03<00:30,  2.06it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 94%|█████████▍| 944/1000 [09:08<00:30,  1.83it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 95%|█████████▍| 946/1000 [09:09<00:30,  1.77it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 95%|█████████▍| 948/1000 [09:10<00:31,  1.63it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 96%|█████████▌| 962/1000 [09:18<00:22,  1.69it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 97%|█████████▋| 967/1000 [09:21<00:18,  1.82it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 97%|█████████▋| 968/1000 [09:22<00:20,  1.55it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 98%|█████████▊| 980/1000 [09:28<00:10,  1.98it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 99%|█████████▉| 988/1000 [09:32<00:05,  2.19it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "100%|██████████| 1000/1000 [09:39<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "rmses = []\n",
    "for _ in tqdm(range(1000)):\n",
    "    u = next(user_gen)\n",
    "    udf = freqs[freqs.user_id == u]    \n",
    "    vi = udf.beer_id.map(beer_id_to_vecs_index)\n",
    "\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(vecs[vi, :],\n",
    "                                                    udf.user_pref.values,\n",
    "                                                    test_size = 0.1, random_state=0)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds = model.predict(xtest)\n",
    "    diffs = preds - ytest\n",
    "    sumsq = np.dot(diffs, diffs)\n",
    "    rmse = np.sqrt(sumsq / len(diffs))\n",
    "    rmses.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40666412277531083"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITH BEER NAME AND BREWERY NAME ADDED TO BAG OF WORDS, AND WITH ABV/5.0, 10-0.71 min-max_df, FIRST 1000 USERS\n",
    "#   AND WITH OHE HOT BEER STYLES\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40866462084021121"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITH BEER NAME AND BREWERY NAME ADDED TO BAG OF WORDS, AND WITH ABV/5.0, 10-0.71 min-max_df, 2nd 1000 USERS\n",
    "#   AND WITH OHE HOT BEER STYLES\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41770131939694782"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITH JUST DESCRIPS, NO ABV, NO BREWERYNAME, NO BEERNAME, FIRST 1000 USERS\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While that's effective, if we're going to train a model for each user, we might as well add the brewery name into the bag of words, and feature the a.b.v. as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41045456724343349"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITH BEER NAME AND BREWERY NAME ADDED TO BAG OF WORDS, AND WITH ABV/10.0, FIRST 1000 USERS\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029312253664937806"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how much of a factor was abv for the last user? \n",
    "model.coef_[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41219801463392686"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITH BEER NAME AND BREWERY NAME ADDED TO BAG OF WORDS, AND WITH ABV/10.0, SECOND 1000 USERS\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40342371577009351"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITH BEER NAME AND BREWERY NAME ADDED TO BAG OF WORDS, AND WITH ABV/10.0, THIRD 1000 USERS\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39471921597581955"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITH BEER NAME AND BREWERY NAME ADDED TO BAG OF WORDS, AND WITH ABV/10.0, FOURTH 1000 USERS\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40582003370423486"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITH BEER NAME AND BREWERY NAME ADDED TO BAG OF WORDS, AND WITH ABV/10.0, FIFTH 1000 USERS\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36608485008657315"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITH BEER NAME AND BREWERY NAME ADDED TO BAG OF WORDS, AND WITH ABV/10.0, SIXTH 1000 USERS\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different min and max doc_freqs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112970, 17250)"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english', min_df=8, max_df=0.67, binary=True)\n",
    "vecs = cv.fit_transform(descrips.beer_description)\n",
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vecs = hstack([vecs, descrips.abv.values[:, np.newaxis] / 5.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vecs = csr_matrix(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112970, 17251)"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SGDRegressor(penalty='elasticnet', early_stopping=True, validation_fraction=0.1, \n",
    "                     random_state=0, max_iter=500, tol=1e-4, l1_ratio=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 19/1000 [00:13<11:25,  1.43it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  2%|▏         | 22/1000 [00:15<10:28,  1.56it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  2%|▏         | 23/1000 [00:16<11:40,  1.39it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  3%|▎         | 29/1000 [00:20<10:35,  1.53it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  3%|▎         | 31/1000 [00:22<10:04,  1.60it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  6%|▌         | 61/1000 [00:40<08:40,  1.80it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  6%|▋         | 65/1000 [00:42<08:56,  1.74it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▊         | 87/1000 [00:54<08:40,  1.76it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▉         | 94/1000 [00:58<08:40,  1.74it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 10%|▉         | 98/1000 [01:01<08:26,  1.78it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 11%|█         | 106/1000 [01:06<08:30,  1.75it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 11%|█         | 107/1000 [01:07<10:17,  1.45it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 11%|█▏        | 113/1000 [01:10<07:35,  1.95it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 12%|█▏        | 119/1000 [01:14<09:03,  1.62it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 13%|█▎        | 126/1000 [01:18<08:13,  1.77it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 14%|█▍        | 144/1000 [01:29<07:28,  1.91it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 16%|█▋        | 165/1000 [01:41<07:25,  1.87it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 17%|█▋        | 167/1000 [01:43<08:09,  1.70it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 17%|█▋        | 170/1000 [01:45<09:20,  1.48it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 18%|█▊        | 184/1000 [01:53<09:08,  1.49it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|█▉        | 195/1000 [01:59<07:07,  1.88it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|█▉        | 196/1000 [02:00<08:38,  1.55it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|█▉        | 197/1000 [02:01<09:35,  1.39it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|██        | 203/1000 [02:05<08:09,  1.63it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 21%|██        | 212/1000 [02:10<06:44,  1.95it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 22%|██▏       | 222/1000 [02:16<07:41,  1.69it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 23%|██▎       | 232/1000 [02:22<07:00,  1.83it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 23%|██▎       | 234/1000 [02:24<08:32,  1.50it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 25%|██▌       | 251/1000 [02:34<07:50,  1.59it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 25%|██▌       | 254/1000 [02:37<08:51,  1.40it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▌       | 258/1000 [02:40<09:34,  1.29it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▌       | 259/1000 [02:41<10:07,  1.22it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 27%|██▋       | 266/1000 [02:45<07:37,  1.60it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 27%|██▋       | 271/1000 [02:48<06:54,  1.76it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 28%|██▊       | 275/1000 [02:51<07:01,  1.72it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 28%|██▊       | 281/1000 [02:54<06:44,  1.78it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 28%|██▊       | 284/1000 [02:56<06:23,  1.87it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 29%|██▉       | 289/1000 [02:59<07:07,  1.66it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 29%|██▉       | 291/1000 [03:01<08:04,  1.46it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 34%|███▎      | 336/1000 [03:28<05:39,  1.96it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 34%|███▍      | 340/1000 [03:30<06:39,  1.65it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 34%|███▍      | 345/1000 [03:34<06:38,  1.64it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 35%|███▍      | 347/1000 [03:35<06:50,  1.59it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 35%|███▌      | 352/1000 [03:38<06:50,  1.58it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 36%|███▌      | 356/1000 [03:41<07:12,  1.49it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 36%|███▋      | 365/1000 [03:46<05:59,  1.77it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 37%|███▋      | 369/1000 [03:49<06:31,  1.61it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 39%|███▉      | 389/1000 [04:00<05:57,  1.71it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 39%|███▉      | 393/1000 [04:03<07:00,  1.44it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 40%|███▉      | 397/1000 [04:06<07:03,  1.42it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 41%|████      | 407/1000 [04:12<05:40,  1.74it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 42%|████▏     | 423/1000 [04:22<05:25,  1.77it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 43%|████▎     | 428/1000 [04:25<05:29,  1.74it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 44%|████▍     | 440/1000 [04:32<04:57,  1.88it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 44%|████▍     | 444/1000 [04:34<04:54,  1.89it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 44%|████▍     | 445/1000 [04:35<05:44,  1.61it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 45%|████▌     | 452/1000 [04:39<05:16,  1.73it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 46%|████▋     | 464/1000 [04:46<05:06,  1.75it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 47%|████▋     | 470/1000 [04:49<04:49,  1.83it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 47%|████▋     | 471/1000 [04:50<05:36,  1.57it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 47%|████▋     | 474/1000 [04:53<06:16,  1.40it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 48%|████▊     | 485/1000 [04:59<05:26,  1.58it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 49%|████▊     | 486/1000 [05:00<06:10,  1.39it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 50%|████▉     | 498/1000 [05:07<04:52,  1.72it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 50%|█████     | 501/1000 [05:10<05:46,  1.44it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 52%|█████▏    | 516/1000 [05:18<04:39,  1.73it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 52%|█████▏    | 520/1000 [05:20<04:27,  1.79it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 54%|█████▎    | 535/1000 [05:29<03:58,  1.95it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 55%|█████▍    | 545/1000 [05:34<04:06,  1.84it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 55%|█████▍    | 547/1000 [05:36<04:41,  1.61it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 56%|█████▌    | 557/1000 [05:42<04:51,  1.52it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 56%|█████▋    | 564/1000 [05:46<04:20,  1.67it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 58%|█████▊    | 580/1000 [05:55<03:37,  1.93it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 59%|█████▊    | 586/1000 [05:59<04:11,  1.64it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 60%|█████▉    | 598/1000 [06:07<05:19,  1.26it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 60%|██████    | 603/1000 [06:11<04:39,  1.42it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 61%|██████    | 607/1000 [06:14<04:27,  1.47it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 61%|██████    | 610/1000 [06:16<04:31,  1.44it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 61%|██████▏   | 613/1000 [06:18<04:47,  1.35it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 61%|██████▏   | 614/1000 [06:20<05:31,  1.17it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 62%|██████▏   | 623/1000 [06:25<04:03,  1.55it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 63%|██████▎   | 627/1000 [06:28<03:48,  1.63it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 64%|██████▍   | 638/1000 [06:35<03:10,  1.90it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 65%|██████▍   | 647/1000 [06:40<03:51,  1.52it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 66%|██████▌   | 660/1000 [06:48<03:26,  1.65it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 66%|██████▋   | 664/1000 [06:51<03:25,  1.64it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 67%|██████▋   | 670/1000 [06:54<02:53,  1.90it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 68%|██████▊   | 680/1000 [07:01<03:29,  1.53it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 68%|██████▊   | 682/1000 [07:02<03:21,  1.58it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 71%|███████▏  | 714/1000 [07:21<02:46,  1.71it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 72%|███████▎  | 725/1000 [07:27<02:24,  1.90it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 74%|███████▍  | 743/1000 [07:38<02:17,  1.87it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 75%|███████▍  | 747/1000 [07:40<02:21,  1.79it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 75%|███████▌  | 754/1000 [07:44<02:14,  1.83it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 77%|███████▋  | 770/1000 [07:54<02:14,  1.71it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 78%|███████▊  | 778/1000 [07:59<02:23,  1.55it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 79%|███████▉  | 791/1000 [08:07<02:10,  1.61it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 79%|███████▉  | 792/1000 [08:08<02:24,  1.44it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 81%|████████  | 806/1000 [08:16<01:46,  1.82it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 81%|████████▏ | 814/1000 [08:21<01:33,  1.98it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 83%|████████▎ | 827/1000 [08:31<02:10,  1.33it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 84%|████████▍ | 839/1000 [08:37<01:33,  1.72it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 84%|████████▍ | 843/1000 [08:40<01:47,  1.46it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 84%|████████▍ | 844/1000 [08:41<01:48,  1.44it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 84%|████████▍ | 845/1000 [08:42<01:52,  1.38it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 85%|████████▌ | 852/1000 [08:46<01:18,  1.88it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 85%|████████▌ | 853/1000 [08:47<01:32,  1.60it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 86%|████████▌ | 859/1000 [08:50<01:18,  1.80it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 86%|████████▌ | 862/1000 [08:52<01:23,  1.65it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 86%|████████▋ | 864/1000 [08:54<01:35,  1.42it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 88%|████████▊ | 877/1000 [09:04<01:18,  1.56it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 89%|████████▉ | 889/1000 [09:12<01:14,  1.49it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 90%|████████▉ | 895/1000 [09:18<01:47,  1.02s/it]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 90%|████████▉ | 896/1000 [09:19<01:48,  1.04s/it]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 90%|█████████ | 900/1000 [09:23<01:23,  1.20it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 91%|█████████ | 908/1000 [09:27<00:53,  1.73it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 93%|█████████▎| 927/1000 [09:38<00:43,  1.68it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 94%|█████████▍| 938/1000 [09:46<00:41,  1.49it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 94%|█████████▍| 943/1000 [09:51<00:52,  1.08it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 95%|█████████▍| 949/1000 [09:55<00:35,  1.43it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 95%|█████████▌| 954/1000 [09:59<00:37,  1.24it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 97%|█████████▋| 973/1000 [10:13<00:18,  1.47it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 97%|█████████▋| 974/1000 [10:14<00:19,  1.31it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 98%|█████████▊| 982/1000 [10:20<00:14,  1.25it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 99%|█████████▊| 986/1000 [10:24<00:11,  1.20it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "100%|██████████| 1000/1000 [10:34<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "rmses = []\n",
    "for _ in tqdm(range(1000)):\n",
    "    u = next(user_gen)\n",
    "    udf = freqs[freqs.user_id == u]    \n",
    "    vi = udf.beer_id.map(beer_id_to_vecs_index)\n",
    "\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(vecs[vi, :],\n",
    "                                                    udf.user_pref.values,\n",
    "                                                    test_size = 0.1, random_state=0)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds = model.predict(xtest)\n",
    "    diffs = preds - ytest\n",
    "    sumsq = np.dot(diffs, diffs)\n",
    "    rmse = np.sqrt(sumsq / len(diffs))\n",
    "    rmses.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40935367156602692"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITH BEER NAME AND BREWERY NAME ADDED TO BAG OF WORDS, AND WITH ABV/10.0, wider min-max_df, FIRST 1000 USERS\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41102899786202451"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITH BEER NAME AND BREWERY NAME ADDED TO BAG OF WORDS, AND WITH ABV/10.0, wider min-max_df, SECOND 1000 USERS\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40099016637930346"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITH BEER NAME AND BREWERY NAME ADDED TO BAG OF WORDS, AND WITH ABV/5.0, wider min-max_df, THIRD 1000 USERS\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39267224585736399"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITH BEER NAME AND BREWERY NAME ADDED TO BAG OF WORDS, AND WITH ABV/2.0, wider min-max_df, FOURTH 1000 USERS\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "abv / 5.0 worked slightly better than abv / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40347976746241548"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITH BEER NAME AND BREWERY NAME ADDED TO BAG OF WORDS, AND WITH ABV/5.0, 10-0.8 min-max_df, FIFTH 1000 USERS\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3640813027042098"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITH BEER NAME AND BREWERY NAME ADDED TO BAG OF WORDS, AND WITH ABV/5.0, 8-0.67 min-max_df, SIXTH 1000 USERS\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# boolean array marking which users rated exactly 4 beers\n",
    "fours = checkins.groupby('user_id').size() == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8989"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(fours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "      <th>beer_bias</th>\n",
       "      <th>user_bias</th>\n",
       "      <th>user_pref</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2595866</th>\n",
       "      <td>836231</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Liberty Station POMMA Said Knock You Out</td>\n",
       "      <td>IPA - Red</td>\n",
       "      <td>3.75349</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Red India Pale Ale w/ Pommegranate made by Pin...</td>\n",
       "      <td>-0.50349</td>\n",
       "      <td>-0.192930</td>\n",
       "      <td>-0.310560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595866</th>\n",
       "      <td>310841</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Liberty Station POMMA Said Knock You Out</td>\n",
       "      <td>IPA - Red</td>\n",
       "      <td>3.75349</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Red India Pale Ale w/ Pommegranate made by Pin...</td>\n",
       "      <td>0.24651</td>\n",
       "      <td>0.375592</td>\n",
       "      <td>-0.129083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595866</th>\n",
       "      <td>2395919</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Liberty Station POMMA Said Knock You Out</td>\n",
       "      <td>IPA - Red</td>\n",
       "      <td>3.75349</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Red India Pale Ale w/ Pommegranate made by Pin...</td>\n",
       "      <td>0.24651</td>\n",
       "      <td>0.257727</td>\n",
       "      <td>-0.011218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301381</th>\n",
       "      <td>13106</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Hop Valley Brewing Company</td>\n",
       "      <td>Citrus Mistress IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73392</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Munich malt, 4 different hops and grapefruit p...</td>\n",
       "      <td>-0.23392</td>\n",
       "      <td>-0.038338</td>\n",
       "      <td>-0.195582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222013</th>\n",
       "      <td>3650609</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Claremont Craft Ales</td>\n",
       "      <td>35 Miles NE</td>\n",
       "      <td>IPA - New England</td>\n",
       "      <td>3.82279</td>\n",
       "      <td>7.0</td>\n",
       "      <td>hazy IPA</td>\n",
       "      <td>0.17721</td>\n",
       "      <td>0.334958</td>\n",
       "      <td>-0.157747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  rating_user                brewery_name  \\\n",
       "beer_id                                                     \n",
       "2595866   836231         3.25               Stone Brewing   \n",
       "2595866   310841         4.00               Stone Brewing   \n",
       "2595866  2395919         4.00               Stone Brewing   \n",
       "301381     13106         3.50  Hop Valley Brewing Company   \n",
       "2222013  3650609         4.00        Claremont Craft Ales   \n",
       "\n",
       "                                              beer_name         beer_style  \\\n",
       "beer_id                                                                      \n",
       "2595866  Stone Liberty Station POMMA Said Knock You Out          IPA - Red   \n",
       "2595866  Stone Liberty Station POMMA Said Knock You Out          IPA - Red   \n",
       "2595866  Stone Liberty Station POMMA Said Knock You Out          IPA - Red   \n",
       "301381                              Citrus Mistress IPA     IPA - American   \n",
       "2222013                                     35 Miles NE  IPA - New England   \n",
       "\n",
       "         rating_global  abv  \\\n",
       "beer_id                       \n",
       "2595866        3.75349  7.5   \n",
       "2595866        3.75349  7.5   \n",
       "2595866        3.75349  7.5   \n",
       "301381         3.73392  6.5   \n",
       "2222013        3.82279  7.0   \n",
       "\n",
       "                                          beer_description  beer_bias  \\\n",
       "beer_id                                                                 \n",
       "2595866  Red India Pale Ale w/ Pommegranate made by Pin...   -0.50349   \n",
       "2595866  Red India Pale Ale w/ Pommegranate made by Pin...    0.24651   \n",
       "2595866  Red India Pale Ale w/ Pommegranate made by Pin...    0.24651   \n",
       "301381   Munich malt, 4 different hops and grapefruit p...   -0.23392   \n",
       "2222013                                           hazy IPA    0.17721   \n",
       "\n",
       "         user_bias  user_pref  \n",
       "beer_id                        \n",
       "2595866  -0.192930  -0.310560  \n",
       "2595866   0.375592  -0.129083  \n",
       "2595866   0.257727  -0.011218  \n",
       "301381   -0.038338  -0.195582  \n",
       "2222013   0.334958  -0.157747  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the boolean array as a map to select the 36K checkins of these 9K users\n",
    "fours = checkins[checkins.user_id.map(fours)]\n",
    "fours.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "four_gen = (user for user in fours.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fours.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "fours['beer_description'] = fours.brewery_name + ' ' + fours.beer_name + ' ' + fours.beer_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "      <th>beer_bias</th>\n",
       "      <th>user_bias</th>\n",
       "      <th>user_pref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2595866</td>\n",
       "      <td>836231</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Liberty Station POMMA Said Knock You Out</td>\n",
       "      <td>IPA - Red</td>\n",
       "      <td>3.75349</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Stone Brewing Stone Liberty Station POMMA Said...</td>\n",
       "      <td>-0.50349</td>\n",
       "      <td>-0.19293</td>\n",
       "      <td>-0.31056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beer_id  user_id  rating_user   brewery_name  \\\n",
       "0  2595866   836231         3.25  Stone Brewing   \n",
       "\n",
       "                                        beer_name beer_style  rating_global  \\\n",
       "0  Stone Liberty Station POMMA Said Knock You Out  IPA - Red        3.75349   \n",
       "\n",
       "   abv                                   beer_description  beer_bias  \\\n",
       "0  7.5  Stone Brewing Stone Liberty Station POMMA Said...   -0.50349   \n",
       "\n",
       "   user_bias  user_pref  \n",
       "0   -0.19293   -0.31056  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fours.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 30/1000 [00:10<05:30,  2.93it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 46%|████▌     | 458/1000 [02:36<03:08,  2.87it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "100%|██████████| 1000/1000 [05:55<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "rmses = []\n",
    "for _ in tqdm(range(1000)):\n",
    "    u = next(four_gen)\n",
    "    udf = fours[fours.user_id == u]    \n",
    "    vi = udf.beer_id.map(beer_id_to_vecs_index)\n",
    "\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(vecs[vi, :],\n",
    "                                                    udf.user_pref.values,\n",
    "                                                    test_size = 0.25, random_state=0)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds = model.predict(xtest)\n",
    "    diffs = preds - ytest\n",
    "    sumsq = np.dot(diffs, diffs)\n",
    "    rmse = np.sqrt(sumsq / len(diffs))\n",
    "    rmses.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2884738178097056"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just fours!  first 1000\n",
    "# (so this is users who have only rated 3 beers and we want to predict the fourth, so results won't be great)\n",
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that's way too low, and highlights the need to calculate the user biases only on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35956"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here's the cell where the biases were calculated\n",
    "# Make a column that shows the user's overall \"generosity\" or lack thereof\n",
    "userbiasdict = dict(checkins.groupby('user_id')['beer_bias'].mean())\n",
    "checkins['user_bias'] = checkins.user_id.map(userbiasdict)\n",
    "# and then see how much each rating deviates from that user's baseline bias/generosity\n",
    "checkins['user_pref'] = checkins.beer_bias - checkins.user_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_models(df, test_frac, wordvecs, beer_2_vec_map, user_generator, batch_size, rando=0):\n",
    "    '''\n",
    "    @df input has columns indicating the user's ratings biases,\n",
    "    but the training will only use the biases calculate on itself.\n",
    "    '''\n",
    "    rmses = []\n",
    "    for _ in tqdm(range(batch_size)):\n",
    "        u = next(user_generator)\n",
    "        udf = df[df.user_id == u]\n",
    "        ratings = len(udf)\n",
    "        # use the last @test_frac fraction of each user's checkins as the test group\n",
    "        split = int(ratings * (1-test_frac))\n",
    "        utrain = udf.iloc[:split, :]\n",
    "        utest = udf.iloc[split:, :]\n",
    "        # make the corresponding split to the vector indices, vi\n",
    "        vi = udf.beer_id.map(beer_2_vec_map)\n",
    "        trainvecs = wordvecs[vi[:split], :]\n",
    "        testvecs = wordvecs[vi[split:], :]\n",
    "        # calculate the user's avg generosity/stinginess towards KNOWN ratings\n",
    "        known_bias = utrain.beer_bias.mean()\n",
    "        train_targets = utrain.beer_bias - known_bias\n",
    "        # especially after only 3 ratings, those training targets will be changing with each rating,\n",
    "        ##  so these results will not be great if the user's ratings vary much\n",
    "        stop_early = len(utrain) > 10\n",
    "        model = SGDRegressor(penalty='elasticnet', early_stopping=stop_early, validation_fraction=0.1, \n",
    "                     random_state=rando, max_iter=500, tol=1e-4, l1_ratio=0.15)\n",
    "        model.fit(trainvecs, train_targets)\n",
    "        preds = model.predict(testvecs)\n",
    "        diffs = preds - utest.user_pref\n",
    "        sumsq = np.dot(diffs, diffs)\n",
    "        rmse = np.sqrt(sumsq / len(diffs))\n",
    "        rmses.append(rmse)\n",
    "    return np.mean(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep this randomly sampled first user's four checkins as an example of how the first 3 checkins can  \n",
    "be vastly misleading for the fourth checkin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "      <th>beer_bias</th>\n",
       "      <th>user_bias</th>\n",
       "      <th>user_pref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2595866</td>\n",
       "      <td>836231</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Liberty Station POMMA Said Knock You Out</td>\n",
       "      <td>IPA - Red</td>\n",
       "      <td>3.75349</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Stone Brewing Stone Liberty Station POMMA Said...</td>\n",
       "      <td>-0.50349</td>\n",
       "      <td>-0.19293</td>\n",
       "      <td>-0.31056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26960</th>\n",
       "      <td>3383299</td>\n",
       "      <td>836231</td>\n",
       "      <td>3.50</td>\n",
       "      <td>The Fermentorium Beverage Co.</td>\n",
       "      <td>Pilot 0X61: South African DIPA</td>\n",
       "      <td>IPA - Imperial / Double</td>\n",
       "      <td>3.87289</td>\n",
       "      <td>9.0</td>\n",
       "      <td>The Fermentorium Beverage Co. Pilot 0X61: Sout...</td>\n",
       "      <td>-0.37289</td>\n",
       "      <td>-0.19293</td>\n",
       "      <td>-0.17996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28099</th>\n",
       "      <td>3043409</td>\n",
       "      <td>836231</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Boston Beer Company</td>\n",
       "      <td>Harvest New England IPA</td>\n",
       "      <td>IPA - New England</td>\n",
       "      <td>3.45455</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Boston Beer Company Harvest New England IPA Ha...</td>\n",
       "      <td>-0.20455</td>\n",
       "      <td>-0.19293</td>\n",
       "      <td>-0.01162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33865</th>\n",
       "      <td>1258262</td>\n",
       "      <td>836231</td>\n",
       "      <td>4.00</td>\n",
       "      <td>One Mile Brewing Co</td>\n",
       "      <td>No Limits IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.69079</td>\n",
       "      <td>6.5</td>\n",
       "      <td>One Mile Brewing Co No Limits IPA Hop driven I...</td>\n",
       "      <td>0.30921</td>\n",
       "      <td>-0.19293</td>\n",
       "      <td>0.50214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       beer_id  user_id  rating_user                   brewery_name  \\\n",
       "0      2595866   836231         3.25                  Stone Brewing   \n",
       "26960  3383299   836231         3.50  The Fermentorium Beverage Co.   \n",
       "28099  3043409   836231         3.25            Boston Beer Company   \n",
       "33865  1258262   836231         4.00            One Mile Brewing Co   \n",
       "\n",
       "                                            beer_name  \\\n",
       "0      Stone Liberty Station POMMA Said Knock You Out   \n",
       "26960                  Pilot 0X61: South African DIPA   \n",
       "28099                         Harvest New England IPA   \n",
       "33865                                   No Limits IPA   \n",
       "\n",
       "                    beer_style  rating_global  abv  \\\n",
       "0                    IPA - Red        3.75349  7.5   \n",
       "26960  IPA - Imperial / Double        3.87289  9.0   \n",
       "28099        IPA - New England        3.45455  4.6   \n",
       "33865           IPA - American        3.69079  6.5   \n",
       "\n",
       "                                        beer_description  beer_bias  \\\n",
       "0      Stone Brewing Stone Liberty Station POMMA Said...   -0.50349   \n",
       "26960  The Fermentorium Beverage Co. Pilot 0X61: Sout...   -0.37289   \n",
       "28099  Boston Beer Company Harvest New England IPA Ha...   -0.20455   \n",
       "33865  One Mile Brewing Co No Limits IPA Hop driven I...    0.30921   \n",
       "\n",
       "       user_bias  user_pref  \n",
       "0       -0.19293   -0.31056  \n",
       "26960   -0.19293   -0.17996  \n",
       "28099   -0.19293   -0.01162  \n",
       "33865   -0.19293    0.50214  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fours[fours.user_id == 836231]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:48<00:00,  3.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25414542955815506"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_models(df=fours,\n",
    "            test_frac=0.25,\n",
    "            wordvecs=vecs,\n",
    "            beer_2_vec_map=beer_id_to_vecs_index,\n",
    "            user_generator=four_gen,\n",
    "            batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after you get these user preference predictions down to this .25 rmse, you have to calculate what the user would actually rate the beers.  Start with the global mean, add this predicted user preference, and then add a user bias, which should just consist of the known bias of the (user-specific) training set.  This sort of formulation should work best with constant updates to the user's profile (model), adjusting the user bias as you go, and re-training on the new means every checkin.  The overhead isn't much, just a series of 10-20K floats per user, which can be used to initialize the training with a warm start for quicker convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For all users with at least 5 ratings, train this NLP/abv SGDRegressor on all but their last rating, then predict the last, and compare how those predictions do compared to the smart baseline predictions with Pearson similarities between users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1037030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19264"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiveplus = checkins.groupby('user_id').size() > 4\n",
    "fiveplus = checkins[checkins.user_id.map(fiveplus)]\n",
    "print(len(fiveplus))\n",
    "fiveplus.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_last(df, wordvecs, beer_2_vec_map, last_x=1, rando=0):\n",
    "    '''\n",
    "    @df input has columns indicating the user's ratings biases,\n",
    "    but the training will only use the biases calculated on itself.\n",
    "    '''\n",
    "    # keep scores in this dict\n",
    "    scores = dict()\n",
    "    #nlp_rmses = []\n",
    "    #baseline_rmses = []\n",
    "    \n",
    "    for u in tqdm(df.user_id.unique()):\n",
    "        udf = df[df.user_id == u]\n",
    "        ratings = len(udf)\n",
    "        # use the @last_x of each user's checkins as the test group\n",
    "        split = ratings - last_x\n",
    "        utrain = udf.iloc[:split, :]\n",
    "        utest = udf.iloc[split:, :]\n",
    "        # make the corresponding split to the vector indices, vi\n",
    "        vi = udf.beer_id.map(beer_2_vec_map)\n",
    "        trainvecs = wordvecs[vi[:split], :]\n",
    "        testvecs = wordvecs[vi[split:], :]\n",
    "        # calculate the user's avg generosity/stinginess towards KNOWN ratings\n",
    "        known_bias = utrain.beer_bias.mean()\n",
    "        train_targets = utrain.beer_bias - known_bias\n",
    "        \n",
    "        stop_early = len(utrain) > 10\n",
    "        model = SGDRegressor(penalty='elasticnet', early_stopping=stop_early, validation_fraction=0.1, \n",
    "                     random_state=rando, max_iter=500, tol=1e-5, l1_ratio=0.75)\n",
    "        model.fit(trainvecs, train_targets)\n",
    "        \n",
    "        preds = model.predict(testvecs)\n",
    "        baseline_preds = utest.rating_global + known_bias\n",
    "        nlp_preds = (0.3 + 1 / trainvecs.shape[0]) * preds + baseline_preds\n",
    "        \n",
    "        diffs_base = baseline_preds - utest.rating_user\n",
    "        sumsq = np.dot(diffs_base, diffs_base)\n",
    "        rmse_base = np.sqrt(sumsq / len(diffs_base))\n",
    "        #baseline_rmses.append(rmse_base)\n",
    "        \n",
    "        diffs_nlp = nlp_preds - utest.rating_user\n",
    "        sumsq = np.dot(diffs_nlp, diffs_nlp)\n",
    "        rmse_nlp = np.sqrt(sumsq / len(diffs_nlp))\n",
    "        #nlp_rmses.append(rmse_nlp)\n",
    "        \n",
    "        scores[u] = (rmse_base, rmse_nlp)\n",
    "        \n",
    "    return scores #np.mean(baseline_rmses), np.mean(nlp_rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# commenting out the first line here, after running it already.  It's unnecessary even once.\n",
    "#fiveplus['beer_description'] = fiveplus.brewery_name + ' ' + fiveplus.beer_name + ' ' + fiveplus.beer_description\n",
    "fiveplus.reset_index(inplace=True)  # reset the indices so the mapper to BOW vecs works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "      <th>beer_bias</th>\n",
       "      <th>user_bias</th>\n",
       "      <th>user_pref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2095023</td>\n",
       "      <td>3340203</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Stone Brewing Stone Scorpion Bowl IPA To creat...</td>\n",
       "      <td>0.01211</td>\n",
       "      <td>0.167938</td>\n",
       "      <td>-0.155828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2095023</td>\n",
       "      <td>2166716</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Stone Brewing Stone Scorpion Bowl IPA To creat...</td>\n",
       "      <td>-0.23789</td>\n",
       "      <td>-0.663801</td>\n",
       "      <td>0.425911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2095023</td>\n",
       "      <td>2607740</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Stone Brewing Stone Scorpion Bowl IPA To creat...</td>\n",
       "      <td>-0.23789</td>\n",
       "      <td>-0.207602</td>\n",
       "      <td>-0.030288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2095023</td>\n",
       "      <td>1040951</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Stone Brewing Stone Scorpion Bowl IPA To creat...</td>\n",
       "      <td>-0.23789</td>\n",
       "      <td>-0.078888</td>\n",
       "      <td>-0.159002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2095023</td>\n",
       "      <td>1338056</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Stone Brewing</td>\n",
       "      <td>Stone Scorpion Bowl IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.73789</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Stone Brewing Stone Scorpion Bowl IPA To creat...</td>\n",
       "      <td>-0.48789</td>\n",
       "      <td>-0.027114</td>\n",
       "      <td>-0.460776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beer_id  user_id  rating_user   brewery_name                beer_name  \\\n",
       "0  2095023  3340203         3.75  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "1  2095023  2166716         3.50  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "2  2095023  2607740         3.50  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "3  2095023  1040951         3.50  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "4  2095023  1338056         3.25  Stone Brewing  Stone Scorpion Bowl IPA   \n",
       "\n",
       "       beer_style  rating_global  abv  \\\n",
       "0  IPA - American        3.73789  7.5   \n",
       "1  IPA - American        3.73789  7.5   \n",
       "2  IPA - American        3.73789  7.5   \n",
       "3  IPA - American        3.73789  7.5   \n",
       "4  IPA - American        3.73789  7.5   \n",
       "\n",
       "                                    beer_description  beer_bias  user_bias  \\\n",
       "0  Stone Brewing Stone Scorpion Bowl IPA To creat...    0.01211   0.167938   \n",
       "1  Stone Brewing Stone Scorpion Bowl IPA To creat...   -0.23789  -0.663801   \n",
       "2  Stone Brewing Stone Scorpion Bowl IPA To creat...   -0.23789  -0.207602   \n",
       "3  Stone Brewing Stone Scorpion Bowl IPA To creat...   -0.23789  -0.078888   \n",
       "4  Stone Brewing Stone Scorpion Bowl IPA To creat...   -0.48789  -0.027114   \n",
       "\n",
       "   user_pref  \n",
       "0  -0.155828  \n",
       "1   0.425911  \n",
       "2  -0.030288  \n",
       "3  -0.159002  \n",
       "4  -0.460776  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiveplus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 2\n"
     ]
    }
   ],
   "source": [
    "short_test = fiveplus[(fiveplus.user_id == 2607740) | (fiveplus.user_id == 1040951)]\n",
    "print(len(short_test), short_test.user_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "baseline_error, nlp_error = test_last(short_test, vecs, beer_id_to_vecs_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_baseline_error = 0.27962614819309595\n",
      "test_nlp_error = 0.3123180189674395\n"
     ]
    }
   ],
   "source": [
    "print(f'test_baseline_error = {baseline_error}')\n",
    "print(f'test_nlp_error = {nlp_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 331/19264 [02:51<2:43:17,  1.93it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  2%|▏         | 390/19264 [03:23<2:32:02,  2.07it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  2%|▏         | 467/19264 [04:07<2:31:09,  2.07it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  3%|▎         | 571/19264 [04:57<2:24:28,  2.16it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  4%|▎         | 698/19264 [05:56<2:24:05,  2.15it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  4%|▎         | 705/19264 [05:59<2:19:06,  2.22it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  4%|▍         | 784/19264 [06:38<2:32:20,  2.02it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  4%|▍         | 807/19264 [06:49<2:27:59,  2.08it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  4%|▍         | 815/19264 [06:55<3:27:22,  1.48it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  4%|▍         | 844/19264 [07:12<2:57:57,  1.73it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  4%|▍         | 857/19264 [07:19<2:40:52,  1.91it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  5%|▌         | 980/19264 [08:25<3:00:12,  1.69it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  5%|▌         | 1059/19264 [09:06<2:21:21,  2.15it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  6%|▌         | 1129/19264 [09:43<2:32:44,  1.98it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  6%|▌         | 1161/19264 [10:03<3:02:32,  1.65it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  6%|▋         | 1221/19264 [10:33<2:20:45,  2.14it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  6%|▋         | 1228/19264 [10:37<2:54:21,  1.72it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  6%|▋         | 1242/19264 [10:45<2:28:03,  2.03it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  6%|▋         | 1248/19264 [10:48<2:46:50,  1.80it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  6%|▋         | 1249/19264 [10:49<3:04:03,  1.63it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  7%|▋         | 1267/19264 [10:59<2:27:32,  2.03it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  7%|▋         | 1276/19264 [11:04<3:02:37,  1.64it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  7%|▋         | 1351/19264 [11:44<2:59:53,  1.66it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  7%|▋         | 1363/19264 [11:51<2:55:44,  1.70it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  7%|▋         | 1376/19264 [11:58<2:41:38,  1.84it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  7%|▋         | 1389/19264 [12:05<2:41:13,  1.85it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  7%|▋         | 1404/19264 [12:13<2:35:20,  1.92it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  7%|▋         | 1422/19264 [12:23<2:38:40,  1.87it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  7%|▋         | 1439/19264 [12:33<2:57:06,  1.68it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  7%|▋         | 1440/19264 [12:34<3:11:40,  1.55it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1478/19264 [12:55<2:40:20,  1.85it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1520/19264 [13:17<2:18:26,  2.14it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1523/19264 [13:19<2:29:20,  1.98it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1545/19264 [13:31<2:59:38,  1.64it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1546/19264 [13:32<3:11:00,  1.55it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1548/19264 [13:34<3:45:16,  1.31it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1549/19264 [13:34<3:49:51,  1.28it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1553/19264 [13:37<2:48:56,  1.75it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1554/19264 [13:38<3:07:39,  1.57it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1560/19264 [13:42<3:01:18,  1.63it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1562/19264 [13:43<2:54:21,  1.69it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1568/19264 [13:46<2:41:14,  1.83it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1574/19264 [13:50<3:12:15,  1.53it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1580/19264 [13:54<3:35:43,  1.37it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1582/19264 [13:56<4:00:26,  1.23it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1591/19264 [14:01<2:44:37,  1.79it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1603/19264 [14:08<2:27:15,  2.00it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1613/19264 [14:14<2:31:19,  1.94it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1620/19264 [14:17<2:39:40,  1.84it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1621/19264 [14:18<2:56:25,  1.67it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1629/19264 [14:22<2:33:57,  1.91it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 1633/19264 [14:24<2:22:02,  2.07it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▊         | 1639/19264 [14:28<2:35:00,  1.90it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▊         | 1645/19264 [14:31<2:22:22,  2.06it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▊         | 1646/19264 [14:32<2:49:55,  1.73it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▊         | 1655/19264 [14:37<2:39:27,  1.84it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▊         | 1659/19264 [14:39<3:01:46,  1.61it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▊         | 1660/19264 [14:40<3:16:25,  1.49it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▊         | 1675/19264 [14:49<2:42:14,  1.81it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▊         | 1677/19264 [14:50<2:56:28,  1.66it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▊         | 1685/19264 [14:56<3:28:23,  1.41it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▉         | 1687/19264 [14:57<3:12:33,  1.52it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▉         | 1688/19264 [14:58<3:22:40,  1.45it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▉         | 1702/19264 [15:05<2:27:49,  1.98it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▉         | 1704/19264 [15:07<2:39:45,  1.83it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▉         | 1715/19264 [15:13<2:51:06,  1.71it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▉         | 1716/19264 [15:14<3:06:21,  1.57it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▉         | 1726/19264 [15:20<2:27:54,  1.98it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▉         | 1728/19264 [15:21<2:56:23,  1.66it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▉         | 1749/19264 [15:34<2:50:18,  1.71it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▉         | 1802/19264 [16:00<2:26:05,  1.99it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 12%|█▏        | 2226/19264 [19:37<2:12:18,  2.15it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 12%|█▏        | 2322/19264 [20:26<2:27:16,  1.92it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 12%|█▏        | 2344/19264 [20:38<2:38:14,  1.78it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 12%|█▏        | 2379/19264 [20:56<2:33:38,  1.83it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 13%|█▎        | 2568/19264 [22:29<2:42:11,  1.72it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 14%|█▍        | 2719/19264 [23:45<2:17:19,  2.01it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 14%|█▍        | 2732/19264 [23:52<2:52:08,  1.60it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 15%|█▍        | 2799/19264 [24:28<2:16:34,  2.01it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 15%|█▍        | 2857/19264 [25:00<3:01:00,  1.51it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 15%|█▍        | 2859/19264 [25:01<3:05:24,  1.47it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 15%|█▌        | 2928/19264 [25:38<2:16:25,  2.00it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 15%|█▌        | 2948/19264 [25:50<2:28:59,  1.83it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 15%|█▌        | 2952/19264 [25:53<2:28:43,  1.83it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 16%|█▌        | 3018/19264 [26:29<2:12:18,  2.05it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 16%|█▌        | 3085/19264 [27:03<2:09:40,  2.08it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 17%|█▋        | 3367/19264 [29:25<2:41:46,  1.64it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 18%|█▊        | 3395/19264 [29:40<2:24:34,  1.83it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 18%|█▊        | 3396/19264 [29:40<2:46:53,  1.58it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 18%|█▊        | 3399/19264 [29:42<2:32:06,  1.74it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 18%|█▊        | 3401/19264 [29:43<2:31:47,  1.74it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 18%|█▊        | 3410/19264 [29:49<2:35:44,  1.70it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 18%|█▊        | 3411/19264 [29:50<2:57:21,  1.49it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 18%|█▊        | 3415/19264 [29:52<2:23:13,  1.84it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 18%|█▊        | 3418/19264 [29:54<2:19:48,  1.89it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 18%|█▊        | 3426/19264 [29:58<2:10:49,  2.02it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 18%|█▊        | 3427/19264 [29:59<2:34:00,  1.71it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▊        | 3591/19264 [31:23<2:03:03,  2.12it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▊        | 3595/19264 [31:25<2:15:05,  1.93it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▊        | 3601/19264 [31:29<2:28:26,  1.76it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▊        | 3603/19264 [31:30<2:32:55,  1.71it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▊        | 3605/19264 [31:32<2:56:26,  1.48it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▊        | 3608/19264 [31:33<2:47:13,  1.56it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▉        | 3616/19264 [31:38<2:16:07,  1.92it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▉        | 3618/19264 [31:39<2:24:11,  1.81it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▉        | 3625/19264 [31:43<2:27:46,  1.76it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▉        | 3627/19264 [31:45<2:46:35,  1.56it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▉        | 3633/19264 [31:49<2:46:35,  1.56it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▉        | 3636/19264 [31:51<2:39:34,  1.63it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▉        | 3639/19264 [31:53<2:38:10,  1.65it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▉        | 3644/19264 [31:55<2:24:30,  1.80it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▉        | 3654/19264 [32:01<2:26:53,  1.77it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|█▉        | 3769/19264 [32:59<2:06:34,  2.04it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|█▉        | 3784/19264 [33:07<2:09:18,  2.00it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|█▉        | 3817/19264 [33:24<2:09:27,  1.99it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|█▉        | 3836/19264 [33:35<2:14:55,  1.91it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|█▉        | 3844/19264 [33:39<2:06:06,  2.04it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|██        | 3868/19264 [33:51<2:11:35,  1.95it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|██        | 3921/19264 [34:19<2:11:28,  1.95it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|██        | 3924/19264 [34:21<2:28:20,  1.72it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|██        | 3927/19264 [34:23<2:13:58,  1.91it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|██        | 3928/19264 [34:23<2:33:06,  1.67it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|██        | 3945/19264 [34:32<2:08:39,  1.98it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 21%|██        | 3991/19264 [34:57<2:20:04,  1.82it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 21%|██        | 3997/19264 [35:00<2:12:40,  1.92it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 22%|██▏       | 4154/19264 [36:21<1:57:36,  2.14it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 23%|██▎       | 4365/19264 [38:12<2:13:32,  1.86it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 23%|██▎       | 4499/19264 [39:26<2:28:46,  1.65it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 24%|██▍       | 4615/19264 [40:26<2:18:13,  1.77it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 24%|██▍       | 4623/19264 [40:30<2:10:12,  1.87it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 24%|██▍       | 4665/19264 [40:53<2:04:00,  1.96it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 24%|██▍       | 4707/19264 [41:17<1:53:54,  2.13it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 25%|██▍       | 4786/19264 [41:58<2:21:29,  1.71it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 25%|██▍       | 4802/19264 [42:07<1:59:37,  2.01it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 25%|██▍       | 4811/19264 [42:12<2:15:05,  1.78it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 25%|██▍       | 4814/19264 [42:14<2:15:33,  1.78it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 25%|██▌       | 4820/19264 [42:18<2:27:22,  1.63it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 25%|██▌       | 4863/19264 [42:40<2:04:35,  1.93it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▌       | 4936/19264 [43:21<2:25:42,  1.64it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▌       | 4943/19264 [43:25<2:12:31,  1.80it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▌       | 4949/19264 [43:28<2:05:01,  1.91it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▌       | 4967/19264 [43:38<2:02:30,  1.95it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▌       | 4999/19264 [43:55<2:12:35,  1.79it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▌       | 5000/19264 [43:56<2:24:52,  1.64it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▌       | 5017/19264 [44:06<2:41:32,  1.47it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▌       | 5026/19264 [44:12<2:28:27,  1.60it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▌       | 5029/19264 [44:14<2:29:52,  1.58it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▌       | 5031/19264 [44:16<2:34:31,  1.54it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▌       | 5045/19264 [44:23<1:55:17,  2.06it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▋       | 5089/19264 [44:45<2:04:56,  1.89it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 27%|██▋       | 5166/19264 [45:24<2:13:09,  1.76it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 27%|██▋       | 5167/19264 [45:24<2:22:11,  1.65it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 27%|██▋       | 5172/19264 [45:27<2:16:58,  1.71it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 27%|██▋       | 5187/19264 [45:36<2:16:52,  1.71it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 28%|██▊       | 5420/19264 [47:36<1:53:12,  2.04it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 29%|██▊       | 5501/19264 [48:16<2:31:53,  1.51it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 29%|██▊       | 5506/19264 [48:19<2:33:12,  1.50it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 29%|██▊       | 5508/19264 [48:21<2:21:48,  1.62it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 29%|██▊       | 5509/19264 [48:21<2:30:55,  1.52it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 29%|██▊       | 5511/19264 [48:23<3:17:14,  1.16it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 30%|███       | 5873/19264 [51:24<1:56:15,  1.92it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 31%|███       | 5878/19264 [51:27<2:00:21,  1.85it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 31%|███       | 5972/19264 [52:18<2:14:17,  1.65it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 32%|███▏      | 6090/19264 [53:22<1:42:54,  2.13it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 32%|███▏      | 6128/19264 [53:43<2:12:25,  1.65it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 32%|███▏      | 6160/19264 [54:04<2:08:30,  1.70it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 32%|███▏      | 6168/19264 [54:09<2:32:18,  1.43it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 32%|███▏      | 6171/19264 [54:11<2:28:08,  1.47it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 33%|███▎      | 6309/19264 [55:12<1:36:04,  2.25it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 33%|███▎      | 6358/19264 [55:36<1:56:09,  1.85it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 33%|███▎      | 6360/19264 [55:38<2:00:20,  1.79it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 33%|███▎      | 6373/19264 [55:45<2:18:09,  1.56it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 33%|███▎      | 6377/19264 [55:48<2:08:48,  1.67it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 33%|███▎      | 6391/19264 [55:56<2:05:02,  1.72it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 34%|███▍      | 6530/19264 [57:12<3:11:24,  1.11it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 34%|███▍      | 6539/19264 [57:19<3:00:20,  1.18it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 34%|███▍      | 6572/19264 [57:37<1:30:20,  2.34it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 34%|███▍      | 6575/19264 [57:39<1:58:45,  1.78it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 34%|███▍      | 6576/19264 [57:40<2:07:11,  1.66it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 34%|███▍      | 6594/19264 [57:52<2:14:36,  1.57it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 34%|███▍      | 6620/19264 [58:06<1:38:20,  2.14it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 34%|███▍      | 6624/19264 [58:09<2:00:48,  1.74it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 34%|███▍      | 6627/19264 [58:10<1:53:44,  1.85it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 34%|███▍      | 6634/19264 [58:14<1:53:05,  1.86it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 35%|███▍      | 6724/19264 [58:59<1:40:15,  2.08it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 35%|███▍      | 6726/19264 [59:00<1:55:25,  1.81it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 35%|███▍      | 6727/19264 [59:01<2:10:40,  1.60it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 35%|███▌      | 6754/19264 [59:15<1:48:09,  1.93it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 35%|███▌      | 6777/19264 [59:28<1:35:08,  2.19it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 35%|███▌      | 6791/19264 [59:34<1:36:26,  2.16it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 36%|███▌      | 6903/19264 [1:00:28<1:40:15,  2.05it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 36%|███▌      | 6970/19264 [1:01:01<1:36:04,  2.13it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 36%|███▋      | 6999/19264 [1:01:16<1:50:14,  1.85it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 37%|███▋      | 7080/19264 [1:01:51<1:21:13,  2.50it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 37%|███▋      | 7124/19264 [1:02:12<1:45:40,  1.91it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 37%|███▋      | 7153/19264 [1:02:27<1:58:46,  1.70it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 37%|███▋      | 7207/19264 [1:02:55<2:03:21,  1.63it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 37%|███▋      | 7208/19264 [1:02:56<2:08:09,  1.57it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 38%|███▊      | 7261/19264 [1:03:25<1:56:26,  1.72it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 38%|███▊      | 7294/19264 [1:03:40<2:02:01,  1.63it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 38%|███▊      | 7305/19264 [1:03:46<1:50:25,  1.80it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 38%|███▊      | 7341/19264 [1:04:05<1:36:57,  2.05it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 38%|███▊      | 7388/19264 [1:04:32<1:48:30,  1.82it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 38%|███▊      | 7413/19264 [1:04:46<1:47:35,  1.84it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 39%|███▊      | 7439/19264 [1:04:58<1:36:37,  2.04it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 39%|███▉      | 7537/19264 [1:05:42<1:19:46,  2.45it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 39%|███▉      | 7545/19264 [1:05:47<1:55:56,  1.68it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 39%|███▉      | 7555/19264 [1:05:52<1:42:20,  1.91it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 40%|███▉      | 7701/19264 [1:06:49<1:12:21,  2.66it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 40%|████      | 7780/19264 [1:07:19<1:24:23,  2.27it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 41%|████      | 7834/19264 [1:07:39<1:02:10,  3.06it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 41%|████      | 7943/19264 [1:08:22<1:16:38,  2.46it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 41%|████▏     | 7947/19264 [1:08:24<1:39:04,  1.90it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 41%|████▏     | 7975/19264 [1:08:37<52:01,  3.62it/s]  /Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 41%|████▏     | 7976/19264 [1:08:38<1:19:40,  2.36it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 42%|████▏     | 8029/19264 [1:08:55<59:46,  3.13it/s]  /Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 43%|████▎     | 8281/19264 [1:10:14<1:20:20,  2.28it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 43%|████▎     | 8374/19264 [1:10:43<1:16:19,  2.38it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 45%|████▍     | 8620/19264 [1:12:05<54:15,  3.27it/s]  /Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 45%|████▍     | 8631/19264 [1:12:09<54:27,  3.25it/s]  /Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 45%|████▌     | 8672/19264 [1:12:21<48:57,  3.61it/s]  /Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 45%|████▌     | 8728/19264 [1:12:40<1:12:21,  2.43it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 45%|████▌     | 8735/19264 [1:12:44<1:32:17,  1.90it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 45%|████▌     | 8759/19264 [1:12:53<1:07:16,  2.60it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 46%|████▌     | 8785/19264 [1:13:02<56:52,  3.07it/s]  /Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 48%|████▊     | 9171/19264 [1:14:58<48:05,  3.50it/s]  /Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 49%|████▉     | 9402/19264 [1:16:06<48:14,  3.41it/s]  /Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 50%|████▉     | 9544/19264 [1:16:48<46:45,  3.46it/s]  /Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 50%|████▉     | 9596/19264 [1:17:03<45:41,  3.53it/s]  /Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 51%|█████     | 9766/19264 [1:17:53<44:50,  3.53it/s]  /Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 51%|█████     | 9769/19264 [1:17:54<53:02,  2.98it/s]  /Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 54%|█████▍    | 10378/19264 [1:20:54<41:25,  3.57it/s]  /Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 57%|█████▋    | 10971/19264 [1:23:49<39:13,  3.52it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 58%|█████▊    | 11249/19264 [1:25:11<39:10,  3.41it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 64%|██████▍   | 12345/19264 [1:30:34<53:08,  2.17it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 65%|██████▌   | 12599/19264 [1:31:49<35:50,  3.10it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 66%|██████▌   | 12673/19264 [1:32:11<31:00,  3.54it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 68%|██████▊   | 13053/19264 [1:34:04<30:07,  3.44it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 69%|██████▉   | 13381/19264 [1:35:41<28:19,  3.46it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 70%|███████   | 13562/19264 [1:36:35<29:20,  3.24it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 71%|███████   | 13611/19264 [1:36:49<28:41,  3.28it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 73%|███████▎  | 13985/19264 [1:38:38<25:02,  3.51it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 73%|███████▎  | 14101/19264 [1:39:13<28:59,  2.97it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 73%|███████▎  | 14158/19264 [1:39:30<30:03,  2.83it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 73%|███████▎  | 14159/19264 [1:39:30<34:43,  2.45it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 77%|███████▋  | 14847/19264 [1:42:52<21:13,  3.47it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 78%|███████▊  | 15071/19264 [1:44:01<23:59,  2.91it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 81%|████████▏ | 15652/19264 [1:46:52<18:19,  3.28it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 88%|████████▊ | 16929/19264 [1:53:08<10:51,  3.58it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 89%|████████▉ | 17104/19264 [1:53:59<11:06,  3.24it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 90%|████████▉ | 17295/19264 [1:54:54<09:31,  3.45it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 93%|█████████▎| 17857/19264 [1:57:38<06:46,  3.46it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 93%|█████████▎| 17963/19264 [1:58:08<06:15,  3.47it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 96%|█████████▌| 18529/19264 [2:00:55<03:35,  3.41it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 99%|█████████▉| 19067/19264 [2:03:30<00:58,  3.37it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "100%|██████████| 19264/19264 [2:04:28<00:00,  3.40it/s]\n"
     ]
    }
   ],
   "source": [
    "baseline_error, nlp_error = test_last(fiveplus, vecs, beer_id_to_vecs_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_baseline_error = 0.3081064876194298\n",
      "test_nlp_error = 0.3126100764886783\n"
     ]
    }
   ],
   "source": [
    "# all 19K users and 1M checkins\n",
    "print(f'test_baseline_error = {baseline_error}')\n",
    "print(f'test_nlp_error = {nlp_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fivers = (u for u in fiveplus.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1073271"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for _ in range(11):\n",
    "    u=next(fivers)\n",
    "u=next(fivers)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_df = fiveplus[fiveplus.user_id == u]\n",
    "len(u_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "      <th>beer_bias</th>\n",
       "      <th>user_bias</th>\n",
       "      <th>user_pref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>389595</th>\n",
       "      <td>1016561</td>\n",
       "      <td>1073271</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3 Stars Brewing Company</td>\n",
       "      <td>Above the Clouds</td>\n",
       "      <td>Farmhouse Ale - Saison</td>\n",
       "      <td>3.57005</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3 Stars Brewing Company Above the Clouds Style...</td>\n",
       "      <td>0.92995</td>\n",
       "      <td>0.432022</td>\n",
       "      <td>0.497928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389608</th>\n",
       "      <td>2452100</td>\n",
       "      <td>1073271</td>\n",
       "      <td>4.25</td>\n",
       "      <td>Old Ox Brewery</td>\n",
       "      <td>Goal Crusher</td>\n",
       "      <td>IPA - International</td>\n",
       "      <td>3.70614</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Old Ox Brewery Goal Crusher This amazing mix o...</td>\n",
       "      <td>0.54386</td>\n",
       "      <td>0.432022</td>\n",
       "      <td>0.111838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389611</th>\n",
       "      <td>659313</td>\n",
       "      <td>1073271</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Blue Mountain Brewery</td>\n",
       "      <td>A Hopwork Orange</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.63205</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Blue Mountain Brewery A Hopwork Orange An IPA ...</td>\n",
       "      <td>0.36795</td>\n",
       "      <td>0.432022</td>\n",
       "      <td>-0.064072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389676</th>\n",
       "      <td>2922244</td>\n",
       "      <td>1073271</td>\n",
       "      <td>4.25</td>\n",
       "      <td>AleSmith Brewing Company</td>\n",
       "      <td>Gregarious Nature</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.78609</td>\n",
       "      <td>7.0</td>\n",
       "      <td>AleSmith Brewing Company Gregarious Nature Two...</td>\n",
       "      <td>0.46391</td>\n",
       "      <td>0.432022</td>\n",
       "      <td>0.031888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389768</th>\n",
       "      <td>2485082</td>\n",
       "      <td>1073271</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Center Of The Universe Brewing Company</td>\n",
       "      <td>Chameleon IPA Green</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.80481</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Center Of The Universe Brewing Company Chamele...</td>\n",
       "      <td>0.19519</td>\n",
       "      <td>0.432022</td>\n",
       "      <td>-0.236832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389803</th>\n",
       "      <td>2365122</td>\n",
       "      <td>1073271</td>\n",
       "      <td>4.25</td>\n",
       "      <td>Terrapin Beer Co.</td>\n",
       "      <td>So Fresh &amp; So Green, Green - Citra</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>3.72725</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Terrapin Beer Co.  So Fresh &amp; So Green, Green ...</td>\n",
       "      <td>0.52275</td>\n",
       "      <td>0.432022</td>\n",
       "      <td>0.090728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389819</th>\n",
       "      <td>2415824</td>\n",
       "      <td>1073271</td>\n",
       "      <td>4.25</td>\n",
       "      <td>6 Bears &amp; A Goat Brewing Company</td>\n",
       "      <td>Trop Hours</td>\n",
       "      <td>Pale Ale - American</td>\n",
       "      <td>3.58494</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6 Bears &amp; A Goat Brewing Company Trop Hours Am...</td>\n",
       "      <td>0.66506</td>\n",
       "      <td>0.432022</td>\n",
       "      <td>0.233038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389823</th>\n",
       "      <td>2534246</td>\n",
       "      <td>1073271</td>\n",
       "      <td>4.25</td>\n",
       "      <td>Northern Outer Banks Brewing Company</td>\n",
       "      <td>Corolla Lager</td>\n",
       "      <td>Lager - American Amber / Red</td>\n",
       "      <td>3.53250</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Northern Outer Banks Brewing Company Corolla L...</td>\n",
       "      <td>0.71750</td>\n",
       "      <td>0.432022</td>\n",
       "      <td>0.285478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389828</th>\n",
       "      <td>19562</td>\n",
       "      <td>1073271</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Mad Fox Brewing Company</td>\n",
       "      <td>Defender American Pale Ale</td>\n",
       "      <td>Pale Ale - American</td>\n",
       "      <td>3.37204</td>\n",
       "      <td>5.2</td>\n",
       "      <td>Mad Fox Brewing Company Defender American Pale...</td>\n",
       "      <td>0.62796</td>\n",
       "      <td>0.432022</td>\n",
       "      <td>0.195938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389832</th>\n",
       "      <td>28524</td>\n",
       "      <td>1073271</td>\n",
       "      <td>4.25</td>\n",
       "      <td>Port City Brewing</td>\n",
       "      <td>Optimal® Wit</td>\n",
       "      <td>Witbier</td>\n",
       "      <td>3.62283</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Port City Brewing Optimal® Wit GABF: 2013 Gold...</td>\n",
       "      <td>0.62717</td>\n",
       "      <td>0.432022</td>\n",
       "      <td>0.195148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        beer_id  user_id  rating_user                            brewery_name  \\\n",
       "389595  1016561  1073271         4.50                 3 Stars Brewing Company   \n",
       "389608  2452100  1073271         4.25                          Old Ox Brewery   \n",
       "389611   659313  1073271         4.00                   Blue Mountain Brewery   \n",
       "389676  2922244  1073271         4.25                AleSmith Brewing Company   \n",
       "389768  2485082  1073271         4.00  Center Of The Universe Brewing Company   \n",
       "389803  2365122  1073271         4.25                      Terrapin Beer Co.    \n",
       "389819  2415824  1073271         4.25        6 Bears & A Goat Brewing Company   \n",
       "389823  2534246  1073271         4.25    Northern Outer Banks Brewing Company   \n",
       "389828    19562  1073271         4.00                 Mad Fox Brewing Company   \n",
       "389832    28524  1073271         4.25                       Port City Brewing   \n",
       "\n",
       "                                 beer_name                    beer_style  \\\n",
       "389595                    Above the Clouds        Farmhouse Ale - Saison   \n",
       "389608                        Goal Crusher           IPA - International   \n",
       "389611                    A Hopwork Orange                IPA - American   \n",
       "389676                   Gregarious Nature                IPA - American   \n",
       "389768                 Chameleon IPA Green                IPA - American   \n",
       "389803  So Fresh & So Green, Green - Citra                IPA - American   \n",
       "389819                          Trop Hours           Pale Ale - American   \n",
       "389823                       Corolla Lager  Lager - American Amber / Red   \n",
       "389828          Defender American Pale Ale           Pale Ale - American   \n",
       "389832                        Optimal® Wit                       Witbier   \n",
       "\n",
       "        rating_global  abv                                   beer_description  \\\n",
       "389595        3.57005  6.3  3 Stars Brewing Company Above the Clouds Style...   \n",
       "389608        3.70614  7.5  Old Ox Brewery Goal Crusher This amazing mix o...   \n",
       "389611        3.63205  7.0  Blue Mountain Brewery A Hopwork Orange An IPA ...   \n",
       "389676        3.78609  7.0  AleSmith Brewing Company Gregarious Nature Two...   \n",
       "389768        3.80481  6.8  Center Of The Universe Brewing Company Chamele...   \n",
       "389803        3.72725  6.6  Terrapin Beer Co.  So Fresh & So Green, Green ...   \n",
       "389819        3.58494  5.6  6 Bears & A Goat Brewing Company Trop Hours Am...   \n",
       "389823        3.53250  6.0  Northern Outer Banks Brewing Company Corolla L...   \n",
       "389828        3.37204  5.2  Mad Fox Brewing Company Defender American Pale...   \n",
       "389832        3.62283  4.9  Port City Brewing Optimal® Wit GABF: 2013 Gold...   \n",
       "\n",
       "        beer_bias  user_bias  user_pref  \n",
       "389595    0.92995   0.432022   0.497928  \n",
       "389608    0.54386   0.432022   0.111838  \n",
       "389611    0.36795   0.432022  -0.064072  \n",
       "389676    0.46391   0.432022   0.031888  \n",
       "389768    0.19519   0.432022  -0.236832  \n",
       "389803    0.52275   0.432022   0.090728  \n",
       "389819    0.66506   0.432022   0.233038  \n",
       "389823    0.71750   0.432022   0.285478  \n",
       "389828    0.62796   0.432022   0.195938  \n",
       "389832    0.62717   0.432022   0.195148  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1073271: (0.19651279720279735, 0.1777578412714842)}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_last(u_df, vecs, beer_id_to_vecs_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample1K = np.random.choice(fiveplus.user_id.unique(), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "fiveplus['sampled'] = fiveplus.user_id.apply(lambda uid: uid in sample1K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52139"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(fiveplus.sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 18/973 [00:10<08:06,  1.96it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 77/973 [00:41<08:45,  1.70it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 82/973 [00:44<08:55,  1.67it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 15%|█▍        | 144/973 [01:17<07:49,  1.76it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 17%|█▋        | 167/973 [01:30<07:35,  1.77it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 17%|█▋        | 169/973 [01:31<07:47,  1.72it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▉        | 187/973 [01:41<07:08,  1.83it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|█▉        | 193/973 [01:44<06:43,  1.93it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 25%|██▍       | 241/973 [02:10<07:10,  1.70it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 33%|███▎      | 317/973 [02:49<05:33,  1.97it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 35%|███▍      | 339/973 [03:00<05:19,  1.98it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 38%|███▊      | 367/973 [03:14<05:11,  1.95it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 98%|█████████▊| 949/973 [06:23<00:07,  3.30it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "100%|██████████| 973/973 [06:31<00:00,  3.21it/s]\n"
     ]
    }
   ],
   "source": [
    "sample1K_scores = test_last(fiveplus[fiveplus.sampled], vecs, beer_id_to_vecs_index, rando=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.31365449,  0.31276952])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([val for val in sample1K_scores.values()], axis=0)  # ([baseline error only, baseline plus regression error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sizes = dict(fiveplus.groupby('user_id').size())\n",
    "by_size = [sizes[key] for key in sample1K_scores.keys()]\n",
    "baselines = [v[0] for v in sample1K_scores.values()]\n",
    "nlps = [v[1] for v in sample1K_scores.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assertion test\n",
    "len(by_size) == len(baselines) == len(nlps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4QAAAJQCAYAAADWlqq2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1RzjEQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a4a7a4ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.scatter(by_size, np.array(baselines) - np.array(nlps), facecolors='none', edgecolors='b', alpha=0.5)\n",
    "plt.axhline(0.25, c='g')\n",
    "plt.axhline(-0.25, c='g')\n",
    "plt.axhline(0, c='k', alpha=0.3)\n",
    "plt.ylabel('<--  Baseline model better \\\n",
    "        NLP model better -->')\n",
    "plt.xlabel('Size of training set')\n",
    "plt.ylim(-0.75, 0.75);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With max_df set to 0.17, removing top 8 most frequent words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 13/973 [00:07<08:09,  1.96it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  2%|▏         | 18/973 [00:10<08:01,  1.98it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  3%|▎         | 31/973 [00:17<07:49,  2.01it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  3%|▎         | 33/973 [00:18<08:33,  1.83it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  5%|▍         | 44/973 [00:25<09:02,  1.71it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 75/973 [00:41<07:05,  2.11it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 77/973 [00:43<08:44,  1.71it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 81/973 [00:45<09:25,  1.58it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 82/973 [00:46<10:11,  1.46it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▊         | 83/973 [00:47<10:46,  1.38it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▊         | 85/973 [00:49<11:24,  1.30it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 13%|█▎        | 130/973 [01:12<07:30,  1.87it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 14%|█▍        | 134/973 [01:14<07:21,  1.90it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 14%|█▍        | 140/973 [01:18<07:43,  1.80it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 15%|█▍        | 144/973 [01:20<08:39,  1.59it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 15%|█▌        | 146/973 [01:22<08:29,  1.62it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 15%|█▌        | 148/973 [01:23<09:10,  1.50it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 15%|█▌        | 150/973 [01:24<08:57,  1.53it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 17%|█▋        | 165/973 [01:32<06:12,  2.17it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 17%|█▋        | 166/973 [01:33<07:44,  1.74it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 17%|█▋        | 167/973 [01:34<08:46,  1.53it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 17%|█▋        | 169/973 [01:35<07:51,  1.71it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 18%|█▊        | 180/973 [01:41<06:21,  2.08it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▉        | 187/973 [01:44<07:08,  1.83it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|█▉        | 193/973 [01:48<06:43,  1.93it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 22%|██▏       | 217/973 [02:01<07:06,  1.77it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 24%|██▎       | 231/973 [02:09<05:47,  2.13it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 25%|██▍       | 241/973 [02:14<07:03,  1.73it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 25%|██▍       | 242/973 [02:15<07:13,  1.69it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 25%|██▌       | 244/973 [02:16<07:32,  1.61it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 25%|██▌       | 248/973 [02:18<06:26,  1.88it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▌       | 249/973 [02:19<07:00,  1.72it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 28%|██▊       | 270/973 [02:30<05:47,  2.03it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 29%|██▉       | 284/973 [02:37<04:51,  2.37it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 31%|███       | 303/973 [02:47<05:49,  1.92it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 33%|███▎      | 317/973 [02:54<06:12,  1.76it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 34%|███▎      | 328/973 [03:01<05:36,  1.91it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 34%|███▍      | 330/973 [03:02<05:45,  1.86it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 35%|███▍      | 339/973 [03:07<06:00,  1.76it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 36%|███▋      | 354/973 [03:16<05:31,  1.87it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 38%|███▊      | 367/973 [03:22<04:47,  2.11it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 40%|████      | 394/973 [03:35<03:20,  2.89it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 44%|████▍     | 431/973 [03:47<03:10,  2.85it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 45%|████▍     | 436/973 [03:49<03:18,  2.70it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 47%|████▋     | 456/973 [03:56<02:21,  3.66it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 74%|███████▍  | 719/973 [05:17<01:14,  3.42it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 76%|███████▌  | 736/973 [05:22<01:11,  3.33it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 95%|█████████▍| 923/973 [06:20<00:14,  3.49it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 98%|█████████▊| 949/973 [06:28<00:07,  3.29it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 99%|█████████▊| 960/973 [06:31<00:03,  3.32it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "100%|██████████| 973/973 [06:36<00:00,  3.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# also lowered early stopping tol param in the model, from 1e-4 to 1e-5\n",
    "sample1K_scores = test_last(fiveplus[fiveplus.sampled], vecs, beer_id_to_vecs_index, rando=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.31365449,  0.31241381])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([val for val in sample1K_scores.values()], axis=0)  # ([baseline error only, baseline plus regression error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  5%|▍         | 23/489 [00:13<04:05,  1.90it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  5%|▌         | 26/489 [00:15<05:05,  1.52it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  6%|▌         | 27/489 [00:15<05:07,  1.50it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  6%|▋         | 31/489 [00:18<05:02,  1.52it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  7%|▋         | 36/489 [00:21<04:14,  1.78it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  8%|▊         | 39/489 [00:23<04:15,  1.76it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▉         | 44/489 [00:27<05:03,  1.47it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▉         | 45/489 [00:27<05:06,  1.45it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 10%|█         | 51/489 [00:31<04:53,  1.49it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 13%|█▎        | 64/489 [00:39<04:21,  1.63it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 14%|█▍        | 70/489 [00:42<04:11,  1.67it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 15%|█▍        | 72/489 [00:44<04:34,  1.52it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 16%|█▌        | 77/489 [00:47<04:23,  1.57it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 18%|█▊        | 89/489 [00:55<04:29,  1.48it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 19%|█▉        | 93/489 [00:57<03:32,  1.86it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 25%|██▍       | 122/489 [01:14<03:12,  1.91it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▌       | 125/489 [01:15<03:13,  1.88it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 28%|██▊       | 136/489 [01:24<03:09,  1.86it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 33%|███▎      | 162/489 [01:40<03:39,  1.49it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 35%|███▍      | 170/489 [01:45<03:22,  1.57it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 40%|████      | 198/489 [02:00<01:55,  2.51it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 44%|████▍     | 216/489 [02:06<01:19,  3.43it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 46%|████▌     | 224/489 [02:09<01:22,  3.19it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 46%|████▌     | 226/489 [02:10<02:08,  2.04it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 82%|████████▏ | 400/489 [03:04<00:28,  3.07it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "100%|██████████| 489/489 [03:31<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.30772315  0.30482691]\n"
     ]
    }
   ],
   "source": [
    "# try a different sample\n",
    "np.random.seed(1)\n",
    "sample500 = np.random.choice(fiveplus.user_id.unique(), 500)\n",
    "fiveplus['sampled'] = fiveplus.user_id.apply(lambda uid: uid in sample500)\n",
    "sample500_scores = test_last(fiveplus[fiveplus.sampled], vecs, beer_id_to_vecs_index, rando=1)\n",
    "print(np.mean([val for val in sample500_scores.values()], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the coefficients for one user, to see how sparse they might be, since the scores for the baseline seem to be essentially the same as for NLP/abv/style predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 13)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = sample500[-1]\n",
    "udf = fiveplus[fiveplus.user_id == u]\n",
    "udf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.968302777778 1.02550631114\n"
     ]
    }
   ],
   "source": [
    "ratings = len(udf)\n",
    "# use the last rating only as test\n",
    "split = ratings - 1\n",
    "utrain = udf.iloc[:split, :]\n",
    "utest = udf.iloc[split:, :]\n",
    "# make the corresponding split to the vector indices, vi\n",
    "vi = udf.beer_id.map(beer_id_to_vecs_index)\n",
    "trainvecs = vecs[vi[:split], :]\n",
    "testvecs = vecs[vi[split:], :]\n",
    "# calculate the user's avg generosity/stinginess towards KNOWN ratings\n",
    "known_bias = utrain.beer_bias.mean()\n",
    "train_targets = utrain.beer_bias - known_bias\n",
    "        \n",
    "stop_early = len(utrain) > 10\n",
    "model = SGDRegressor(penalty='elasticnet', early_stopping=stop_early, validation_fraction=0.1, \n",
    "                     random_state=1, max_iter=500, tol=1e-5, l1_ratio=0.15)\n",
    "model.fit(trainvecs, train_targets)\n",
    "        \n",
    "preds = model.predict(testvecs)\n",
    "baseline_preds = utest.rating_global + known_bias\n",
    "nlp_preds = (0.3 + 1 / trainvecs.shape[0]) * preds + baseline_preds\n",
    "        \n",
    "diffs_base = baseline_preds - utest.rating_user\n",
    "sumsq = np.dot(diffs_base, diffs_base)\n",
    "rmse_base = np.sqrt(sumsq / len(diffs_base))\n",
    "\n",
    "diffs_nlp = nlp_preds - utest.rating_user\n",
    "sumsq = np.dot(diffs_nlp, diffs_nlp)\n",
    "rmse_nlp = np.sqrt(sumsq / len(diffs_nlp))\n",
    "\n",
    "print(rmse_base, rmse_nlp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_user</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>rating_global</th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_description</th>\n",
       "      <th>beer_bias</th>\n",
       "      <th>user_bias</th>\n",
       "      <th>user_pref</th>\n",
       "      <th>sampled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>926456</th>\n",
       "      <td>3038137</td>\n",
       "      <td>2348465</td>\n",
       "      <td>5.00</td>\n",
       "      <td>Bottle Logic Brewing</td>\n",
       "      <td>Time Trials</td>\n",
       "      <td>IPA - Imperial / Double New England</td>\n",
       "      <td>3.96855</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Bottle Logic Brewing Time Trials A mosaic and ...</td>\n",
       "      <td>1.03145</td>\n",
       "      <td>0.271575</td>\n",
       "      <td>0.759875</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926461</th>\n",
       "      <td>2810477</td>\n",
       "      <td>2348465</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Left Coast Brewing Co.</td>\n",
       "      <td>Simply Citra</td>\n",
       "      <td>Pale Ale - New England</td>\n",
       "      <td>3.49517</td>\n",
       "      <td>5.5</td>\n",
       "      <td>Left Coast Brewing Co. Simply Citra New Englan...</td>\n",
       "      <td>0.50483</td>\n",
       "      <td>0.271575</td>\n",
       "      <td>0.233255</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926464</th>\n",
       "      <td>1226915</td>\n",
       "      <td>2348465</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Four Sons Brewing</td>\n",
       "      <td>King Coco</td>\n",
       "      <td>Red Ale - Imperial / Double</td>\n",
       "      <td>3.87233</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Four Sons Brewing King Coco Coconuts for days.</td>\n",
       "      <td>0.12767</td>\n",
       "      <td>0.271575</td>\n",
       "      <td>-0.143905</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926466</th>\n",
       "      <td>2945404</td>\n",
       "      <td>2348465</td>\n",
       "      <td>4.75</td>\n",
       "      <td>FiftyFifty Brewing Co.</td>\n",
       "      <td>I Did It All For the Cookie</td>\n",
       "      <td>Brown Ale - Imperial / Double</td>\n",
       "      <td>3.70066</td>\n",
       "      <td>9.0</td>\n",
       "      <td>FiftyFifty Brewing Co. I Did It All For the Co...</td>\n",
       "      <td>1.04934</td>\n",
       "      <td>0.271575</td>\n",
       "      <td>0.777765</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926468</th>\n",
       "      <td>2722461</td>\n",
       "      <td>2348465</td>\n",
       "      <td>3.25</td>\n",
       "      <td>The Bruery</td>\n",
       "      <td>Rice &amp; Beans (2018)</td>\n",
       "      <td>Blonde Ale</td>\n",
       "      <td>3.94005</td>\n",
       "      <td>7.7</td>\n",
       "      <td>The Bruery Rice &amp; Beans (2018) Rice and Beans ...</td>\n",
       "      <td>-0.69005</td>\n",
       "      <td>0.271575</td>\n",
       "      <td>-0.961625</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        beer_id  user_id  rating_user            brewery_name  \\\n",
       "926456  3038137  2348465         5.00    Bottle Logic Brewing   \n",
       "926461  2810477  2348465         4.00  Left Coast Brewing Co.   \n",
       "926464  1226915  2348465         4.00       Four Sons Brewing   \n",
       "926466  2945404  2348465         4.75  FiftyFifty Brewing Co.   \n",
       "926468  2722461  2348465         3.25              The Bruery   \n",
       "\n",
       "                          beer_name                           beer_style  \\\n",
       "926456                  Time Trials  IPA - Imperial / Double New England   \n",
       "926461                 Simply Citra               Pale Ale - New England   \n",
       "926464                    King Coco          Red Ale - Imperial / Double   \n",
       "926466  I Did It All For the Cookie        Brown Ale - Imperial / Double   \n",
       "926468          Rice & Beans (2018)                           Blonde Ale   \n",
       "\n",
       "        rating_global   abv  \\\n",
       "926456        3.96855   7.8   \n",
       "926461        3.49517   5.5   \n",
       "926464        3.87233  10.0   \n",
       "926466        3.70066   9.0   \n",
       "926468        3.94005   7.7   \n",
       "\n",
       "                                         beer_description  beer_bias  \\\n",
       "926456  Bottle Logic Brewing Time Trials A mosaic and ...    1.03145   \n",
       "926461  Left Coast Brewing Co. Simply Citra New Englan...    0.50483   \n",
       "926464     Four Sons Brewing King Coco Coconuts for days.    0.12767   \n",
       "926466  FiftyFifty Brewing Co. I Did It All For the Co...    1.04934   \n",
       "926468  The Bruery Rice & Beans (2018) Rice and Beans ...   -0.69005   \n",
       "\n",
       "        user_bias  user_pref  sampled  \n",
       "926456   0.271575   0.759875     True  \n",
       "926461   0.271575   0.233255     True  \n",
       "926464   0.271575  -0.143905     True  \n",
       "926466   0.271575   0.777765     True  \n",
       "926468   0.271575  -0.961625     True  "
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1754"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many terms were weighted in the trained model?\n",
    "len(np.nonzero(model.coef_)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and how many of the terms in the single test rating were in those 1754?\n",
    "lastbeerID = udf.loc[udf.index[-1], 'beer_id']\n",
    "vect = beer_id_to_vecs_index[lastbeerID]\n",
    "vect = vecs.toarray()[vect, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  170,   481,  1339,  1401,  2110,  2634,  2828,  2974,  3472,\n",
       "         4244,  4992,  5144,  5317,  5612,  6435,  6696,  7373,  7601,\n",
       "         7858,  8559, 11152, 13399, 14077, 14937, 14938]),)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weighted = [feat for feat in np.nonzero(vect)[0] if feat in set(np.nonzero(model.coef_)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170, 481, 1339, 1401, 2110, 2634, 2828, 2974, 3472, 4244, 4992, 5144, 5317, 5612, 6435, 6696, 7373, 7601, 7858, 8559, 11152, 13399, 14077, 14937, 14938]\n"
     ]
    }
   ],
   "source": [
    "print(weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18636445])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so at least all words in the test rating description were seen and fit in the training ratings.\n",
    "## how much did the dot product contribute?\n",
    "model.predict(testvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user rated this beer .69 below the global mean, where he tended to rate beers .27 over the mean, so the baseline  \n",
    "was off by .96, and the NLP/abv/style model was off another 0.19 in the wrong direction, which got mutiplied down to  \n",
    ".06, for a total of 1.02 wrong.  Let's see why the model leaned the wrong way on this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018', 'add', 'base', 'beans', 'bruery', 'character', 'cinnamon', 'coffee', 'creamy', 'dosing', 'extra', 'features', 'fit', 'fresh', 'heavy', 'horchata', 'just', 'lactose', 'like', 'mia', 'rice', 'tierra', 'vanilla']\n"
     ]
    }
   ],
   "source": [
    "print([cv.get_feature_names()[word] for word in np.nonzero(vect)[0][:-2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's really hard to believe the the training ratings, all 144 of them, included descriptions with 'horchata', 'cinnamon', and 'tierra', so maybe the random initializations of the SGD Regressor didn't get pushed to zero by the regularizers.  But let's see where the model went wrong before adjusting regularizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.063637492968631651, 'character'), (0.049800001767233204, 'fresh'), (-0.043483593152654244, 'just'), (0.04100373763695872, 'vanilla'), (-0.035334403770771787, 'like'), (0.029497633207047933, 'beans'), (0.024502455017940034, 'features'), (0.02235863034129186, 'cinnamon'), (0.011553906457230553, 'rice'), (-0.010920592089463405, 'coffee'), (0.0090194635071176258, 'lactose'), (-0.0088118005099497802, 'creamy'), (-0.0086635022053072799, 'base'), (0.0067852116403035647, 'dosing'), (0.0067852116403035647, 'horchata'), (0.0067852116403035647, 'mia'), (0.0067852116403035647, 'tierra'), (0.0055841977006605807, 'fit'), (0.0050789552507178645, 'heavy'), (0.0035017682115361937, 'extra'), (-0.0029137693361845083, '2018'), (0.0027293080727261339, 'add'), (0.002074350911327369, 'bruery')]\n"
     ]
    }
   ],
   "source": [
    "coefs = [model.coef_[x] for x in np.nonzero(vect)[0][:-2]]\n",
    "print(sorted(list(zip(coefs, [cv.get_feature_names()[word]\n",
    "                              for word in np.nonzero(vect)[0][:-2]])),\n",
    "             key=lambda tup: abs(tup[0]), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18735508654730298"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# had the user tried a blonde ale before the test?\n",
    "'Blonde Ale' in udf.beer_style.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.968302777778 1.02439600448\n"
     ]
    }
   ],
   "source": [
    "# try pushing some more weights to zero\n",
    "model = SGDRegressor(penalty='elasticnet', early_stopping=stop_early, validation_fraction=0.1, \n",
    "                     random_state=1, max_iter=100, tol=1e-5, l1_ratio=0.75)\n",
    "model.fit(trainvecs, train_targets)\n",
    "        \n",
    "preds = model.predict(testvecs)\n",
    "baseline_preds = utest.rating_global + known_bias\n",
    "nlp_preds = (0.3 + 1 / trainvecs.shape[0]) * preds + baseline_preds\n",
    "        \n",
    "diffs_base = baseline_preds - utest.rating_user\n",
    "sumsq = np.dot(diffs_base, diffs_base)\n",
    "rmse_base = np.sqrt(sumsq / len(diffs_base))\n",
    "\n",
    "diffs_nlp = nlp_preds - utest.rating_user\n",
    "sumsq = np.dot(diffs_nlp, diffs_nlp)\n",
    "rmse_nlp = np.sqrt(sumsq / len(diffs_nlp))\n",
    "\n",
    "print(rmse_base, rmse_nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barely better. see how it fares on sample500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "  6%|▋         | 31/489 [00:17<04:37,  1.65it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  7%|▋         | 36/489 [00:20<03:47,  1.99it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▊         | 42/489 [00:24<04:27,  1.67it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▉         | 44/489 [00:25<05:08,  1.44it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "  9%|▉         | 45/489 [00:26<05:33,  1.33it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 10%|█         | 51/489 [00:30<04:12,  1.74it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 15%|█▍        | 72/489 [00:41<04:23,  1.58it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 16%|█▌        | 77/489 [00:45<04:36,  1.49it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 18%|█▊        | 89/489 [00:52<03:59,  1.67it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 20%|██        | 99/489 [00:58<03:35,  1.81it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 25%|██▍       | 122/489 [01:10<03:13,  1.89it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▌       | 125/489 [01:12<03:27,  1.75it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 26%|██▋       | 129/489 [01:15<03:23,  1.77it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 28%|██▊       | 136/489 [01:18<02:34,  2.29it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 35%|███▍      | 170/489 [01:36<02:47,  1.91it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 40%|████      | 198/489 [01:50<01:59,  2.43it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 44%|████▍     | 216/489 [01:57<01:29,  3.04it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 46%|████▌     | 224/489 [01:59<01:28,  2.99it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 46%|████▌     | 226/489 [02:01<02:23,  1.83it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 59%|█████▊    | 287/489 [02:21<01:01,  3.28it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      " 82%|████████▏ | 400/489 [02:57<00:29,  2.98it/s]/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "100%|██████████| 489/489 [03:26<00:00,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.30772315  0.30463446]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "sample500 = np.random.choice(fiveplus.user_id.unique(), 500)\n",
    "fiveplus['sampled'] = fiveplus.user_id.apply(lambda uid: uid in sample500)\n",
    "sample500_scores = test_last(fiveplus[fiveplus.sampled], vecs, beer_id_to_vecs_index, rando=1)\n",
    "print(np.mean([val for val in sample500_scores.values()], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.063662178004126671, 'character'), (0.049732278331194188, 'fresh'), (-0.043785656852763082, 'just'), (0.040501732606832763, 'vanilla'), (-0.035720248303768645, 'like'), (0.029580759492395421, 'beans'), (0.023966031928233506, 'features'), (0.022053733167995984, 'cinnamon'), (0.011343376941701904, 'rice'), (-0.009927475188164378, 'coffee'), (0.0084905683606552942, 'lactose'), (-0.0083185806795426833, 'base'), (-0.0081361642462119549, 'creamy'), (0.0063762141014153456, 'dosing'), (0.0063762141014153456, 'horchata'), (0.0063762141014153456, 'mia'), (0.0063762141014153456, 'tierra'), (0.0052082504019391549, 'fit'), (0.0043961449926575927, 'heavy'), (0.0031807966938111202, 'extra'), (0.0024689257767401317, 'add'), (-0.0016727371125001089, '2018'), (0.0014625024310899188, 'bruery')]\n"
     ]
    }
   ],
   "source": [
    "# vs. (.3077, .3048) with l1=0.15 in elasticnet\n",
    "\n",
    "coefs = [model.coef_[x] for x in np.nonzero(vect)[0][:-2]]\n",
    "print(sorted(list(zip(coefs, [cv.get_feature_names()[word]\n",
    "                              for word in np.nonzero(vect)[0][:-2]])),\n",
    "             key=lambda tup: abs(tup[0]), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(['vanilla' in udf.beer_description.iloc[i].split() for i in range(len(udf)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(['character' in udf.beer_description.iloc[i].split() for i in range(len(udf)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(['blonde' in udf.beer_description.iloc[i].split() for i in range(len(udf)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find the rating for that beer that had 'blonde' in descrip\n",
    "blondie = udf[udf.beer_description.str.contains('blonde')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blondie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SLO Brew Blueberry A SLO Brew Classic loved near and far, this light-bodied blonde ale is infused with organic blueberry flavor to bring you a fresh “crop to can” aroma and balanced body. With this can in hand, you’re ripe for enhanced well being.']"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(blondie.loc[blondie.index, 'beer_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
